<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistik mit R für Umweltwissenschaftler:innen</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Inhaltsverzeichnis</h2>
   
  <ul>
  <li><a href="#vorwort" id="toc-vorwort" class="nav-link active" data-scroll-target="#vorwort">Vorwort</a>
  <ul class="collapse">
  <li><a href="#quellen" id="toc-quellen" class="nav-link" data-scroll-target="#quellen">Quellen</a></li>
  </ul></li>
  <li><a href="#statistik-1-grundlagen-der-statistik" id="toc-statistik-1-grundlagen-der-statistik" class="nav-link" data-scroll-target="#statistik-1-grundlagen-der-statistik">Statistik 1 Grundlagen der Statistik</a>
  <ul class="collapse">
  <li><a href="#lernziele" id="toc-lernziele" class="nav-link" data-scroll-target="#lernziele">Lernziele</a></li>
  <li><a href="#warum-brauchen-wir-statistik" id="toc-warum-brauchen-wir-statistik" class="nav-link" data-scroll-target="#warum-brauchen-wir-statistik">Warum brauchen wir Statistik?</a>
  <ul class="collapse">
  <li><a href="#ein-beispiel" id="toc-ein-beispiel" class="nav-link" data-scroll-target="#ein-beispiel">Ein Beispiel</a></li>
  <li><a href="#fazit" id="toc-fazit" class="nav-link" data-scroll-target="#fazit">Fazit</a></li>
  </ul></li>
  <li><a href="#warum-mit-r" id="toc-warum-mit-r" class="nav-link" data-scroll-target="#warum-mit-r">Warum mit R?</a>
  <ul class="collapse">
  <li><a href="#was-spricht-dagegen" id="toc-was-spricht-dagegen" class="nav-link" data-scroll-target="#was-spricht-dagegen">Was spricht dagegen?</a></li>
  <li><a href="#was-spricht-dafür" id="toc-was-spricht-dafür" class="nav-link" data-scroll-target="#was-spricht-dafür">Was spricht dafür?</a></li>
  <li><a href="#fazit-1" id="toc-fazit-1" class="nav-link" data-scroll-target="#fazit-1">Fazit</a></li>
  </ul></li>
  <li><a href="#die-rolle-von-hypothesen-in-der-wissenschaft" id="toc-die-rolle-von-hypothesen-in-der-wissenschaft" class="nav-link" data-scroll-target="#die-rolle-von-hypothesen-in-der-wissenschaft">Die Rolle von Hypothesen in der Wissenschaft</a>
  <ul class="collapse">
  <li><a href="#rekapitulation" id="toc-rekapitulation" class="nav-link" data-scroll-target="#rekapitulation">Rekapitulation</a></li>
  <li><a href="#was-ist-eine-hypothese" id="toc-was-ist-eine-hypothese" class="nav-link" data-scroll-target="#was-ist-eine-hypothese">Was ist eine Hypothese?</a></li>
  <li><a href="#wissenschaftliches-arbeiten-in-a-nutshell" id="toc-wissenschaftliches-arbeiten-in-a-nutshell" class="nav-link" data-scroll-target="#wissenschaftliches-arbeiten-in-a-nutshell">Wissenschaftliches Arbeiten (in a nutshell)</a></li>
  </ul></li>
  <li><a href="#die-rolle-der-statistik-beim-hypothesengenerieren-und--testen" id="toc-die-rolle-der-statistik-beim-hypothesengenerieren-und--testen" class="nav-link" data-scroll-target="#die-rolle-der-statistik-beim-hypothesengenerieren-und--testen">Die Rolle der Statistik beim Hypothesengenerieren und -testen</a>
  <ul class="collapse">
  <li><a href="#von-der-hypothese-zur-nullhypothese" id="toc-von-der-hypothese-zur-nullhypothese" class="nav-link" data-scroll-target="#von-der-hypothese-zur-nullhypothese">Von der Hypothese zur Nullhypothese…</a></li>
  <li><a href="#einschub-wichtige-termini-in-der-statistik" id="toc-einschub-wichtige-termini-in-der-statistik" class="nav-link" data-scroll-target="#einschub-wichtige-termini-in-der-statistik">Einschub: Wichtige Termini in der Statistik</a></li>
  <li><a href="#einschub-parameter-vs.-prüfgrössen" id="toc-einschub-parameter-vs.-prüfgrössen" class="nav-link" data-scroll-target="#einschub-parameter-vs.-prüfgrössen">Einschub: Parameter vs.&nbsp;Prüfgrössen</a></li>
  <li><a href="#statistische-implementierung-des-hypothesentestens-am-beispiel-des-t-tests" id="toc-statistische-implementierung-des-hypothesentestens-am-beispiel-des-t-tests" class="nav-link" data-scroll-target="#statistische-implementierung-des-hypothesentestens-am-beispiel-des-t-tests">Statistische Implementierung des Hypothesentestens (am Beispiel des t-Tests)</a></li>
  <li><a href="#fehler-i.-und-ii.-art" id="toc-fehler-i.-und-ii.-art" class="nav-link" data-scroll-target="#fehler-i.-und-ii.-art">Fehler I. und II. Art</a></li>
  <li><a href="#p-werte-und-signifikanzniveaus" id="toc-p-werte-und-signifikanzniveaus" class="nav-link" data-scroll-target="#p-werte-und-signifikanzniveaus">p-Werte und Signifikanzniveaus</a></li>
  </ul></li>
  <li><a href="#t-test-für-eine-metrische-variable-im-vergleich-von-zwei-gruppen" id="toc-t-test-für-eine-metrische-variable-im-vergleich-von-zwei-gruppen" class="nav-link" data-scroll-target="#t-test-für-eine-metrische-variable-im-vergleich-von-zwei-gruppen">t-Test (für eine metrische Variable im Vergleich von zwei Gruppen)</a>
  <ul class="collapse">
  <li><a href="#students-und-welch-t-test" id="toc-students-und-welch-t-test" class="nav-link" data-scroll-target="#students-und-welch-t-test">Students und Welch t-Test</a></li>
  <li><a href="#ein--und-zweiseitiger-t-test" id="toc-ein--und-zweiseitiger-t-test" class="nav-link" data-scroll-target="#ein--und-zweiseitiger-t-test">Ein- und zweiseitiger t-Test</a></li>
  <li><a href="#gepaarter-und-ungepaarter-t-test" id="toc-gepaarter-und-ungepaarter-t-test" class="nav-link" data-scroll-target="#gepaarter-und-ungepaarter-t-test">Gepaarter und ungepaarter t-Test</a></li>
  </ul></li>
  <li><a href="#binomial-test-für-die-häufigkeitsverteilung-einer-binomialen-variablen" id="toc-binomial-test-für-die-häufigkeitsverteilung-einer-binomialen-variablen" class="nav-link" data-scroll-target="#binomial-test-für-die-häufigkeitsverteilung-einer-binomialen-variablen">Binomial-Test (für die Häufigkeitsverteilung einer binomialen Variablen)</a></li>
  <li><a href="#chi-quadrat--bzw.-fishers-test-für-die-assoziation-zweier-binomialer-variablen" id="toc-chi-quadrat--bzw.-fishers-test-für-die-assoziation-zweier-binomialer-variablen" class="nav-link" data-scroll-target="#chi-quadrat--bzw.-fishers-test-für-die-assoziation-zweier-binomialer-variablen">Chi-Quadrat- bzw. Fishers Test (für die Assoziation zweier binomialer Variablen)</a>
  <ul class="collapse">
  <li><a href="#chi-quadrat-test" id="toc-chi-quadrat-test" class="nav-link" data-scroll-target="#chi-quadrat-test">Chi-Quadrat-Test</a></li>
  <li><a href="#fishers-exakter-test" id="toc-fishers-exakter-test" class="nav-link" data-scroll-target="#fishers-exakter-test">Fishers exakter Test</a></li>
  </ul></li>
  <li><a href="#wie-berichte-ich-statistische-ergebnisse" id="toc-wie-berichte-ich-statistische-ergebnisse" class="nav-link" data-scroll-target="#wie-berichte-ich-statistische-ergebnisse">Wie berichte ich statistische Ergebnisse?</a>
  <ul class="collapse">
  <li><a href="#welche-relevanten-informationen-benötige-ich-und-wo-finde-ich-sie" id="toc-welche-relevanten-informationen-benötige-ich-und-wo-finde-ich-sie" class="nav-link" data-scroll-target="#welche-relevanten-informationen-benötige-ich-und-wo-finde-ich-sie">Welche relevanten Informationen benötige ich und wo finde ich sie?</a></li>
  <li><a href="#text-tabelle-oder-abbildung" id="toc-text-tabelle-oder-abbildung" class="nav-link" data-scroll-target="#text-tabelle-oder-abbildung">Text, Tabelle oder Abbildung?</a></li>
  <li><a href="#abbildungen-in-wissenschaftlichen-arbeiten" id="toc-abbildungen-in-wissenschaftlichen-arbeiten" class="nav-link" data-scroll-target="#abbildungen-in-wissenschaftlichen-arbeiten">Abbildungen in wissenschaftlichen Arbeiten</a></li>
  <li><a href="#abbildungen-mit-base-r-oder-mit-ggplot2" id="toc-abbildungen-mit-base-r-oder-mit-ggplot2" class="nav-link" data-scroll-target="#abbildungen-mit-base-r-oder-mit-ggplot2">Abbildungen mit „base R” oder mit <code>ggplot2</code>?</a></li>
  </ul></li>
  <li><a href="#zusammenfassung" id="toc-zusammenfassung" class="nav-link" data-scroll-target="#zusammenfassung">Zusammenfassung</a></li>
  <li><a href="#weiterführende-literatur" id="toc-weiterführende-literatur" class="nav-link" data-scroll-target="#weiterführende-literatur">Weiterführende Literatur</a></li>
  </ul></li>
  <li><a href="#statistik-2-einführung-in-lineare-modelle" id="toc-statistik-2-einführung-in-lineare-modelle" class="nav-link" data-scroll-target="#statistik-2-einführung-in-lineare-modelle">Statistik 2: Einführung in lineare Modelle</a>
  <ul class="collapse">
  <li><a href="#lernziele-1" id="toc-lernziele-1" class="nav-link" data-scroll-target="#lernziele-1">Lernziele</a></li>
  <li><a href="#varianzanalyse-anova-einstieg" id="toc-varianzanalyse-anova-einstieg" class="nav-link" data-scroll-target="#varianzanalyse-anova-einstieg">Varianzanalyse (ANOVA): Einstieg</a>
  <ul class="collapse">
  <li><a href="#einfaktorielle-varianzanalyse-one-way-anova" id="toc-einfaktorielle-varianzanalyse-one-way-anova" class="nav-link" data-scroll-target="#einfaktorielle-varianzanalyse-one-way-anova">Einfaktorielle Varianzanalyse (One-Way ANOVA)</a></li>
  <li><a href="#post-hoc-test-tukey" id="toc-post-hoc-test-tukey" class="nav-link" data-scroll-target="#post-hoc-test-tukey">Post-hoc-Test (Tukey)</a></li>
  </ul></li>
  <li><a href="#voraussetzung-statistischer-verfahren" id="toc-voraussetzung-statistischer-verfahren" class="nav-link" data-scroll-target="#voraussetzung-statistischer-verfahren">Voraussetzung statistischer Verfahren</a>
  <ul class="collapse">
  <li><a href="#parametrische-vs.-nicht-parametrische-verfahren" id="toc-parametrische-vs.-nicht-parametrische-verfahren" class="nav-link" data-scroll-target="#parametrische-vs.-nicht-parametrische-verfahren">Parametrische vs.&nbsp;nicht-parametrische Verfahren</a></li>
  <li><a href="#wie-testet-man-die-voraussetzungen-klassischer-weg" id="toc-wie-testet-man-die-voraussetzungen-klassischer-weg" class="nav-link" data-scroll-target="#wie-testet-man-die-voraussetzungen-klassischer-weg">Wie testet man die Voraussetzungen? (klassischer Weg)</a></li>
  <li><a href="#wie-testet-man-die-voraussetzungen-empfohlener-weg" id="toc-wie-testet-man-die-voraussetzungen-empfohlener-weg" class="nav-link" data-scroll-target="#wie-testet-man-die-voraussetzungen-empfohlener-weg">Wie testet man die Voraussetzungen? (empfohlener Weg)</a></li>
  <li><a href="#was-tun-wenn-die-voraussetzungen-verletzt-sind-nicht-parametrische-verfahren" id="toc-was-tun-wenn-die-voraussetzungen-verletzt-sind-nicht-parametrische-verfahren" class="nav-link" data-scroll-target="#was-tun-wenn-die-voraussetzungen-verletzt-sind-nicht-parametrische-verfahren">Was tun, wenn die Voraussetzungen verletzt sind? (nicht-parametrische Verfahren)</a></li>
  <li><a href="#was-tun-wenn-die-voraussetzungen-verletzt-sind-transformationen" id="toc-was-tun-wenn-die-voraussetzungen-verletzt-sind-transformationen" class="nav-link" data-scroll-target="#was-tun-wenn-die-voraussetzungen-verletzt-sind-transformationen">Was tun, wenn die Voraussetzungen verletzt sind? (Transformationen)</a></li>
  </ul></li>
  <li><a href="#mehrfaktorielle-anova" id="toc-mehrfaktorielle-anova" class="nav-link" data-scroll-target="#mehrfaktorielle-anova">Mehrfaktorielle ANOVA</a></li>
  <li><a href="#korrelationen" id="toc-korrelationen" class="nav-link" data-scroll-target="#korrelationen">Korrelationen</a></li>
  <li><a href="#einfache-lineare-regressionen" id="toc-einfache-lineare-regressionen" class="nav-link" data-scroll-target="#einfache-lineare-regressionen">Einfache lineare Regressionen</a>
  <ul class="collapse">
  <li><a href="#idee" id="toc-idee" class="nav-link" data-scroll-target="#idee">Idee</a></li>
  <li><a href="#statistische-umsetzung" id="toc-statistische-umsetzung" class="nav-link" data-scroll-target="#statistische-umsetzung">Statistische Umsetzung</a></li>
  <li><a href="#implementierung-in-r" id="toc-implementierung-in-r" class="nav-link" data-scroll-target="#implementierung-in-r">Implementierung in R</a></li>
  <li><a href="#voraussetzungen" id="toc-voraussetzungen" class="nav-link" data-scroll-target="#voraussetzungen">Voraussetzungen</a></li>
  <li><a href="#alternativen-zur-methode-der-kleinsten-quadrate-ols" id="toc-alternativen-zur-methode-der-kleinsten-quadrate-ols" class="nav-link" data-scroll-target="#alternativen-zur-methode-der-kleinsten-quadrate-ols">Alternativen zur Methode der kleinsten Quadrate (OLS)</a></li>
  </ul></li>
  <li><a href="#lineare-modelle-allgemein" id="toc-lineare-modelle-allgemein" class="nav-link" data-scroll-target="#lineare-modelle-allgemein">Lineare Modelle allgemein</a>
  <ul class="collapse">
  <li><a href="#was-macht-ein-lineares-modell-aus" id="toc-was-macht-ein-lineares-modell-aus" class="nav-link" data-scroll-target="#was-macht-ein-lineares-modell-aus">Was macht ein lineares Modell aus?</a></li>
  <li><a href="#welche-verfahren-gehören-zu-den-linearen-modellen" id="toc-welche-verfahren-gehören-zu-den-linearen-modellen" class="nav-link" data-scroll-target="#welche-verfahren-gehören-zu-den-linearen-modellen">Welche Verfahren gehören zu den linearen Modellen?</a></li>
  <li><a href="#testen-der-voraussetzungen-von-linearen-modellen-modelldiagnostik" id="toc-testen-der-voraussetzungen-von-linearen-modellen-modelldiagnostik" class="nav-link" data-scroll-target="#testen-der-voraussetzungen-von-linearen-modellen-modelldiagnostik">Testen der Voraussetzungen von linearen Modellen (Modelldiagnostik)</a></li>
  </ul></li>
  <li><a href="#zusammenfassung-1" id="toc-zusammenfassung-1" class="nav-link" data-scroll-target="#zusammenfassung-1">Zusammenfassung</a></li>
  <li><a href="#weiterführende-literatur-1" id="toc-weiterführende-literatur-1" class="nav-link" data-scroll-target="#weiterführende-literatur-1">Weiterführende Literatur</a></li>
  </ul></li>
  <li><a href="#statistik-3-lineare-modelle-ii" id="toc-statistik-3-lineare-modelle-ii" class="nav-link" data-scroll-target="#statistik-3-lineare-modelle-ii">Statistik 3: Lineare Modelle II</a>
  <ul class="collapse">
  <li><a href="#lernziele-2" id="toc-lernziele-2" class="nav-link" data-scroll-target="#lernziele-2">Lernziele</a></li>
  <li><a href="#genereller-ablauf-einer-statistischen-analyse" id="toc-genereller-ablauf-einer-statistischen-analyse" class="nav-link" data-scroll-target="#genereller-ablauf-einer-statistischen-analyse">Genereller Ablauf einer statistischen Analyse</a></li>
  <li><a href="#covarianzanalyse-ancova" id="toc-covarianzanalyse-ancova" class="nav-link" data-scroll-target="#covarianzanalyse-ancova">Covarianzanalyse (ANCOVA)</a></li>
  <li><a href="#polynomische-regressionen" id="toc-polynomische-regressionen" class="nav-link" data-scroll-target="#polynomische-regressionen">Polynomische Regressionen</a></li>
  <li><a href="#multiple-lineare-regressionen" id="toc-multiple-lineare-regressionen" class="nav-link" data-scroll-target="#multiple-lineare-regressionen">Multiple lineare Regressionen</a>
  <ul class="collapse">
  <li><a href="#vorgehen" id="toc-vorgehen" class="nav-link" data-scroll-target="#vorgehen">Vorgehen</a></li>
  <li><a href="#problem-1-korrelation-zwischen-den-prädiktoren" id="toc-problem-1-korrelation-zwischen-den-prädiktoren" class="nav-link" data-scroll-target="#problem-1-korrelation-zwischen-den-prädiktoren">Problem 1: Korrelation zwischen den Prädiktoren</a></li>
  <li><a href="#problem-2-overfitting" id="toc-problem-2-overfitting" class="nav-link" data-scroll-target="#problem-2-overfitting">Problem 2: Overfitting</a></li>
  <li><a href="#modellvereinfachung" id="toc-modellvereinfachung" class="nav-link" data-scroll-target="#modellvereinfachung">Modellvereinfachung</a></li>
  <li><a href="#varianzpartitionierung" id="toc-varianzpartitionierung" class="nav-link" data-scroll-target="#varianzpartitionierung">Varianzpartitionierung</a></li>
  <li><a href="#ergebnisdarstellung-partielle-regressionen-und-3-d-grafiken" id="toc-ergebnisdarstellung-partielle-regressionen-und-3-d-grafiken" class="nav-link" data-scroll-target="#ergebnisdarstellung-partielle-regressionen-und-3-d-grafiken">Ergebnisdarstellung: partielle Regressionen und 3-D-Grafiken</a></li>
  </ul></li>
  <li><a href="#information-theoretician-approach-und-multimodel-inference" id="toc-information-theoretician-approach-und-multimodel-inference" class="nav-link" data-scroll-target="#information-theoretician-approach-und-multimodel-inference">Information theoretician approach und multimodel inference</a>
  <ul class="collapse">
  <li><a href="#vergleich-mit-frequentist-statistics" id="toc-vergleich-mit-frequentist-statistics" class="nav-link" data-scroll-target="#vergleich-mit-frequentist-statistics">Vergleich mit frequentist statistics</a></li>
  <li><a href="#masse-der-modellgüte-aic-bic-aicc-δi-evidence-ratios-akaike-weights" id="toc-masse-der-modellgüte-aic-bic-aicc-δi-evidence-ratios-akaike-weights" class="nav-link" data-scroll-target="#masse-der-modellgüte-aic-bic-aicc-δi-evidence-ratios-akaike-weights">Masse der Modellgüte: AIC, BIC, AICc, Δ<sub>i</sub>, Evidence ratios, Akaike weights</a></li>
  <li><a href="#multimodel-inference" id="toc-multimodel-inference" class="nav-link" data-scroll-target="#multimodel-inference">Multimodel inference</a></li>
  </ul></li>
  <li><a href="#zusammenfassung-2" id="toc-zusammenfassung-2" class="nav-link" data-scroll-target="#zusammenfassung-2">Zusammenfassung</a></li>
  <li><a href="#weiterführende-literatur-2" id="toc-weiterführende-literatur-2" class="nav-link" data-scroll-target="#weiterführende-literatur-2">Weiterführende Literatur</a></li>
  </ul></li>
  <li><a href="#statistik-4-komplexere-regressionsmethoden" id="toc-statistik-4-komplexere-regressionsmethoden" class="nav-link" data-scroll-target="#statistik-4-komplexere-regressionsmethoden">Statistik 4: Komplexere Regressionsmethoden</a>
  <ul class="collapse">
  <li><a href="#lernziele-3" id="toc-lernziele-3" class="nav-link" data-scroll-target="#lernziele-3">Lernziele</a></li>
  <li><a href="#von-linearen-modellen-zu-glms" id="toc-von-linearen-modellen-zu-glms" class="nav-link" data-scroll-target="#von-linearen-modellen-zu-glms">Von linearen Modellen zu GLMs</a>
  <ul class="collapse">
  <li><a href="#zwei-beispiele" id="toc-zwei-beispiele" class="nav-link" data-scroll-target="#zwei-beispiele">Zwei Beispiele</a></li>
  <li><a href="#die-idee-der-generalized-linear-models-glms" id="toc-die-idee-der-generalized-linear-models-glms" class="nav-link" data-scroll-target="#die-idee-der-generalized-linear-models-glms">Die Idee der Generalized linear models (GLMs)</a></li>
  <li><a href="#die-drei-komponenten-eines-glm" id="toc-die-drei-komponenten-eines-glm" class="nav-link" data-scroll-target="#die-drei-komponenten-eines-glm">Die drei Komponenten eines GLM</a></li>
  <li><a href="#mögliche-verteilungen-von-werten-und-von-varianzen" id="toc-mögliche-verteilungen-von-werten-und-von-varianzen" class="nav-link" data-scroll-target="#mögliche-verteilungen-von-werten-und-von-varianzen">Mögliche Verteilungen von Werten und von Varianzen</a></li>
  <li><a href="#typen-von-glms" id="toc-typen-von-glms" class="nav-link" data-scroll-target="#typen-von-glms">Typen von GLMs</a></li>
  <li><a href="#das-fitten-und-die-modellgüte-von-glms" id="toc-das-fitten-und-die-modellgüte-von-glms" class="nav-link" data-scroll-target="#das-fitten-und-die-modellgüte-von-glms">Das Fitten und die Modellgüte von GLMs</a></li>
  </ul></li>
  <li><a href="#poisson-regressionen-für-zähldaten" id="toc-poisson-regressionen-für-zähldaten" class="nav-link" data-scroll-target="#poisson-regressionen-für-zähldaten">Poisson-Regressionen für Zähldaten</a>
  <ul class="collapse">
  <li><a href="#berechnung" id="toc-berechnung" class="nav-link" data-scroll-target="#berechnung">Berechnung</a></li>
  <li><a href="#interpretation-und-visualisierung-der-ergebnisse" id="toc-interpretation-und-visualisierung-der-ergebnisse" class="nav-link" data-scroll-target="#interpretation-und-visualisierung-der-ergebnisse">Interpretation und Visualisierung der Ergebnisse</a></li>
  <li><a href="#overdispersion-als-problem" id="toc-overdispersion-als-problem" class="nav-link" data-scroll-target="#overdispersion-als-problem">Overdispersion als Problem</a></li>
  </ul></li>
  <li><a href="#logistische-regressionen-für-binärdaten" id="toc-logistische-regressionen-für-binärdaten" class="nav-link" data-scroll-target="#logistische-regressionen-für-binärdaten">Logistische Regressionen für Binärdaten</a>
  <ul class="collapse">
  <li><a href="#prinzipielles-vorgehen" id="toc-prinzipielles-vorgehen" class="nav-link" data-scroll-target="#prinzipielles-vorgehen">Prinzipielles Vorgehen</a></li>
  <li><a href="#die-theorie-dahinter" id="toc-die-theorie-dahinter" class="nav-link" data-scroll-target="#die-theorie-dahinter">Die Theorie dahinter</a></li>
  <li><a href="#modelldiagnostik-und-ergebnisse" id="toc-modelldiagnostik-und-ergebnisse" class="nav-link" data-scroll-target="#modelldiagnostik-und-ergebnisse">Modelldiagnostik und Ergebnisse</a></li>
  <li><a href="#umsetzung-in-r" id="toc-umsetzung-in-r" class="nav-link" data-scroll-target="#umsetzung-in-r">Umsetzung in R</a></li>
  </ul></li>
  <li><a href="#nicht-lineare-regressionen" id="toc-nicht-lineare-regressionen" class="nav-link" data-scroll-target="#nicht-lineare-regressionen">Nicht-lineare Regressionen</a>
  <ul class="collapse">
  <li><a href="#beispiele" id="toc-beispiele" class="nav-link" data-scroll-target="#beispiele">Beispiele</a></li>
  <li><a href="#unterschiede-von-linearen-und-nicht-linearen-regressionen" id="toc-unterschiede-von-linearen-und-nicht-linearen-regressionen" class="nav-link" data-scroll-target="#unterschiede-von-linearen-und-nicht-linearen-regressionen">Unterschiede von linearen und nicht-linearen Regressionen</a></li>
  <li><a href="#umsetzung-in-r-1" id="toc-umsetzung-in-r-1" class="nav-link" data-scroll-target="#umsetzung-in-r-1">Umsetzung in R</a></li>
  </ul></li>
  <li><a href="#glättungsfunktionen-und-gams" id="toc-glättungsfunktionen-und-gams" class="nav-link" data-scroll-target="#glättungsfunktionen-und-gams">Glättungsfunktionen und GAMs</a>
  <ul class="collapse">
  <li><a href="#glättungsfunktionen" id="toc-glättungsfunktionen" class="nav-link" data-scroll-target="#glättungsfunktionen">Glättungsfunktionen</a></li>
  <li><a href="#gams-generalized-additive-models" id="toc-gams-generalized-additive-models" class="nav-link" data-scroll-target="#gams-generalized-additive-models">GAMs (Generalized additive models)</a></li>
  </ul></li>
  <li><a href="#zusammenfassung-3" id="toc-zusammenfassung-3" class="nav-link" data-scroll-target="#zusammenfassung-3">Zusammenfassung</a></li>
  <li><a href="#weiterführende-literatur-3" id="toc-weiterführende-literatur-3" class="nav-link" data-scroll-target="#weiterführende-literatur-3">Weiterführende Literatur</a></li>
  </ul></li>
  <li><a href="#statistik-5-von-linearen-modellen-zu-glmms" id="toc-statistik-5-von-linearen-modellen-zu-glmms" class="nav-link" data-scroll-target="#statistik-5-von-linearen-modellen-zu-glmms">Statistik 5: Von linearen Modellen zu GLMMs</a>
  <ul class="collapse">
  <li><a href="#lernziele-4" id="toc-lernziele-4" class="nav-link" data-scroll-target="#lernziele-4">Lernziele</a></li>
  <li><a href="#split-plot-und-repeated-measures-anovas" id="toc-split-plot-und-repeated-measures-anovas" class="nav-link" data-scroll-target="#split-plot-und-repeated-measures-anovas">Split-plot und Repeated-measures ANOVAs</a>
  <ul class="collapse">
  <li><a href="#die-idee" id="toc-die-idee" class="nav-link" data-scroll-target="#die-idee">Die Idee</a></li>
  <li><a href="#ein-beispiel-1" id="toc-ein-beispiel-1" class="nav-link" data-scroll-target="#ein-beispiel-1">Ein Beispiel</a></li>
  <li><a href="#umsetzung-in-r-2" id="toc-umsetzung-in-r-2" class="nav-link" data-scroll-target="#umsetzung-in-r-2">Umsetzung in R</a></li>
  </ul></li>
  <li><a href="#linear-mixed-effect-models-lmms" id="toc-linear-mixed-effect-models-lmms" class="nav-link" data-scroll-target="#linear-mixed-effect-models-lmms">Linear mixed effect models (LMMs)</a>
  <ul class="collapse">
  <li><a href="#die-idee-1" id="toc-die-idee-1" class="nav-link" data-scroll-target="#die-idee-1">Die Idee</a></li>
  <li><a href="#umsetzung-in-r-3" id="toc-umsetzung-in-r-3" class="nav-link" data-scroll-target="#umsetzung-in-r-3">Umsetzung in R</a></li>
  </ul></li>
  <li><a href="#generalized-linear-mixed-effect-models-glmms" id="toc-generalized-linear-mixed-effect-models-glmms" class="nav-link" data-scroll-target="#generalized-linear-mixed-effect-models-glmms">Generalized linear mixed effect models (GLMMs)</a>
  <ul class="collapse">
  <li><a href="#die-idee-2" id="toc-die-idee-2" class="nav-link" data-scroll-target="#die-idee-2">Die Idee</a></li>
  <li><a href="#ein-beispiel-und-seine-umsetzung-in-r" id="toc-ein-beispiel-und-seine-umsetzung-in-r" class="nav-link" data-scroll-target="#ein-beispiel-und-seine-umsetzung-in-r">Ein Beispiel und seine Umsetzung in R</a></li>
  <li><a href="#verschiedene-r-packages-für-glmms" id="toc-verschiedene-r-packages-für-glmms" class="nav-link" data-scroll-target="#verschiedene-r-packages-für-glmms">Verschiedene R-packages für GLMMs</a></li>
  <li><a href="#random-vs.-fixed-factors" id="toc-random-vs.-fixed-factors" class="nav-link" data-scroll-target="#random-vs.-fixed-factors">Random vs.&nbsp;fixed factors</a></li>
  </ul></li>
  <li><a href="#lms-glms-lmms-und-glmms-im-rückblick-und-überblick" id="toc-lms-glms-lmms-und-glmms-im-rückblick-und-überblick" class="nav-link" data-scroll-target="#lms-glms-lmms-und-glmms-im-rückblick-und-überblick">LMs, GLMs, LMMs und GLMMs im Rückblick und Überblick</a></li>
  <li><a href="#zusammenfassung-4" id="toc-zusammenfassung-4" class="nav-link" data-scroll-target="#zusammenfassung-4">Zusammenfassung</a></li>
  <li><a href="#weiterführende-literatur-4" id="toc-weiterführende-literatur-4" class="nav-link" data-scroll-target="#weiterführende-literatur-4">Weiterführende Literatur</a></li>
  </ul></li>
  <li><a href="#statistik-6-einführung-in-multivariate-methoden-und-ordinationen-i" id="toc-statistik-6-einführung-in-multivariate-methoden-und-ordinationen-i" class="nav-link" data-scroll-target="#statistik-6-einführung-in-multivariate-methoden-und-ordinationen-i">Statistik 6: Einführung in „multivariate” Methoden und Ordinationen I</a>
  <ul class="collapse">
  <li><a href="#lernziele-5" id="toc-lernziele-5" class="nav-link" data-scroll-target="#lernziele-5">Lernziele</a></li>
  <li><a href="#einführung-in-multivariate-methoden" id="toc-einführung-in-multivariate-methoden" class="nav-link" data-scroll-target="#einführung-in-multivariate-methoden">Einführung in „multivariate” Methoden</a>
  <ul class="collapse">
  <li><a href="#was-ist-mit-multivariat-gemeint" id="toc-was-ist-mit-multivariat-gemeint" class="nav-link" data-scroll-target="#was-ist-mit-multivariat-gemeint">Was ist mit „multivariat” gemeint?</a></li>
  <li><a href="#inferenzstatistik-vs.-deskriptive-statistik" id="toc-inferenzstatistik-vs.-deskriptive-statistik" class="nav-link" data-scroll-target="#inferenzstatistik-vs.-deskriptive-statistik">Inferenzstatistik vs.&nbsp;deskriptive Statistik</a></li>
  <li><a href="#beispiele-multivariater-datensätze" id="toc-beispiele-multivariater-datensätze" class="nav-link" data-scroll-target="#beispiele-multivariater-datensätze">Beispiele multivariater Datensätze</a></li>
  <li><a href="#ziele-multivariat-deskriptiver-analysen" id="toc-ziele-multivariat-deskriptiver-analysen" class="nav-link" data-scroll-target="#ziele-multivariat-deskriptiver-analysen">Ziele multivariat-deskriptiver Analysen</a></li>
  <li><a href="#zwei-komplementäre-ansätze" id="toc-zwei-komplementäre-ansätze" class="nav-link" data-scroll-target="#zwei-komplementäre-ansätze">Zwei komplementäre Ansätze</a></li>
  </ul></li>
  <li><a href="#die-idee-von-ordinationen" id="toc-die-idee-von-ordinationen" class="nav-link" data-scroll-target="#die-idee-von-ordinationen">Die Idee von Ordinationen</a></li>
  <li><a href="#hauptkomponentenanalyse-pca" id="toc-hauptkomponentenanalyse-pca" class="nav-link" data-scroll-target="#hauptkomponentenanalyse-pca">Hauptkomponentenanalyse (PCA)</a>
  <ul class="collapse">
  <li><a href="#das-prinzip" id="toc-das-prinzip" class="nav-link" data-scroll-target="#das-prinzip">Das Prinzip</a></li>
  <li><a href="#in-r" id="toc-in-r" class="nav-link" data-scroll-target="#in-r">In R</a></li>
  <li><a href="#beispiele-von-anwendungen-von-pcas" id="toc-beispiele-von-anwendungen-von-pcas" class="nav-link" data-scroll-target="#beispiele-von-anwendungen-von-pcas">Beispiele von Anwendungen von PCAs</a></li>
  </ul></li>
  <li><a href="#ordinationen-für-problematische-fälle" id="toc-ordinationen-für-problematische-fälle" class="nav-link" data-scroll-target="#ordinationen-für-problematische-fälle">Ordinationen für „problematische” Fälle</a>
  <ul class="collapse">
  <li><a href="#wann-sind-pcas-problematisch" id="toc-wann-sind-pcas-problematisch" class="nav-link" data-scroll-target="#wann-sind-pcas-problematisch">Wann sind PCAs problematisch?</a></li>
  <li><a href="#korrespondenzanalyse-ca" id="toc-korrespondenzanalyse-ca" class="nav-link" data-scroll-target="#korrespondenzanalyse-ca">Korrespondenzanalyse (CA)</a></li>
  <li><a href="#dca" id="toc-dca" class="nav-link" data-scroll-target="#dca">DCA</a></li>
  <li><a href="#nmds" id="toc-nmds" class="nav-link" data-scroll-target="#nmds">NMDS</a></li>
  </ul></li>
  <li><a href="#zusammenfassung-5" id="toc-zusammenfassung-5" class="nav-link" data-scroll-target="#zusammenfassung-5">Zusammenfassung</a></li>
  <li><a href="#weiterführende-literatur-5" id="toc-weiterführende-literatur-5" class="nav-link" data-scroll-target="#weiterführende-literatur-5">Weiterführende Literatur</a></li>
  <li><a href="#quellen-der-beispiele" id="toc-quellen-der-beispiele" class="nav-link" data-scroll-target="#quellen-der-beispiele">Quellen der Beispiele</a></li>
  </ul></li>
  <li><a href="#statistik-7-ordinationen-ii" id="toc-statistik-7-ordinationen-ii" class="nav-link" data-scroll-target="#statistik-7-ordinationen-ii">Statistik 7: Ordinationen II</a>
  <ul class="collapse">
  <li><a href="#lernziele-6" id="toc-lernziele-6" class="nav-link" data-scroll-target="#lernziele-6">Lernziele</a></li>
  <li><a href="#interpretation-von-ordinationsergebnissen" id="toc-interpretation-von-ordinationsergebnissen" class="nav-link" data-scroll-target="#interpretation-von-ordinationsergebnissen">Interpretation von Ordinationsergebnissen</a>
  <ul class="collapse">
  <li><a href="#beschriftung-der-variablen" id="toc-beschriftung-der-variablen" class="nav-link" data-scroll-target="#beschriftung-der-variablen">Beschriftung der Variablen</a></li>
  <li><a href="#post-hoc-korrelation-von-umweltvariablen" id="toc-post-hoc-korrelation-von-umweltvariablen" class="nav-link" data-scroll-target="#post-hoc-korrelation-von-umweltvariablen">Post hoc-Korrelation von Umweltvariablen</a></li>
  <li><a href="#response-surfaces" id="toc-response-surfaces" class="nav-link" data-scroll-target="#response-surfaces">Response surfaces</a></li>
  <li><a href="#zeitliche-entwicklung" id="toc-zeitliche-entwicklung" class="nav-link" data-scroll-target="#zeitliche-entwicklung">Zeitliche Entwicklung</a></li>
  </ul></li>
  <li><a href="#einführung-constrained-ordinations" id="toc-einführung-constrained-ordinations" class="nav-link" data-scroll-target="#einführung-constrained-ordinations">Einführung Constrained Ordinations</a></li>
  <li><a href="#redundancy-analysis-rda-im-detail" id="toc-redundancy-analysis-rda-im-detail" class="nav-link" data-scroll-target="#redundancy-analysis-rda-im-detail">Redundancy Analysis (RDA) im Detail</a>
  <ul class="collapse">
  <li><a href="#die-idee-3" id="toc-die-idee-3" class="nav-link" data-scroll-target="#die-idee-3">Die Idee</a></li>
  <li><a href="#notwendige-datentransformation-für-gemeinschaftsökologische-daten" id="toc-notwendige-datentransformation-für-gemeinschaftsökologische-daten" class="nav-link" data-scroll-target="#notwendige-datentransformation-für-gemeinschaftsökologische-daten">Notwendige Datentransformation für gemeinschaftsökologische Daten</a></li>
  <li><a href="#ein-beispiel-2" id="toc-ein-beispiel-2" class="nav-link" data-scroll-target="#ein-beispiel-2">Ein Beispiel</a></li>
  <li><a href="#generelles-zum-rda-befehl" id="toc-generelles-zum-rda-befehl" class="nav-link" data-scroll-target="#generelles-zum-rda-befehl">Generelles zum rda-Befehl</a></li>
  <li><a href="#interpretation-der-ergebnisse" id="toc-interpretation-der-ergebnisse" class="nav-link" data-scroll-target="#interpretation-der-ergebnisse">Interpretation der Ergebnisse</a></li>
  <li><a href="#visualisierung-der-ergebnisse" id="toc-visualisierung-der-ergebnisse" class="nav-link" data-scroll-target="#visualisierung-der-ergebnisse">Visualisierung der Ergebnisse</a></li>
  <li><a href="#signifikanz-der-achsen" id="toc-signifikanz-der-achsen" class="nav-link" data-scroll-target="#signifikanz-der-achsen">Signifikanz der Achsen</a></li>
  <li><a href="#partielle-rda-und-varianzpartitionierung" id="toc-partielle-rda-und-varianzpartitionierung" class="nav-link" data-scroll-target="#partielle-rda-und-varianzpartitionierung">Partielle RDA und Varianzpartitionierung</a></li>
  </ul></li>
  <li><a href="#zusammenfassung-6" id="toc-zusammenfassung-6" class="nav-link" data-scroll-target="#zusammenfassung-6">Zusammenfassung</a></li>
  <li><a href="#weiterführende-literatur-6" id="toc-weiterführende-literatur-6" class="nav-link" data-scroll-target="#weiterführende-literatur-6">Weiterführende Literatur</a></li>
  <li><a href="#quellen-des-beispiels" id="toc-quellen-des-beispiels" class="nav-link" data-scroll-target="#quellen-des-beispiels">Quellen des Beispiels</a></li>
  </ul></li>
  <li><a href="#statistik-8-clusteranalysen-und-rückblick" id="toc-statistik-8-clusteranalysen-und-rückblick" class="nav-link" data-scroll-target="#statistik-8-clusteranalysen-und-rückblick">Statistik 8: Clusteranalysen und Rückblick</a>
  <ul class="collapse">
  <li><a href="#lernziele-7" id="toc-lernziele-7" class="nav-link" data-scroll-target="#lernziele-7">Lernziele</a></li>
  <li><a href="#clusteranalysen-allgemein" id="toc-clusteranalysen-allgemein" class="nav-link" data-scroll-target="#clusteranalysen-allgemein">Clusteranalysen allgemein</a></li>
  <li><a href="#k-means-clustering" id="toc-k-means-clustering" class="nav-link" data-scroll-target="#k-means-clustering">k-means clustering</a></li>
  <li><a href="#agglomerative-clusterverfahren" id="toc-agglomerative-clusterverfahren" class="nav-link" data-scroll-target="#agglomerative-clusterverfahren">Agglomerative Clusterverfahren</a>
  <ul class="collapse">
  <li><a href="#einführung" id="toc-einführung" class="nav-link" data-scroll-target="#einführung">Einführung</a></li>
  <li><a href="#güte-von-clusterungen" id="toc-güte-von-clusterungen" class="nav-link" data-scroll-target="#güte-von-clusterungen">Güte von Clusterungen</a></li>
  <li><a href="#wie-viele-cluster-sollte-man-unterscheiden" id="toc-wie-viele-cluster-sollte-man-unterscheiden" class="nav-link" data-scroll-target="#wie-viele-cluster-sollte-man-unterscheiden">Wie viele Cluster sollte man unterscheiden?</a></li>
  <li><a href="#charakterisierung-von-clustern" id="toc-charakterisierung-von-clustern" class="nav-link" data-scroll-target="#charakterisierung-von-clustern">Charakterisierung von Clustern</a></li>
  </ul></li>
  <li><a href="#zusammenfassung-7" id="toc-zusammenfassung-7" class="nav-link" data-scroll-target="#zusammenfassung-7">Zusammenfassung</a></li>
  <li><a href="#weiterführende-literatur-7" id="toc-weiterführende-literatur-7" class="nav-link" data-scroll-target="#weiterführende-literatur-7">Weiterführende Literatur</a></li>
  </ul></li>
  <li><a href="#anhang-übersicht-über-statistische-verfahren" id="toc-anhang-übersicht-über-statistische-verfahren" class="nav-link" data-scroll-target="#anhang-übersicht-über-statistische-verfahren">Anhang: Übersicht über statistische Verfahren</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Statistik mit R für Umweltwissenschaftler:innen</h1>
<p class="subtitle lead">Master Modul “Research Methods”</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Autor:in</div>
    <div class="quarto-title-meta-contents">
             <p>Jürgen Dengler mit Beiträgen von Gian-Andrea Egeler, Daniel Hepenstrick &amp; Stefan Widmer </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<p><img src="./myMediaFolder/media/image1.jpeg" class="img-fluid"></p>
<hr>
<p>Skript, Version 25</p>
<p><strong>Empfohlenes Zitat:</strong></p>
<p>Dengler, J., Egeler, G.-A., Hepenstrick, D. &amp; Widmer, S. 2022. <em>Statistik mit R für Umweltwissenschaftler:innen. Skript Version 25.</em> Institut für Umwelt und Natürliche Resourcen (IUNR), ZHAW, Wädenswil, CH.</p>
<p>Korrekturhinweise und Verbesserungsvorschläge an juergen.dengler@zhaw.ch sind willkommen.</p>
<section id="vorwort" class="level1">
<h1>Vorwort</h1>
<p><em>Jürgen Dengler</em></p>
<p>Ich bin Ökologe, kein Statistiker. Trotzdem (oder vielleicht gerade deswegen) wurde ich vor gut drei Jahren, als ich am IUNR als Dozent und Leiter der Forschungsgruppe Vegetationsökologie gefragt, ob ich nicht den Statistikteil im „Research Methods”-Modul des neuen Masterstudiengangs „Umwelt und Natürliche Resourcen” übernehmen würde. Ich habe zugesagt, obwohl ich mir der doppelten Herausforderung klar war: (1) als statistische Autodidakt Statistik zu lehren und (2) dies nicht nur für ÖkologInnen, sondern für angehende UmweltingenieurInnen im Allgemeinen zu tun, deren Interessen von Umweltbildung bis zu Umwelttechnologien reichen und die gleichermassen im naturwissenschaftlichen wie im sozialwissenschaftlichen Bereichen unterwegs sind.</p>
<p>Der Kurs hat sich über die Jahre weiterentwickelt, vor allem durch konstruktiv-kritisches Feedback der Studierenden. Während nur wenige der ehemaligen TeilnehmerInnen vermutlich von sich behaupten würden, im Modul zu begeisterten Statistikfans geworden zu sein, so konnte ich doch in nachfolgenden Mastermodulen (etwa der „Summer School Biodiversity Monitoring” oder bei Präsentationen von Masterarbeiten) feststellen, dass viele das Handwerkszeug sehr solide gelernt haben und souverän anwenden konnten. Manche konnten am Ende des Masterstudium durch stetiges Learning by doing in der offenen Plattform R sogar statistische Fähigkeiten vorweisen, die deutlich über das im Kurs selbst vermittelte hinausgehen. Ja, acht halbe Kurstage sind extrem wenig, um auch nur die wichtigsten Grundlagen der Statistik zu lernen. Wenn ihr erfolgreich sein wollt, müsst ihr also aktiv mitmachen und mehr Quellen nutzen als nur unsere Inputs im Modul.</p>
<p>Ich hatte eigentlich nicht vor, ein Skript zum Kurs zu erstellen, obwohl das Studierende auch in den Vorjahren immer wieder gewünscht haben. Der Aufwand dafür schien mir zu gross – auch in Relation zu den Stunden, die mir für den Kurs zur Verfügung stehen. Ausserdem fand ich, dass das Lernsetting in den Vorjahren mit einer Vorlesung mit vielen Interaktionen mit den Studierenden, gefolgt von der Vorführung und Diskussion von Demo-R-Skripten und schliesslich betreuten Übungen angemessen und recht effizient war. Dann kam bekanntlich Covid-19 und im Herbstsemester 2020 war alles anders. Wir haben entschieden das „Methodenmodul” aus epidemologischen Gründen ohne physischen Kontakt zu euch durchzuführen. Ich hätte wie andere Dozierende in dieser Situation mit Screencasts arbeiten können, aber ohne die Möglichkeit, dabei auf eure Fragen direkt eingehen zu können, schien mir das wenig erfolgsversprechend. Auch den ganzen Vormittag lang online-Kurs zu halten, schien mir für euch wie für uns Dozierende unzumutbar. Insofern habe ich mich nach Diskussionen mit den anderen Beteiligten entschieden, doch ein Skript zu erstellen. Die Idee ist, dass ihr es vorgängig zu den Kurstagen lest und wir dann in einem gemeinsamen Online-Raum auf Zoom, im Sinne eines „inverted classroom” eure offenen Fragen diskutieren können und ich ggf. Punkte, die nicht alle verstanden haben noch einmal „live” erklären kann.</p>
<p>Das hier vorliegende Skript ist zunächst die Verschriftlichung der Vorlesungsfolien der letzten Jahre. Aber viele Aspekte, die auf den Folien nur in Stichpunkten auftauchten, da sie im Kurs live besprochen wurden, sind jetzt eben auch ausformuliert. Nebenbei wurde natürlich manch Anderes auch noch verbessert, ergänzt und aktualisiert. Nichtsdestotrotz ist es die erste Fassung dieses Skriptes und alle Unzulänglichkeiten seien mir nachgesehen. Verbesserungsvorschläge sind jederzeit willkommen.</p>
<p>Wichtig ist, dass dieses Skript nicht als alleiniges Lehrmaterial gedacht ist. Genauso wichtig sind die gemeinsamen Präsenz-Lektionen mit Diskussion des theoretischen Stoffes und der Vorführung (Demo) exemplarischer R-Codes sowie die Übungen und deren Besprechung. Ich empfehle euch auch, begleitend auch andere Quellen zu nutzen, insbesondere wenn einige von euch meine Erklärungen schwer verständlich finden sollten. Welche Form der Informationsbereitstellung jemand eingängig findet, ist individuell sehr verschieden. Für Statistik 1–5 empfehle ich euch insbesondere das Lehrbuch von Crawley (2015), welches das offizielle Begleitlehrbuch zum Kurs ist. Ich werde auch nicht alle Details aus Crawley (2015) im Kurs wiederholen. In den ersten drei Durchführungen haben wir noch das Buch von Logan (2010) verwendet, das ausführlicher ist und „Kochrezepte” auch für komplexere Fälle bietet, die über das hinausgehen, was wir im Kurs behandeln können. Der Vorteil von Crawley (2015) ist, dass das Buch knapper ist und nicht nur auf biologische Fälle, sondern auf beliebige Disziplinen bezogen. Trotzdem ist Logan (2010) weiterhin eine empfehlenswerte Quelle für inferenzstatistische Methoden. Leider gibt es nach meiner Sichtung von etwa zwei Dutzend Statistikbüchern mit R, keines das gleichermassen die Inferenzstatistik und die deskriptiv-multivariate Statistik in der für den Kurs angemessenen Tiefe behandelt. Man könnte das Mammutwerk von Crawley (2013) nennen, aber trotz über 1000 Seiten sind dort die multivariat-deskriptiven Methoden nur sehr kurz (aber immerhin) behandelt und es ist eher ein Kompendium als ein Lehrbuch. Insofern werde ich für Statistik 6–8 auf andere Quellen zurückgreifen, insbesondere auf das exzellente Lehrbuch von Borcard et al.&nbsp;(2018), das aber weitestgehend inferenzstatistischen Methoden aussen vorlässt und die multivariat-deskriptiven aus der alleinigen Sicht von ÖkologInnen beschreibt. Zu guter Letzt möchte ich noch das Buch von Quinn &amp; Keough (2002) empfehlen, das m.&nbsp;E. die ganze Bandbreite statistischer Methoden für ÖkologInnen beschreibt und hervorragend mit vielen Beispielen erklärt, aber eben aus der „Vor-R-Zeit”, mithin ohne Beispiel-Code. Da nahezu alle aus meiner Sicht empfehlenswerten aktuellen Statistikbücher auf Englisch sind, dieses Skript jedoch auf Deutsch, habe ich im Skript wichtige Fachtermini in beiden Sprachen angegeben (Englisch ist dann <em>kursiv</em>), um eine leichtere Verknüpfung zu schaffen.</p>
<p>Im Skript wird die Theorie beginnend mit den einfachsten statistischen Verfahren (die den Masterstudierenden schon geläufig sein sollten) sukzessive aufgebaut, wobei an geeigneten Stellen wichtige Grundsätze (z.B. unabhängigkeit der Messwerte, Voraussetzungen für Tests etc.) erklärt werden, die für die Statistik insgesamt relevant sind. Die Theorie ist immer mit dem entsprechenden R-Code kombiniert, einschliesslich der Interpretation der textlichen und grafischen Ausgaben von R. Das Skript enthält nur Auszüge des R-Codes, der in Gänze im Unterricht (in der jeweils zweiten Lektion) vorgestellt und besprochen wird. Da es in diesem Kursteil um das Verständnis der Statistik geht, wurde kein grosser Aufwand auf das «Optimieren» des visuellen Outputs gelegt, welches den Code of wesentlich verlängert und den Blick vom «Eigentlichen» abgelenkt hätte.</p>
<section id="quellen" class="level2">
<h2 class="anchored" data-anchor-id="quellen">Quellen</h2>
<p>Borcard, D., Gillet, F. &amp; Legendre, P. 2018. <em>Numerical ecology with R</em>. 2nd ed.&nbsp;Springer, Cham, CH: 435 pp.</p>
<p>Crawley, M.J. 2013. <em>The R book</em>. 2nd ed.&nbsp;John Wiley &amp; Sons, Chichester, UK: 1051 pp.</p>
<p>Crawley, M.J. 2015. <em>Statistics – An introduction using R</em>. 2nd ed.&nbsp;John Wiley &amp; Sons, Chichester, UK: 339 pp.</p>
<p>Logan, M. 2010. <em>Biostatistical design and analysis using R: a practical guide</em>. Wiley-Blackwell, Chichester, UK: 546 pp.</p>
<p>Quinn, G.P. &amp; Keough, M.J. 2002. <em>Experimental design and data analysis for biologists</em>. Cambridge University Press, Cambridge, UK: 537 pp.</p>
</section>
</section>
<section id="statistik-1-grundlagen-der-statistik" class="level1">
<h1>Statistik 1 Grundlagen der Statistik</h1>
<p><strong>In Statistik 1 lernen die Studierenden, was (Inferenz-) Statistik im Kern leistet und warum sie für wissenschaftliche Erkenntnis (in den meisten Disziplinen) unentbehrlich ist. Nach einer Wiederholung der Rolle von Hypothesen wird erläutert, wie Hypothesentests in der <em>frequentist</em>-Statistik umgesetzt werden, einschliesslich p-Werten und Signifikanz-Levels. Die praktische Statistik beginnt mit den beiden einfachsten Fällen, dem Chi-Quadrat-Test für die Assoziation zwischen zwei kategorialen Variablen und dem <em>t</em>-Test auf Unterschiede in Mittelwerten zwischen zwei Gruppen. Abschliessend beschäftigen wir uns damit, wie man Ergebnisse statistischer Analysen am besten in Abbildungen, Tabellen und Text darstellt.</strong></p>
<section id="lernziele" class="level2">
<h2 class="anchored" data-anchor-id="lernziele">Lernziele</h2>
<p><em>Ihr…</em></p>
<ul>
<li><em>versteht, was Statistik im Kern leistet und warum Statistik für wissenschaftliche Erkenntnis (in den meisten Disziplinen) unentbehrlich ist;</em></li>
<li><em>könnt Angaben zu p-Werten oder Signifikanzlevels kritisch würdigen;</em></li>
<li><em>wisst, wann man einen t-Test und wann einen Chi-Quadrat-Test verwendet und wie man das praktisch in R durchführt; und</em></li>
<li><em>habt eine grundlegende Idee, worauf es beim Berichten statistischer Ergebnisse, insbesondere in Abbildungen ankommt.</em></li>
</ul>
</section>
<section id="warum-brauchen-wir-statistik" class="level2">
<h2 class="anchored" data-anchor-id="warum-brauchen-wir-statistik">Warum brauchen wir Statistik?</h2>
<section id="ein-beispiel" class="level3">
<h3 class="anchored" data-anchor-id="ein-beispiel">Ein Beispiel</h3>
<p>Ich möchte die grundlegende Notwendigkeit von Statistik mit einem fiktiven Beispiel visualisieren. Gehen wir von einer einfachen Frage aus dem Zierpflanzenbau aus:</p>
<p><strong><em>Unterscheiden sich zwei verschiedene Sorten (Cultivare) in der Blütengrösse?</em></strong></p>
<p><img src="./myMediaFolder/media/image2.emf.png" class="img-fluid"></p>
<p>Um diese Frage zu beantworten, vermessen wir die Blüten der beiden abgebildeten Individuen:</p>
<ul>
<li>Individuum A: 20 cm²</li>
<li>Individuum B: 12 cm²</li>
</ul>
<p>Mithin wäre unsere naive Antwort auf die Eingangsfragen: <strong>Ja, die Blüten von Sorte A sind grösser als jene von B</strong>. Wir können sogar sagen, um wie viel grösser (8 cm² oder 67 %).</p>
<p>Nun haben Pflanzen (wie fast alle Objekte, mit denen wir uns beschäftigen, mit Ausnahme vielleicht von Elementarteilchen) eine gewisse Variabilität:</p>
<p><img src="./myMediaFolder/media/image3.emf.png" class="img-fluid"></p>
<p>Folglich ist es sinnvoller, für die Beantwortung der Frage jeweils mehrere Individuen zu vermessen. Wir greifen nun 10 Individuen jeder Sorte heraus und erzielen folgende Messergebnisse:</p>
<ul>
<li>Individuen A1–A10 [cm²]: 20; 19; 25; 10; 8; 15; 13; 18; 11; 14</li>
<li>Individuen B1–B10 [cm²]: 12; 15; 16; 7; 8; 10; 12; 11; 13; 10</li>
</ul>
<p>Wir erhalten für A einen Mittelwert von 15.3 cm² und für B einen Mittelwert von 11.4 cm² (was wir einfach in Excel ausrechnen können). <strong>Wir schliessen daher, dass die Blüten von A im Mittel 3.9 cm² grösser sind als jene von B</strong>.</p>
<p>Wir könnten uns also zufrieden zurücklehnen und unserem Ergebnis, das wir mit etwas <strong>deskriptiver Statistik</strong> (Mittelwerte) erzielt haben, vertrauen. Wo liegt der Haken? Wir haben nicht alle existierenden Individuen der Sorten A und B vermessen (die „Grundgesamtheit”), sondern nur eine Stichprobe von jeweils 10 Individuen. Nun könnte es sein, dass KollegInnen von uns die gleiche Untersuchung mit jeweils anderen Stichproben von je 10 Individuen durchgeführt haben, etwa folgendermassen (mit ihren jeweiligen Schlussfolgerungen):</p>
<ul>
<li><strong>Mess-Serie 1:</strong>
<ul>
<li>**Individuen A1–A10 [cm²]: 20; 19; 25; 10; 8; 15; 13; 18; 11; 14</li>
<li>Individuen B1–B10 [cm²]: 12; 15; 16; 7; 8; 10; 12; 11; 13; 10</li>
<li>Ergebnis: A = 15.3; B = 11.4; A – B = 3.9 cm² <strong><em>►A ist grösser als B</em></strong></li>
</ul></li>
<li><strong>Mess-Serie 2:</strong>
<ul>
<li>**Individuen A1–A10 [cm²]: 20; 19; 25; 10; 8; 15; 13; 18; 11; 14</li>
<li>Individuen B1–B10 [cm²]: 12; 15; 16; 7; 8; 10; 12; 11; 13; 10</li>
<li>Ergebnis: A = 12.5; B = 11.3; A – B = 1.2 cm² <strong><em>►A ist (wenig) grösser als B</em></strong></li>
</ul></li>
<li><strong>Mess-Serie 3:</strong>
<ul>
<li>**Individuen A1–A10 [cm²]: 20; 19; 25; 10; 8; 15; 13; 18; 11; 14</li>
<li>Individuen B1–B10 [cm²]: 12; 15; 16; 7; 8; 10; 12; 11; 13; 10</li>
<li>Ergebnis: A = 11.0; B = 11.0; A – B = 0.0 cm² <strong><em>►A ist gleich gross wie B</em></strong></li>
</ul></li>
<li><strong>Mess-Serie 4:</strong>
<ul>
<li>**Individuen A1–A10 [cm²]: 20; 19; 25; 10; 8; 15; 13; 18; 11; 14</li>
<li>Individuen B1–B10 [cm²]: 12; 15; 16; 16; 14; 10; 12; 11; 13; 10</li>
<li>Ergebnis: A = 11.0; B = 12.9; A – B = – 1.9 cm² <strong><em>►A ist kleiner als B&nbsp;&gt; </em></strong></li>
</ul></li>
</ul>
<p>Wer hat nun Recht? Um das zu beantworten, benötigen wir die <strong>schliessende Statistik (Inferenzstatistik)</strong>.</p>
</section>
<section id="fazit" class="level3">
<h3 class="anchored" data-anchor-id="fazit">Fazit</h3>
<ul>
<li>In der Regel wollen wir nicht wissen, ob ein einzelnes Individuum der Sorte A sich von einem einzelnen Individuum der Sorte B unterscheidet.</li>
<li>Meist interessiert uns, ob sich die Sorte A als solche von der Sorte B unterscheidet.</li>
<li>Da es in der Regel nicht möglich ist, sämtliche existierenden Individuen beider Sorten (<strong>Grundgesamtheiten</strong>; engl. <em>populations</em>) zu vermessen, vermessen wir die Individuen in zwei <strong>Stichproben</strong> (engl. <em>samples</em>).</li>
<li>Die <strong>Inferenzstatistik</strong> sagt uns dann, <strong>wie wahrscheinlich</strong> ein festgestellter <strong>Unterschied in den Mittelwerten der Stichproben</strong> einem tatsächlichen <strong>Unterschied in den Mittelwerten der Grundgesamtheiten</strong> entspricht.</li>
</ul>
</section>
</section>
<section id="warum-mit-r" class="level2">
<h2 class="anchored" data-anchor-id="warum-mit-r">Warum mit R?</h2>
<p><img src="./myMediaFolder/media/image4.png" class="img-fluid"></p>
<p>Zugegeben: wir haben euch nicht gefragt…</p>
<section id="was-spricht-dagegen" class="level3">
<h3 class="anchored" data-anchor-id="was-spricht-dagegen">Was spricht dagegen?</h3>
<p>Auf den ersten Blick mag aus eurer Sicht ja einiges dagegensprechen</p>
<ul>
<li><strong>keine GUI</strong> (grafische Benutzeroberfläche) zum Klicken - auf Englisch - <strong>schwerer</strong> zu erlernen</li>
</ul>
</section>
<section id="was-spricht-dafür" class="level3">
<h3 class="anchored" data-anchor-id="was-spricht-dafür">Was spricht dafür?</h3>
<ul>
<li>R ist <strong>kostenlos &amp; open source</strong> (unabhängig von teuren Lizenzen)</li>
<li>R ist extrem <strong>leistungsfähig</strong> und immer <strong>up-to-date</strong> (da Tausende „ehrenamtlich” mitprogrammieren)</li>
<li>R ist nah an den <strong>speziellen Bedürfnissen</strong> der einzelnen Disziplinen (durch zahlreiche spezielle <em>Packages</em>)</li>
<li>R «zwingt» die Benutzenden dazu, ihr <strong>statistisches Vorgehen zu durchdenken</strong> (was zu besseren Ergebnissen führt)</li>
<li>R gewährleistet eine sehr <strong>gute Dokumentation</strong> des eigenen Vorgehens („Reproduzierbarkeit”), da der geschriebene R Code anders als eine Klickabfolge in einem kommerziellen Statistikprogramm mit GUI eingesehen und erneut durchgeführt werden kann</li>
<li>R ist effizient, da man Code, den man einmal entwickelt hat, <strong>immer wieder verwenden bzw. für neue Projekte anpassen</strong> kann</li>
<li>Für R gibt es <strong>umfangreiche Hilfe im Internet</strong> (googlen, spezielle Foren,…)</li>
</ul>
</section>
<section id="fazit-1" class="level3">
<h3 class="anchored" data-anchor-id="fazit-1">Fazit</h3>
<p>Der Kursleiter (J.D.) hat Statistik nicht in seinem Studium gelernt und es sich später im Laufe seiner Forscherlaufbahn mühsam sich selbst beigebracht. Damals gab es noch kein R. Dafür gab es teure kommerzielle Statistikprogramme wie SPSS und STATISTICA, durch die man sich mit einer grafischen Benutzeroberfläche durchklicken konnte und am Ende ein Ergebnis bekam. Nicht immer war ganz klar, was das Programm da gerechnet hatte, aber immerhin bekam man mit relativ wenigen Klicks ein numerisches Ergebnis oder eine Abbildung (oft allerdings in bescheidenem Layout) heraus. Häufig musste man aber erleben, dass das gewünschte statistische Verfahren im jeweiligen Programm in der gewünschten Version nicht implementiert war oder ein teures Zusatzpaket nötig gewesen wäre, das die eigene Universität nicht erworben hatte. Und wenn man dann an eine andere Universität wechselte, musste man oft feststellen, dass dort ein anderes Statistikprogramm erworben und genutzt wurde, für das man viele Dinge umlernen musste. Ganz zu schweigen von Zeiten ausserhalb einer Hochschule, wenn man keinen Zugriff auf ein kommerzielles Statistikprogramm hatte.</p>
<p>Aus dieser Sicht könnt ihr euch also glücklich schätzen, dass es heute R gibt und so leistungsfähig ist wie nie zuvor und auch dass das IUNR in der Ausbildung im Bachelor- und Masterlevel konsequent auf R setzt. Während es auf den ersten Blick vielleicht schwieriger erscheinen mag als die Benutzung von SPSS oder STATISTICA, bin ich überzeugt, dass ein Statistikkurs mit R euch bei gleichem Aufwand ein anderes Verständnislevel für Statistik ermöglichen wird als es Statistikkurse zu meiner Studienzeit taten. Nebenher bekommt ihr noch ein implizites Verständnis wie Algorithmen funktionieren, auch nicht ganz unwichtig in einer zunehmend digitalen Welt.</p>
</section>
</section>
<section id="die-rolle-von-hypothesen-in-der-wissenschaft" class="level2">
<h2 class="anchored" data-anchor-id="die-rolle-von-hypothesen-in-der-wissenschaft">Die Rolle von Hypothesen in der Wissenschaft</h2>
<section id="rekapitulation" class="level3">
<h3 class="anchored" data-anchor-id="rekapitulation">Rekapitulation</h3>
<p>Im Methodenmodul und sicher auch in euren vorausgehenden Studiengängen habt ihr euch bereits mit Hypothesen beschäftigt. Daher beginnen wir mit einem Arbeitsauftrag (allein oder im Austausch mit KommilitonInnen):</p>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Arbeitsauftrag
</div>
</div>
<div class="callout-body-container callout-body">
<p>Formuliert jeweils in einem Satz die folgenden Punkte:</p>
<ul>
<li>Eine beispielhafte Aussage, die den Ansprüchen an eine Hypothese genügt</li>
<li>Eine beispielhafte Aussage, die keine Hypothese ist</li>
</ul>
</div>
</div>
</section>
<section id="was-ist-eine-hypothese" class="level3">
<h3 class="anchored" data-anchor-id="was-ist-eine-hypothese">Was ist eine Hypothese?</h3>
<p>Es gibt in der Literatur wie fast immer in der Wissenschaft verschiedene Formulierungen. Ich schlage die folgende vor:</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Eine Hypothese ist eine aus einer allgemeinen Theorie abgeleitete Vorhersage für eine spezifische Situation.</p>
</div>
</div>
</div>
<p>Leider wird der Begriff „Hypothese” heutzutage in der Wissenschaft „inflationär” und aus meiner Sicht sogar häufig falsch verwendet.</p>
<p>Zweifelhaft sind „ad hoc”-Hypothesen auf der Basis einer Vorabuntersuchung bzw. eines „Bauchgefühls”, aber ohne eine Erklärung des für das vorhergesagte Ergebnis verantwortlichen Mechanismus (also letztlich ohne Theorie dahinter). Wissenschaftstheoretisch sollte man nie dieselben Daten zum Aufstellen und zum Testen einer Hypothese verwenden!</p>
<p>Gänzlich falsch sind angebliche „Hypothesen”, die nachträglich aus den schon erzielten Ergebnissen abgeleitet werden.</p>
<p>Warum findet man in der wissenschaftlichen Literatur wie auch in studentischen Arbeiten so viele „Hypothesen”, die wissenschaftstheoretisch dem Konzept einer Hypothese nicht gerecht werden? Der Grund dürfte darin liegen, dass viele von der Annahme geleitet werden, dass nur eine hypthesentestende Forschung eine gute/richtige Forschung ist. Tatsächlich ist aber hypothesengenierende Forschung genauso wichtig und richtig wie hypothesentestende Forschung. Es gilt also:</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Wenn das Vorwissen nicht für eine <strong>plausibel begründete Hypothese</strong> ausreicht (<strong>hypothesentestende Forschung</strong>), formuliert man das Forschungsthema korrekterweise besser als <strong>offene Frage</strong> (<strong>hypothesengenerierende Forschung</strong>).</p>
</div>
</div>
</div>
<p>Dabei können offene Fragen meist mit (fast) den gleichen statistischen Verfahren addressiert werden wie Hypothesen. Allerdings sollten Hypothesen konkret sein, also nicht „A unterscheidet sich von B”, sondern entweder „A ist grösser als B” oder „A ist kleiner als B”. Hier würde also im Fall einer Hypothese ein einseitiger Test, im Fall einer offenen Frage ein zweiseitiger Test zur Anwendung kommen. Dazu aber später mehr.</p>
</section>
<section id="wissenschaftliches-arbeiten-in-a-nutshell" class="level3">
<h3 class="anchored" data-anchor-id="wissenschaftliches-arbeiten-in-a-nutshell">Wissenschaftliches Arbeiten (in a nutshell)</h3>
<p>Wenn wir modernes wissenschaftliches Arbeiten ganz knapp visualisieren, ergibt sich folgendes Bild:</p>
<p><img src="./myMediaFolder/media/image6.emf.png" class="img-fluid"></p>
<p>Bei den ersten Schritten von den Beobachtungen bis zur Spekulation über die Musterursachen handelt es sich um hypothesengenerierende Forschung. Erst wenn man regelmässig, ähnliche Befunde hat, macht das Formulieren enier echten Hypothese Sinn, die nicht nur das gefundene Muster vorhersagt, sondern auch einen Mechanismus bereithält, der erklärt, wie es zustande gekommen ist. Eine solche Hypothese kann dann in einer neuen Untersuchung (mit neuen Daten!) getestet werden, die spezifisch darauf ausgelegt ist, alternative Erklärungsmöglichkeiten auszuschliessen („Experiment”). Hypothesengenierende und hypothesentestende Forschung sind im modernen Forschungsablauf also beide gleichermassen nötig, aber in der Regel getrennt voneinander.</p>
<p>In einer Forschungsarbeit, die für das Testen einer zuvor in anderen Arbeiten erarbeiteten Hypothese, entwickelt wurde („Experiment”), kann das Ergebnis entweder eine Bestätigung oder eine Falsifizierung sein. Wichtig ist, dass eine einmalige Bestätigung keine Verifizierung einer Hypothese ist, während eine einmalige Falsifizierung zur Widerlegung genügt. <strong>Eine Verifizierung einer Hypothese in einem absoluten Sinn ist grundsätzlich nicht möglich, absolute Wahrheit gibt es in der Wissenschaft nicht!</strong> Wenn man jedoch eine Hypothese mit immer neuen „Experimenten” unter immer neuen Rahmenbedingungen „herausfordert” und sie dabei nie falsifiziert wird, dann wird aus einer <strong>einfachen Hypothese</strong> zunehmend <strong>gesichertes Wissen</strong>. Wenn man dagegen eine Hypothese widerlegt hat, muss man zurückgehen. Die vorgeschlagene Erklärung für das gefundene Muster oder sogar das Muster an sich hat sich als nicht korrekt/nicht allgemeingültig herausgestellt. Man muss sich also einen anderen Mechanismus/eine andere Hypothese ausdenken und diese erneut testen. Dies geschieht dann nicht in derselben, sondern in einer folgenden wissenschaftlichen Arbeit.</p>
<p>Mit diesem Wissen über den Ablauf von wissenschaftlicher Erkenntnis und der Rolle des Hypothesentestens dabei habe ich noch eine Frage, zu der ihr euch bis zum Kurstag Gedanken machen solltet:</p>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Frage
</div>
</div>
<div class="callout-body-container callout-body">
<p>Profitiert Wissenschaft mehr von der Bestätigung oder von der Falsifizierung von Hypothesen? (Bitte begründet eure Antwort!)</p>
</div>
</div>
</section>
</section>
<section id="die-rolle-der-statistik-beim-hypothesengenerieren-und--testen" class="level2">
<h2 class="anchored" data-anchor-id="die-rolle-der-statistik-beim-hypothesengenerieren-und--testen">Die Rolle der Statistik beim Hypothesengenerieren und -testen</h2>
<p>Wir haben gesehen, dass Hypothesen zentral für die moderne Wissenschaft sind, sowohl ihr Generieren als auch ihr Test. Doch welche Rolle spielt die Statistik dabei?</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Statistiche Verfahren, die implizit oder explizit Hypothesen testen, bezeichnet man als <strong>Inferenzstatistik (schliessende Statistik)</strong> – im Gegensatz zur <strong>deskriptiven Statistik</strong>.</p>
</div>
</div>
</div>
<section id="von-der-hypothese-zur-nullhypothese" class="level3">
<h3 class="anchored" data-anchor-id="von-der-hypothese-zur-nullhypothese">Von der Hypothese zur Nullhypothese…</h3>
<p>Die Herausforderung ist nun aber, wie oben gesehen, dass man eine <strong>Hypothese (H<sub>a</sub>)</strong> (auch <strong>Forschungshypothese</strong> oder <strong><em>a</em>lternative Hypothese</strong> genannt) nicht verifizieren kann, sondern nur falsifizieren. In der Statistik behilft man sich daher mit einem Trick, der sogenannten <strong>Nullhypothese (H<sub>0</sub>)</strong>. Die Nullhypothese ist die Negation der Hypothese, d.&nbsp;h. die Summe aller möglichen Beobachtungen, die mit der Hypothese nicht im Einklang sind. Wenn man nun die Nullhypothese falsifiziert, kann man indirekt die Hypothese bestätigen.</p>
<p>In unserem Beispiel von oben:</p>
<ul>
<li>Hypothese (H<sub>A</sub>): <strong><em>Sorte A und Sorte B unterscheiden sich in ihrer Blütengrösse</em></strong></li>
<li>Nullhypothese (H<sub>A0</sub>): <strong><em>Sorte A und Sorte B haben die gleiche Blütengrösse</em></strong></li>
</ul>
<p>Das ist formal korrekt, wissenschaftlich ist die Forschungshypothese aber wenig überzeugend, weilschwerlich ein Mechanismus vorstellbar ist, der in Sorte B sowohl kleinere als auch grössere, nur keine gleich grossen Blüten hervorbringt. Insofern wäre das folgende Paar sinnvoller:</p>
<ul>
<li>Hypothese (H<sub>B</sub>): <strong><em>Sorte A hat grössere Blüten als Sorte B</em></strong></li>
<li>Nullhypothese (H<sub>B0</sub>): <strong><em>Sorte A hat kleinere oder gleich grosse Blüten wie Sorte B</em></strong></li>
</ul>
<p>Die erste Forschungshypothese (H<sub>A</sub>) ist eine ungerichtete Hypothese und entspricht dem, was man in hypothesengenerierender Forschung implizit macht (wenn man also offene Fragen, aber keine konkreten Hypothesen hat). In diesem Fall wäre die zugehörige Forschungsfrage: <strong>„Unterscheiden sich die Sorten A und B in ihren Blütengrössen?“</strong>. Die zweite Forschungshypothese (H<sub>B</sub>) ist dagegen gerichtet und wäre für hypothesentestenden Forschung adäquat. In der hypothesentestenden Forschung sollten wir auch eine Begründung/einen Mechanismus anführen, der vermutlich zu dem vorhergesagten Ergebnis führt, etwa dass die Sorte A polyploid ist. Dies gehört zur Begründung der Forschungshypothese, aber ist nicht Bestandteil der Forschungshypothese.</p>
</section>
<section id="einschub-wichtige-termini-in-der-statistik" class="level3">
<h3 class="anchored" data-anchor-id="einschub-wichtige-termini-in-der-statistik">Einschub: Wichtige Termini in der Statistik</h3>
<p>Bis hierher sind uns schon einige wichtige statistische Begriffe (wie Stichprobe und Grundgesamtheit) begegnet, deshalb sollen sie hier samt ihren englischen Pendants noch einmal rekapituliert werden:</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 22%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Deutscher Begriff</strong></th>
<th style="text-align: left;"><strong>Englischer Begriff</strong></th>
<th style="text-align: left;"><strong>Definition</strong></th>
<th style="text-align: left;"><strong>Beispiel(e)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Beobachtung</strong></td>
<td style="text-align: left;"><em>Observation</em></td>
<td style="text-align: left;">experimentelle bzw. Beobachtungseinheit</td>
<td style="text-align: left;">Pflanzenindividuum</td>
</tr>
<tr class="even">
<td><strong>Stichprobe</strong></td>
<td style="text-align: left;"><em>Sample</em></td>
<td style="text-align: left;">alle beprobten Einheiten</td>
<td style="text-align: left;">die 20 untersuchten Pflanzenindividuen</td>
</tr>
<tr class="odd">
<td><strong>Grundgesamtheit</strong></td>
<td style="text-align: left;"><em>Population</em></td>
<td style="text-align: left;">Gesamtheit aller Einheiten, über die eine Aussage getroffen werden soll</td>
<td style="text-align: left;">alle Individuen der beiden Sorten</td>
</tr>
<tr class="even">
<td><strong>Messung</strong></td>
<td style="text-align: left;"><em>Measurement</em></td>
<td style="text-align: left;">einzelne erhobene Information</td>
<td style="text-align: left;">Blütengrösse eines Individuums</td>
</tr>
<tr class="odd">
<td><strong>Variable</strong></td>
<td style="text-align: left;"><em>Variable</em></td>
<td style="text-align: left;">Kategorie der erhobenen Information</td>
<td style="text-align: left;">Blütengrösse, Sorte</td>
</tr>
</tbody>
</table>
<p>Der englische Begriff <em>population</em> führt oft zu Verwirrung, da er in der Statistik etwas anderes meint als in der Biologie. Population ist schlicht die Grundgesamtheit, die in seltenen Fällen einer biologischen Population entspricht, in den meisten Fällen aber nicht (etwa <em>population of chairs</em>). Auch Messung/measurement wird in der Statistik weiter als in der Allgemeinsprache verwendet, d.&nbsp;h. auch für Zählungen oder Erhebung von kategorialen Variablen.</p>
</section>
<section id="einschub-parameter-vs.-prüfgrössen" class="level3">
<h3 class="anchored" data-anchor-id="einschub-parameter-vs.-prüfgrössen">Einschub: Parameter vs.&nbsp;Prüfgrössen</h3>
<p>Wenn wir in Inferenzstatistik betreiben, also von einer Stichprobe auf die Grundgesamtheit schliessen wollen, müssen wir zudem zwischen Parametern und Prüfgrössen unterscheiden. Unter Parameter (<em>parameter</em>) wird eine Grösse der deskriptiven Statistik für eine betimmte Variable in der Grundgesamtheit verstanden, über die wir eine Aussage treffen wollen, die wir aber nicht kennen. Dagegen ist eine Prüfgrösse (<em>statistic</em>) eine aus den Messungen der Variablen in der Stichprobe berechnete Grösse, die zur Schätzung des Parameters dient. Etwas verwirrend ist, dass <em>stastitic</em> (Prüfgrösse) und <em>statistics</em> (die Statistik als Fach) fast gleich lauten. Oft wird die Konvention verwendet, dass die Prüfgrössen mit kursiven lateinischen Buchstaben (z. B. <em>s</em>²) und die korrespondierenden Parameter mit den äquivalenten griechischen Buchstaben (z. B. σ²) bezeichnet werden (siehe die folgende Tabelle):</p>
<p><img src="./myMediaFolder/media/image7.png" class="img-fluid"></p>
<p>(aus Quinn &amp; Keough 2002)</p>
</section>
<section id="statistische-implementierung-des-hypothesentestens-am-beispiel-des-t-tests" class="level3">
<h3 class="anchored" data-anchor-id="statistische-implementierung-des-hypothesentestens-am-beispiel-des-t-tests">Statistische Implementierung des Hypothesentestens (am Beispiel des t-Tests)</h3>
<p>Wie lässt sich das Hypothesentesten nun mathematisch und statistisch umsetzen. Wir bleiben bei unserer offenen Forschungsfrage „Unterscheiden sich die Sorten A und B in ihren Blütengrössen?“, woraus sich die Forschungshypothese „Sorten A und B unterscheiden sich in ihren Blütengrössen” ergibt. Mit dem Mittelwert µ der Variablen (Blütengrösse) in den jeweiligen Grundgesamtheiten (A und B) lassen sich Forschungshypothese und Nullhypothese mathematisch wie folgt formulieren:</p>
<ul>
<li><strong>H<sub>a</sub>:</strong> µ<sub>A</sub> ≠ µ<sub>B</sub></li>
<li><strong>H<sub>0</sub>:</strong> µ<sub>A</sub> = µ<sub>B</sub> oder µ<sub>A</sub> – µ<sub>B</sub> = 0</li>
</ul>
<p>Für die Überprüfung der H<sub>0</sub> gibt es eine Teststatistik (Prüfgrösse) den <em>t</em>-Wert, der wie folgt definiert ist:</p>
<p><span class="math display">\[t = \frac{\left( {\overline{y}}_{A} - {\overline{y}}_{B} \right) - (\mu_{A} - \mu_{B})}{s_{{\overline{y}}_{A} - {\overline{y}}_{B}}}\]</span></p>
<p>Da für die H<sub>0</sub> gilt µ<sub>A</sub> – µ<sub>B</sub> = 0, lässt sich das vereinfachen zu:</p>
<p><span class="math display">\[t = \frac{\left( {\overline{y}}_{A} - {\overline{y}}_{B} \right)}{s_{{\overline{y}}_{A} - {\overline{y}}_{B}}}\]</span></p>
<p>Die Prüfgrösse <em>t</em> ist also die Differenz der beiden Mittelwerte dividiert durch den Standardfehler der Differenz der beiden Mittelwerte. Wenn also die Differenz der Mittelwerte gross und/oder der Standardfehler dieser Differenz klein ist, so ist t weit von Null entfernt.</p>
<p>Was sagt uns der berechnete <em>t</em>-Wert nun? Um daraus etwas schlussfolgern zu können, müssen wir ihn mit der theoretischen <em>t</em>-Verteilung vergleichen. Für diese gilt:</p>
<ul>
<li>Sie ist symmetrisch, mit einem Maximum bei 0.</li>
<li>Der genaue Kurvenverlauf variiert in Abhängigkeit von den Freiheitsgraden (<em>degrees of freedom</em> = df). Bei vielen Freiheitsgraden, d.&nbsp;h. einer grossen Stichprobengrösse (mehr dazu, wie sich die Stichprobenzahl in Freiheitsgrade übersetzt, folgt später), nähert sicht die <em>t</em>-Verteilung einer Normalverteilung (auch <em>z</em>-Verteilung genannt).</li>
</ul>
<p>Die allgemeine Konvention in der Statistik ist, dass die Nullhypothese dann verworfen wird, wenn die berechnete Prüfgrösse extremer ist als 95 % aller möglichen Werte bei der gegebenen Stichprobengrösse. Beim t-Test fragt man also, ob der berechnete <em>t</em>-Wert extremer ist als 95&nbsp;% aller <em>t</em>-Werte der der Stichprobengrösse entsprechenden <em>t</em>-Verteilung. Da unsere Hypothese ungerichtet ist (also ist verschieden und nicht ist grösser/ist kleiner), benötigen wir einen zweiseitigen <em>t</em>-Test. Dieser bestimmt die “kritischen” <em>t</em>-Werte (<em>t<sub>c</sub></em>), indem auf beiden Seiten quasi 2.5 % der Fläche des Integrals unter der Wahrscheinlichkeitsverteilung abgeschnitten werden, wie die folgende Abbildung veranschaulicht:</p>
<p><img src="./myMediaFolder/media/image8.png" class="img-fluid">&nbsp;(aus Quinn &amp; Keough 2002)</p>
<p>Wenn also der berechnete <em>t</em>-Wert &gt; <em>t<sub>c</sub></em> (oder &lt; –<em>t<sub>c</sub></em>) ist, dann sind wir <strong>hinreichend sicher</strong>, dass sich die Mittelwerte nicht nur in der Stichprobe, sondern auch in der Grundgesamtheit unterscheiden.</p>
</section>
<section id="fehler-i.-und-ii.-art" class="level3">
<h3 class="anchored" data-anchor-id="fehler-i.-und-ii.-art">Fehler I. und II. Art</h3>
<p>Wichtig ist, dass es in der physischen Realität nie eine absolute Sicherheit gibt. Wenn wir also wir feststellen, dass die Wahrscheinlichkeit, dass die Nullhypothese zutrifft (oder präziser: dass das vorliegende Ergebnis oder ein extremeres bei Zutreffen der Nullhypothese aufgetreten wäre) kleiner als 5 % ist, gibt es eben doch Fälle gibt, in denen wir fälschlich die Nullhypothese verwerfen, d.&nbsp;h. das Vorliegend eines Effektes bejahen, obwohl er in der Realität (d.&nbsp;h. der Grundgesamtheit) nicht auftritt. Das bezeichnet man als <strong>Typ I-Fehler</strong>. Umgekehrt kann es aber auch passieren, dass man die Nullhypothese aufgrund des statistischen Tests beibehält, also einen Effekt nicht nachweist, obwohl er in der Realität existiert (<strong>Typ II-Fehler</strong>). Diese beiden Phänomene sind in der folgenden beiden Abbildungen visualisiert:</p>
<p><img src="./myMediaFolder/media/image9.emf.png" class="img-fluid"></p>
<p><img src="./myMediaFolder/media/image10.png" class="img-fluid">&nbsp;(aus Quinn &amp; Keough 2002)</p>
<p>Wie man der zweiten Visualisierung entnehmen kann, steigt die Wahrscheinlichkeit eines Typ II-Fehlers, je weiter man die akzeptierte Wahrscheinlichkeit eines Typ I-Fehlers reduziert. In der Statistik wir im Allgemeinen sehr viel stärker auf die Minimierung von Typ I-Fehlern fokusiert, d.&nbsp;h. man will vermeiden, dass man fälschlich einen Effekt behauptet, der in Realität nicht existiert, während es als weniger problematisch angesehen wird, einen vorhandenen, aber dann sehr schwachen Effekt, nicht nachgewiesen zu haben.</p>
</section>
<section id="p-werte-und-signifikanzniveaus" class="level3">
<h3 class="anchored" data-anchor-id="p-werte-und-signifikanzniveaus">p-Werte und Signifikanzniveaus</h3>
<p>Signifikanzniveaus und p-Werte sind zentrale Termini in der am weitesten verbreiteten inferenz-statistischen Schule, der <strong><em>frequentist statistics</em></strong> („Frequentistische Statistik”, aber ich habe den Begriff noch nie im Deutschen gehört). Deren Grundideen sind:</p>
<ul>
<li><p>Die beobachteten Werte werden als eine Beobachtung unter vielen möglichen Beobachtungen interpretiert, die zusammen eine <strong>Häufigkeitsverteilung</strong> ergeben.</p></li>
<li><p>Es wird eine <strong>einzige wahre Beschreibung der Realität</strong> angenommen, der man sich mit bestimmten Irrtumswahrscheinlichkeiten annähern kann</p></li>
</ul>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>In der <em>frequentist statistics</em>, sind die <em>p</em>-Werte das zentrale „Gütemass”. Als <strong><em>p</em>-Wert</strong> bezeichnet man dabei die berechnete <strong>Wahrscheinlichkeit eines Typ I-Fehlers</strong>. Der <em>p</em>-Wert bezeichnet also die Wahrscheinlichkeit, dass man aufgrund des statistischen Tests einen Zusammenhang feststellt, ohne dass dieser in Realität existiert.</p>
</div>
</div>
</div>
<p>Als <strong>statistisch signifikant</strong> bezeichnet man Ergebnisse, die unter einem bestimmten <em>p</em>-Wert liegen. Diese Schwellenwerte sind Konventionen und nicht „gottgegeben”. Traditionell werden drei Signifikanzniveaus verwendet (wozu R noch ein viertes hinzugefügt hat, das man mit „marginal signifikant” bezeichnen könnte), die wie folgt notiert werden:</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 16%">
<col style="width: 70%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Notation</th>
<th>Bedeutung</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">***</td>
<td><em>p</em> &lt; 0.001</td>
<td style="text-align: left;">höchst signifikant; <em>highly significant</em></td>
</tr>
<tr class="even">
<td style="text-align: left;">**</td>
<td><em>p</em> &lt; 0.01</td>
<td style="text-align: left;">hoch signifikant; <em>very significant</em></td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td><em>p</em> &lt; 0.05</td>
<td style="text-align: left;">signifikant; <em>significant</em></td>
</tr>
<tr class="even">
<td style="text-align: left;">.</td>
<td><em>p</em> &lt; 0.1</td>
<td style="text-align: left;">marginal signifikant; <em>marginally significant</em></td>
</tr>
</tbody>
</table>
<p>Die Schwellenwerte der Signifikanzniveaus (d.&nbsp;h. Schwellenwerte für akzeptierte Typ I-Fehler) werden auch mit α bezeichnet. Was man in einer Arbeit als signifikant betrachtet, sollte man vor Beginn der Untersuchung festlegen und im Methodenteil schreiben („als Signifikanzschwelle verwenden wir α <strong>=</strong> 0.05” oder „als signifikant sehen wir Ergebnisse mit p <strong>&lt;</strong> 0.05 an”). Es bietet sich normalerweise an, bei der allgemeinen Konvention von α <strong>=</strong> 0.05 zu bleiben, es sei denn es sprechen spezifische Gründe dagegen. Ein Grund könnte sein, dass die Verwerfung der Nullhypothese/Annahme der Forschunshypothese schwerwiegende Folgen hätte und man sich daher besonders sicher sein will.</p>
<p>Da sich ober-und unterhalb der genannten Schwellen nichts Fundamentales ändert, sollte man grundsätzlich die exakten <em>p</em>-Werte mit drei Nachkommastellen (z.B. „<em>p</em> = 0.038”bzw. wenn noch niedriger als „<em>p</em> &lt; 0.001”) angeben. Zur besseren Lesbarkeit können zusätzlich die korrespondierenden Signifikanzniveaus angegeben werden.</p>
<p>Es ist wichtig, sich bewusst zu sein, dass <strong>statistisch signifikant nicht gleichbedeutend ist mit biologisch bzw. sozialwissenschaftlich bedeutsam</strong>. Ein Effekt kann statistisch hochsignikant sein (wg. grosser Stichprobengrösse) und trotzdem inhaltlich bedeutungslos (da die Effektgrösse minimal ist). Umgekehrt kann ein inhaltlich bedeutsamer Effekt evtl. nicht statistisch signifikant nachgewiesen werden, wenn man extrem wenige Replikate hatte.</p>
<p>Mit dem Kriterium „statistische Signifikanz”/<em>p</em>-Wert trennen wir unsere Ergebnisse in einem ersten Schritt in jene, die wir für <strong>belastbar</strong> halten und jene, die mit grosser Wahrscheinlichkeit „zufällig” („Rauschen in den Daten”, Messungenauigkeit, etc.) zustande gekommen sind. Bei den belastbaren müssen wir dann immer noch ihre <strong>Relevanz</strong> (also die Effektstärke) beurteilen.</p>
</section>
</section>
<section id="t-test-für-eine-metrische-variable-im-vergleich-von-zwei-gruppen" class="level2">
<h2 class="anchored" data-anchor-id="t-test-für-eine-metrische-variable-im-vergleich-von-zwei-gruppen">t-Test (für eine metrische Variable im Vergleich von zwei Gruppen)</h2>
<p>Bei den beiden vorausgehenden einfachen Tests haben wir jeweils binäre Daten bezüglich ihrer Häufigkeitsverteilung analysiert. Oft haben wir aber metrische Variablen als abhängige Grösse, etwa in unserem Blumenbeispiel:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: right;">Sorte A</th>
<th style="text-align: right;">Sorte B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">20</td>
<td style="text-align: right;">12</td>
</tr>
<tr class="even">
<td style="text-align: right;">19</td>
<td style="text-align: right;">15</td>
</tr>
<tr class="odd">
<td style="text-align: right;">25</td>
<td style="text-align: right;">16</td>
</tr>
<tr class="even">
<td style="text-align: right;">10</td>
<td style="text-align: right;">7</td>
</tr>
<tr class="odd">
<td style="text-align: right;">8</td>
<td style="text-align: right;">8</td>
</tr>
<tr class="even">
<td style="text-align: right;">15</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="odd">
<td style="text-align: right;">13</td>
<td style="text-align: right;">12</td>
</tr>
<tr class="even">
<td style="text-align: right;">28</td>
<td style="text-align: right;">11</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11</td>
<td style="text-align: right;">13</td>
</tr>
<tr class="even">
<td style="text-align: right;">14</td>
<td style="text-align: right;">10</td>
</tr>
</tbody>
</table>
<p>H<sub>0</sub>: Die beiden Sorten unterscheiden sich nicht in der Blütengrösse.</p>
<section id="students-und-welch-t-test" class="level3">
<h3 class="anchored" data-anchor-id="students-und-welch-t-test">Students und Welch t-Test</h3>
<p>Als statistisches Verfahren kommt <strong>Students <em>t</em>-Test für zwei unabhängige Stichproben</strong> zum Einsatz („Student” ist das Pseudonym für William Sealy Gosset, dem Erfinder des Tests, dessen Arbeitsvertrag in der Privatwirtschaft das Publizieren von Ergebnissen verbot).</p>
<p><span class="math display">\[
t = \frac{\bar{X}_1-\bar{X}_2}{s_p\times \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}
\]</span></p>
<p>Wobei <span class="math inline">\(s_p\)</span> der gepoolten Varianz entspricht:</p>
<p><span class="math display">\[
s_p = \sqrt{\frac{(n_1-1)s^{2}_{X_{1}}+(n_2-1)s^{2}_{X_{2}}))}{n_1+n_2-2}}
\]</span></p>
<p>Der berechnete t-Wert wird mit der t-Verteilung für (<em>n</em><sub>1</sub> – 1) + (<em>n</em><sub>2</sub> – 1) Freiheitsgraden verglichen. Der klassische t-Test setzt Normalverteilung und gleiche Varianzen voraus:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(blume<span class="sc">$</span>a,blume<span class="sc">$</span>b, <span class="at">var.equal=</span>T)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wenn Varianzgleichheit nicht gegeben ist, verwendet man Welch’ <em>t</em>-Test. Dieser approximiert die Freiheitsgrade mit der Welch-Satterthwaite-Gleichung. Er setzt weiterhin Normalverteilung voraus, benötigt aber keine gleichen Varianzen. Welch’ <em>t</em>-Test kann/sollte also immer verwendet werden, wenn keine vorherigen Tests auf Varianzgleichheit durchgeführt werden und ist daher Standard (default) in R:</p>
<p><span class="math display">\[
t = \frac{\bar{X}_1 - \bar{X}_2}{s\frac{}{\Delta}}
\]</span></p>
<p>Wobei</p>
<p><span class="math display">\[
s\frac{}{\Delta} = \sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}
\]</span></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(blume<span class="sc">$</span>a,blume<span class="sc">$</span>b, <span class="at">var.equal=</span>F)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(blume<span class="sc">$</span>a,blume<span class="sc">$</span>b) </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="ein--und-zweiseitiger-t-test" class="level3">
<h3 class="anchored" data-anchor-id="ein--und-zweiseitiger-t-test">Ein- und zweiseitiger t-Test</h3>
<p>Bislang war unsere Hypothese, dass irgendein Unterschied vorliegt (was, wie oben dargelegt, keine adäquate Forschungshypothese ist, sondern die implizite Hypothese, wenn man eine offene Frage formuliert, aber keine klare Theorie hat). Wenn es eine Theorie gibt, aus der sich eine klare Vorhersage treffen lässt, so enthält diese normalerweise auch eine Aussage über die Richtung des Effekts, also ob die Blüten von A grösser als jene von B sind oder umgekehrt. Dann verwendet man einen einseitigen <em>t</em>-Test, denn man je nach Richtung der Hypothese mit greater oder less spezifizieren muss. Bildlich gesprochen werden beim gängigen Signifikanzniveau von α = 0.05 beim beidseitigen <em>t</em>-Test je 2.5&nbsp;% der Integralfläche links und rechts „abgeschnitten”, beim einseitigen <em>t</em>-Test dagegen 5&nbsp;% auf einer Seite. Wenn der berechnete <em>t</em>-Wert in einem der abgeschnittenen „Dreiecke” liegt, ist das Ergebnis signifikant.</p>
<p><img src="./myMediaFolder/media/image16.png" class="img-fluid">&nbsp;(aus Quinn &amp; Keough 2002)</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(blume<span class="sc">$</span>a,blume<span class="sc">$</span>b)                        <span class="co"># zweiseitig</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(blume<span class="sc">$</span>a,blume<span class="sc">$</span>b, <span class="at">alternative=</span><span class="st">"greater"</span>) <span class="co"># einseitig</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(blume<span class="sc">$</span>a,blume<span class="sc">$</span>b, <span class="at">alternative=</span><span class="st">"less"</span>)    <span class="co"># einseitig</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="gepaarter-und-ungepaarter-t-test" class="level3">
<h3 class="anchored" data-anchor-id="gepaarter-und-ungepaarter-t-test">Gepaarter und ungepaarter t-Test</h3>
<p>Bislang haben wir angenommen, dass die Individuen der beiden Sorten unabhängig voneinander jeweils zufällig ausgewählt wurden. Dann ist ein ungepaarter <em>t</em>-Test (<em>default</em>-Einstellung in R) richtig. Wenn jedoch je zwei Messwerte zusammengehören, etwa wenn je eine Pflanze der Sorten A und B gemeinsam in einem Topf wuchsen , so kommt ein gepaarter <em>t</em>-Test zur Anwendung. Da dieser mehr „Informationen” zur Verfügung hat, hat er mehr statistische „<em>power</em>”, wird i.&nbsp;d.&nbsp;R. also zu stärker signifikanten Ergebnissen führen:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(blume<span class="sc">$</span>a,blume<span class="sc">$</span>b, <span class="at">paired=</span>T) <span class="co">#gepaarter t-Test</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="binomial-test-für-die-häufigkeitsverteilung-einer-binomialen-variablen" class="level2">
<h2 class="anchored" data-anchor-id="binomial-test-für-die-häufigkeitsverteilung-einer-binomialen-variablen">Binomial-Test (für die Häufigkeitsverteilung einer binomialen Variablen)</h2>
<p>Der Binomial-Test ist eines der einfachsten statistischen Verfahren überhaupt. Er testet, ob die Verteilung einer binären Variable von einer Zufallsverteilung abweicht. Eine binomiale (binäre) Variable ist eine, die zwei mögliche Zustände hat, etwa lebend/tot, männlich/weiblich oder besser/schlechter. Wenn das Ergebnis zufällig wäre, müssten in der Stichprobe beide Ausprägungen ungefähr gleich häufig vertreten sein. Folglich testet der Binomialtest, wie wahrscheinlich es ist, dass die vorgefundene Häufigkeitsverteilung in der Stichprobe zustande gekommen wäre, wenn beide Zustände gleich häufig sind. Wenn diese Wahrscheinlichkeit &lt; 0.05 ist, nimmt man in der Statistik gewöhnlich an, dass der Unterschied in der Stichprobe einem realen Unterschied in der Grundgesamtheit ist.</p>
<p>Betrachten wir den Frauenanteil im schweizerischen Nationalrat als Beispiel. Im Jahr 2019 waren 84 von 200 Mitgliedern weiblich (42%). Nehmen wir in guter Näherung an, dass im Stimmvolk das Geschlechterverhältnis 1:1 ist: Kann die Abweichung von 50 % unter den Mitgliedern noch durch Zufall erklärt werden oder deutet das auf eine «Bevorzugung» von Männern bei der Kandidat:innenaufstellung und im Wahlvorgang hin. Die Antwort liefert der Binomialtest, dem man die Zahl der „Erfolge” (weiblich: 82) und die Stichprobengrösse (200) übergeben muss:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.test</span>(<span class="dv">82</span>,<span class="dv">200</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>     Exact binomial test</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>data: 84 and 200</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>number of successes = 84, number of trials = 200, p-value = 0.02813</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>alternative hypothesis: true probability of success is not equal to 0.5</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>95 percent confidence interval:</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a> 0.3507439 0.4916638</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>sample estimates:</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>probability of success</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>                  0.42</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Der Unterschied ist also signifikant (<em>p</em> &lt; 0.05), wir können die Nullhypothese («keine Bevorzugung von Männern») also verwerfen. Der Output sagt uns auch noch, dass ohne Bevorzugung / Benachteiligung eines Geschlechts der gegenwärtige Frauenanteil im Nationalrat nur zustande hätte kommen können, wenn der Frauenanteil im Stimmvolk zwischen 35 % und 49&nbsp;% läge. Da dieser Bereich 50 % (also den der Nullhypothese ensprechenden Wert) nicht einschliesst, ist es logisch, dass diese verworfen wird. Der Test ist „symmetrisch”: Wir können also statt der Anzahl der weiblichen Nationalratsmitglieder auch jene der männlichen eingeben und bekommen den gleichen <em>p</em>-Wert</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.test</span>(<span class="dv">116</span>,<span class="dv">200</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>    Exact binomial test</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>data: 116 and 200</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>number of successes = 116, number of trials = 200, p-value = 0.02813</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>alternative hypothesis: true probability of success is not equal to 0.5</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>95 percent confidence interval:</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a> 0.5083362 0.6492561</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>sample estimates:</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>probability of success</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>                  0.58</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="chi-quadrat--bzw.-fishers-test-für-die-assoziation-zweier-binomialer-variablen" class="level2">
<h2 class="anchored" data-anchor-id="chi-quadrat--bzw.-fishers-test-für-die-assoziation-zweier-binomialer-variablen">Chi-Quadrat- bzw. Fishers Test (für die Assoziation zweier binomialer Variablen)</h2>
<p>Die Frage beim Assoziationstest ist eine ähnliche wie beim Binomialtest. Wiederum geht es um binomiale Variablen, dieses Mal aber nicht um eine einzige, sondern um zwei an denselben Objekten erhobene Variablen, deren Zusammenhang man wissen will.</p>
<p>Im folgenden Beispiel wollen wir wissen, ob die Augenfarbe und die Haarfarbe von Personen miteinander zusammenhängen. Die einfachste Form des Assoziationstests setzt zwei binomiale/binäre Variablen voraus, wir müssen also z. B. grüne Augen ausschliessen oder mit einer der beiden anderen Augenfarben zusammenfassen. Unsere Beobachtungsergebnisse von 114 Personen könnten wie folgt aussehen:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">Blaue Augen</th>
<th style="text-align: center;">Braune Augen</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Helle Haare</td>
<td style="text-align: center;">38</td>
<td style="text-align: center;">11</td>
</tr>
<tr class="even">
<td style="text-align: left;">Dunkle Haare</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">51</td>
</tr>
</tbody>
</table>
<p>Sind diese Werte so erwartbar unter der Nullhypothese, dass Augenfarbe und Haarfarbe unabhängig voneinander sind? Anders als beim Binomialtest oben ist die Nullhypothese jedoch nicht die Gleichverteilung aller Merkmale bzw. Merkmalskombinationen. Vielmehr gehen wir von der gegebenen Häufigkeit der vier Einzelmerkmale aus. Wir müssen also berechnen, mit welcher Wahrscheinlichkeit die Kombination blaue Augen – helle Haare unter den 114 ProbantInnen auftreten sollte, wenn beide Merkmale unabhängig voneinander sind. Das geht folgendermassen:</p>
<table class="table">
<colgroup>
<col style="width: 19%">
<col style="width: 29%">
<col style="width: 29%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">Blaue Augen</th>
<th style="text-align: center;">Braune Augen</th>
<th style="text-align: center;"><strong>Zeilen Total </strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Helle Haare</td>
<td style="text-align: center;"><span class="math inline">\(\frac{49\times 52}{114}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{49\times 62}{114}\)</span></td>
<td style="text-align: center;"><strong>49</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">Dunkle Haare</td>
<td style="text-align: center;"><span class="math inline">\(\frac{64\times 52}{114}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{65\times 62}{114}\)</span></td>
<td style="text-align: center;"><strong>65</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Reihen Total</strong></td>
<td style="text-align: center;"><strong>52</strong></td>
<td style="text-align: center;"><strong>62</strong></td>
<td style="text-align: center;"><strong>114</strong></td>
</tr>
</tbody>
</table>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">Blaue Augen</th>
<th style="text-align: center;">Braune Augen</th>
<th style="text-align: center;">Zeilen total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Helle Haare</td>
<td style="text-align: center;">22.35</td>
<td style="text-align: center;">26.65</td>
<td style="text-align: center;"><strong>49</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">Dunkle Haare</td>
<td style="text-align: center;">29.65</td>
<td style="text-align: center;">33.35</td>
<td style="text-align: center;"><strong>65</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Reihen Total</strong></td>
<td style="text-align: center;"><strong>52</strong></td>
<td style="text-align: center;"><strong>62</strong></td>
<td style="text-align: center;"><strong>114</strong></td>
</tr>
</tbody>
</table>
<p>Die beobachteten Werte (z. B. 38 Personen mit blauen Augen/hellen Haare) unterscheiden sich deutlich von den erwarteten Werten unter der Nullhypothese (22.35 Personen). Aber ist das auch statistisch signifikant?</p>
<section id="chi-quadrat-test" class="level3">
<h3 class="anchored" data-anchor-id="chi-quadrat-test">Chi-Quadrat-Test</h3>
<p>Der traditionelle statistische Test für diese Frage ist Pearsons Chi-Quadrat-Test (auch <em>Χ</em><sup>2</sup>-Test geschrieben). Wie <em>t</em> ist <em>Χ</em><sup>2</sup> eine Teststatistik, die abhängig von den Freiheitsgraden (df) einer ganz bestimmten Kurve folgt.</p>
<p><span class="math display">\[
X^2= \sum{\frac{(O-E)^2}{E}}
\]</span></p>
<p>Wobei <span class="math inline">\(O = \text{observed}\)</span>, <span class="math inline">\(E = \text{expected}\)</span></p>
<p><img src="./myMediaFolder/media/image20.png" class="img-fluid"><br>
(aus Quinn &amp; Keough 2002)</p>
<p>Wir können den <em>Χ</em><sup>2</sup>-Wert in unserem Fall einfach händisch berechnen:</p>
<table class="table">
<colgroup>
<col style="width: 40%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 13%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">O</th>
<th style="text-align: center;">E</th>
<th style="text-align: center;"><span class="math inline">\((O-E)^2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\frac{(O-E)^2}{E}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Helle Haare &amp; blaue Augen</td>
<td style="text-align: center;">38</td>
<td style="text-align: center;">22.35</td>
<td style="text-align: center;">244.92</td>
<td style="text-align: center;">10.96</td>
</tr>
<tr class="even">
<td style="text-align: left;">Helle Haare &amp; braune Augen</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">26.65</td>
<td style="text-align: center;">244.92</td>
<td style="text-align: center;">9.19</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Dunkle Haare &amp; blaue Augen</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">29.65</td>
<td style="text-align: center;">244.92</td>
<td style="text-align: center;">8.26</td>
</tr>
<tr class="even">
<td style="text-align: left;">Dunkle Haare &amp; braune Augen</td>
<td style="text-align: center;">51</td>
<td style="text-align: center;">35.35</td>
<td style="text-align: center;">244.92</td>
<td style="text-align: center;">6.93</td>
</tr>
<tr class="odd">
<td style="text-align: left;">X<sub>2</sub></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">35.33</td>
</tr>
</tbody>
</table>
<p>Ist <em>Χ</em>² = 35.33 nun signifikant oder nicht? Dazu müssen wir noch die Freiheitsgrade berechnen und das Signifikanzniveau festlegen:</p>
<ul>
<li><strong>Freiheitsgrade:</strong> <span class="math inline">\((\text{Spalten}-1)\times(\text{Zeilen}-1)=(2-1)\times(\text2-1)=1\)</span></li>
<li><strong>Signifikanzlevel:</strong> z.B. <span class="math inline">\(\alpha = 0.05\)</span></li>
</ul>
<p>Traditionell hätte man den kritischen Wert für diese Kombination in einer gedruckten Tabelle nachgeschlagen. Wir fragen einfach R, wobei wir 1 – α (in unserem Fall 1-0.05) eingeben müssen, da wir wissen wollen, ob wir im äussersten rechten Teil der Verteilungskurve liegen, also extremer als 95 % der Werte unter der Nullhypothese keiner Assoziation.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qchisq</span>(<span class="fl">0.95</span>,<span class="dv">1</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>3.841495</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Unser berechneter <em>Χ</em>²-Wert (35.33) ist viel grösser als der kritische Wert (3.84), also gibt es eine Assoziation zwischen den Variablen (d.&nbsp;h. die Kombinationen blau/hell und braun/dunkel sind überproportional häufig). Wenn wir, wie oben empfohlen, einen präzisen p-Wert für die Assoziation wollen, erhalten wir ihn folgendermassen (beachte, dass chisq.test eine Matrix als Argument benötigt):</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>count <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">38</span>,<span class="dv">14</span>,<span class="dv">11</span>,<span class="dv">51</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(count)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>Pearson's Chi-squared test with Yates' continuity correction</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>data: count</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>X-squared = 33.112, df = 1, p-value = 8.7e-09</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Die Assoziation ist also höchst signifikant (<em>p</em> &lt; 0.001).</p>
</section>
<section id="fishers-exakter-test" class="level3">
<h3 class="anchored" data-anchor-id="fishers-exakter-test">Fishers exakter Test</h3>
<p>Für kleine Erwartungswerte in den Zellen (&lt; 5) ist der Chi-Quadrat-Test nicht zuverlässig. Dafür gibt es Fishers exakten Test.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>count2 <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">9</span>,<span class="dv">1</span>),<span class="at">nrow=</span><span class="dv">2</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.test</span>(count2)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>     Fisher's Exact Test for Count Data</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>data: count</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>p-value = 0.04299</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>alternative hypothesis: true odds ratio is not equal to 1</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>95 percent confidence interval:</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>0.001280876 1.102291244</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>sample estimates:</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>odds ratio</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>0.08026151</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Man kann/sollte Fishers exakten Test jedoch grundsätzlich verwenden, da er mit der heutigen Rechenleistung von Computern kein Problem mehr darstellt. Angewandt auf unseren Haarfarben / Augenfarben-Datensatz ergibt sich:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>count</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>     [,1]  [,2]</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>[1,]   38    11</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>[2,]   14    51</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.test</span>(count)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>     Fisher's Exact Test for Count Data</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>data: count</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>p-value = 2.099e-09</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>alternative hypothesis: true odds ratio is not equal to 1</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>95 percent confidence interval:</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  4.746351 34.118920</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>sample estimates:</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>odds ratio</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  12.22697</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wie man der Ausgabe entnehmen kann ist die Teststatistik hier die sogenannte <strong><em>odds ratio</em></strong>, ein Term für den es keine gute deutsche Übersetzung gibt. Sie bezeichnet die <strong>Wahrscheinlichkeit des Eintretens geteilt durch die Wahrscheinlichkeit des Nichteintretens</strong>. Aus der Umgangssprache und Wettspielen sind wir bereits vertraut mit <em>odds ratios</em>: «50:50-Chancen» bezeichnen nichts anderes als eine <em>odds ratio</em> von 1 (50 / 50 = 1). Bei einem Assoziationstest ist entspricht der <em>odds rati</em>o die Multiplikation der Wahrscheinlichkeiten auf der einen Diagonalen geteilt durch jene der anderen Diagonalen, also (38 x 51) / (14 x 11).</p>
</section>
</section>
<section id="wie-berichte-ich-statistische-ergebnisse" class="level2">
<h2 class="anchored" data-anchor-id="wie-berichte-ich-statistische-ergebnisse">Wie berichte ich statistische Ergebnisse?</h2>
<section id="welche-relevanten-informationen-benötige-ich-und-wo-finde-ich-sie" class="level3">
<h3 class="anchored" data-anchor-id="welche-relevanten-informationen-benötige-ich-und-wo-finde-ich-sie">Welche relevanten Informationen benötige ich und wo finde ich sie?</h3>
<p>Die Ergebnisausgaben in R sind mitunter umfangreich. Da kommt es darauf an, effizient herausfiltern zu können, was welche Information darin bedeutet und welche davon man in einer wissenschaftlichen arbeit braucht. Hier ist die Ausgabe des vorhergehenden gepaarten <em>t</em>-Tests:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>     Paired t-test</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>data: blume$a and blume$b</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>t = 3.4821, df = 9, p-value = 0.006916</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>alternative hypothesis: true difference in means is not equal to 0</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>95 percent confidence interval:</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  1.366339 6.433661</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>sample estimates:</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>mean of the differences</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>                    3.9</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Welche Informationen davon werden benötigt:</p>
<ol type="1">
<li>Name des Tests (<strong>Methode</strong>)</li>
<li>Signifikanz/<em>p</em>-Wert (<strong>Verlässlichkeit des Ergebnisses</strong>)</li>
<li>Effektgrösse und -richtung (<strong>unser eigentliches Ergebnis!</strong>)</li>
<li>ggf. Wert der Teststatistik und Freiheitsgrade(„Zwischenergebnisse”)</li>
</ol>
<p>Werfen wir noch einmal einen Blick auf den Output von R:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>     Paired t-test</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>data: blume$a and blume$b</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>t = 3.4821, df = 9, p-value = 0.006916</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>alternative hypothesis: true difference in means is not equal to 0</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>95 percent confidence interval:</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  1.366339 6.433661</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>sample estimates:</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>mean of the differences</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>                    3.9</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wichtig ist es, bei aller „Begeisterung” für die <em>p</em>-Werte nicht unser eigentliches Ergebnis zu vergessen, d.&nbsp;h. die Antwort auf die Frage ob die Blüten von A oder von B grösser sind und wenn ja wie stark (blau). Ob Freiheitsgrade und der Wert der Teststatistik angegeben werden müssen, darüber gehen die Geschmäcker auseinander. Wenn man die Daten korrekt in R eingegeben hat, spezifiziert R die Freiheitsgrade automatisch und bei gegebenen Freiheitsgraden ist die Beziehung von <em>t</em> zu <em>p</em> eindeutig. Deshalb genügt es m. E. <em>p</em> anzugeben. (Aber wenn der Betreuer oder die Editorin auch noch <em>t</em> und <em>df</em> haben wollen, dann sollte man sie parat haben). Ein adäquater Satz im Ergebnisteil, der den obigen R <em>output</em> zusammenfasst, lautet daher:</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Die Blütengrösse unterschied sich hochsignifikant zwischen den beiden Sorten mit einem Mittelwert von 15.3 cm² für Sorte A und 11.4 cm² für Sorte B (gepaarter <em>t</em>-Test, <em>p</em> = 0.007, <em>t</em> = 3.482, FG = 9).</p>
</div>
</div>
</div>
<p>Oder auf Englisch:</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Flower sizes differed very significantly between the two cultivars with a mean size of 15.3 cm² in cultivar A and 11.4 cm² in the cultivar B (paired <em>t</em>-test, <em>p</em> = 0.007, <em>t</em> = 3.482, df = 9).</p>
</div>
</div>
</div>
</section>
<section id="text-tabelle-oder-abbildung" class="level3">
<h3 class="anchored" data-anchor-id="text-tabelle-oder-abbildung">Text, Tabelle oder Abbildung?</h3>
<p>Hier kommen ein paar wichtige Vorgaben und Empfehlungen:</p>
<ul>
<li><strong>Jedes Ergebnis nur 1x ausführlich darstellen</strong>, entweder als Abbildung, in einer Tabelle oder als Text</li>
<li>Wenn als Abbildung oder Tabelle, dann <strong>im Text mit einem zusammenfassenden Statement darauf verweisen</strong>, das nicht alle Details wiederholt</li>
<li><strong>Signifikante und nicht signifikante Ergebnisse</strong> berichten</li>
<li><strong>Gängige Strategie:</strong>
<ul>
<li><strong>Abbildungen:</strong> für die wichtigsten signifikanten Ergebnisse</li>
<li><strong>Tabellen:</strong> für die weiteren signifikanten Ergebnisse</li>
<li><strong>Nur Text:</strong> für die nicht signifikanten Ergebnisse</li>
</ul></li>
</ul>
</section>
<section id="abbildungen-in-wissenschaftlichen-arbeiten" class="level3">
<h3 class="anchored" data-anchor-id="abbildungen-in-wissenschaftlichen-arbeiten">Abbildungen in wissenschaftlichen Arbeiten</h3>
<p>Zumindest für die wichtigsten signifikanten Ergebnisse produzieren wir normalerweise Abbildungen. Dabei ist es wichtig, die folgenden Prinzipien zu beherzigen:</p>
<ul>
<li>Abbildungen (und Tabellen) sollten <strong>ohne den zugehörigen Text informativ</strong> sein, d.&nbsp;h. normalerweise <em>p</em>-Werte in der Abbildung/Tabelle bzw. Unter-/Überschrift angeben</li>
<li><strong>Achsen sind verständlich beschriftet</strong> (ausgeschriebene Variablennamen mit Einheit)</li>
<li><strong>Keine Abbildungsüberschrift</strong> (es gibt die Legende in der Abbildungsunterschrift)</li>
<li>Keine überflüssigen Elemente (z.&nbsp;B. Rahmen, farbiger Hintergrund,horizontale und vertikale Linien)</li>
<li>Klarer <strong>Kontrast</strong>, ausreichende <strong>Linienstärke</strong> und <strong>Schriftgrösse.</strong></li>
</ul>
</section>
<section id="abbildungen-mit-base-r-oder-mit-ggplot2" class="level3">
<h3 class="anchored" data-anchor-id="abbildungen-mit-base-r-oder-mit-ggplot2">Abbildungen mit „base R” oder mit <code>ggplot2</code>?</h3>
<p>Im Folgenden visualisiert mit den Boxplots, die zum <em>t</em>-Test gehören.</p>
<p>In „base R” geht das folgendermassen:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(size<span class="sc">~</span>cultivar,<span class="at">data=</span>blume.long)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image22.png" class="img-fluid"></p>
<p>In ggplot2 geht es folgendermassen (mit <em>default</em>-Einstellungen):</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(blume.long, <span class="fu">aes</span>(cultivar,size)) <span class="sc">+</span> <span class="fu">geom_boxplot</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image23.png" class="img-fluid"></p>
<p>Gut ist, dass die Achsen automatisch beschriftet wurden. Störend ist der graue Hintergrund (reduziert Kontrast) und die weissen Gitternetzlinien (übeflüssig und dank des zu geringen Kontrasts eh kaum zu sehen).</p>
<p>Man kann das in ggplot2 durch Wahl des vordefinierten <code>theme_classic</code> optimieren:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(blume.long, <span class="fu">aes</span>(cultivar,size)) <span class="sc">+</span> <span class="fu">geom_boxplot</span>()<span class="sc">+</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_classic</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image24.png" class="img-fluid"></p>
<p>Das Ergebnis ist insgesamt OK, allerdings sind die Linien zu fein und die Schrift zu klein – jeweils relativ zur Gesamtgrösse der Abbildung.</p>
<p>Man kann weiter optimieren durch Hinzufügen weiterer Steuerelemente:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(blume.long, <span class="fu">aes</span>(cultivar,size)) <span class="sc">+</span> </span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_boxplot</span>(<span class="at">size=</span><span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_classic</span>() <span class="sc">+</span> </span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">axis.line =</span> <span class="fu">element_line</span>(<span class="at">size=</span><span class="dv">1</span>), <span class="at">axis.ticks =</span> <span class="fu">element_line</span>(<span class="at">size=</span><span class="dv">1</span>),<span class="at">axis.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">20</span>), <span class="at">axis.title =</span><span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">20</span>))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image25.png" class="img-fluid"></p>
<p>Jetzt passt es… Einzig könnte man noch den <em>p</em>-Wert einblenden und die Achsenbeschriftungen jeweils mit einem Grossbuchstaben beginnen.</p>
<p>Ob man die Grafiken mit ggplot2 oder base R gestaltet, sei jedem selbst überlassen. Beides hat Vor- und Nachteile. Was man aber vermeiden sollte, sind die Ausgaben von ggplot2 mit default-Einstellungen, da diese gängigen Standards für gute Grafiken widerspechen. Hier noch einmal zusammengefasst die Vor- und Nachteile beider Systeme:</p>
<p>Base R:</p>
<ul>
<li>Einfache Syntax, daher geeignet für schnelles Plotten</li>
<li>ABER: Syntax variiert zwischen verschiedenen Plottbefehlen</li>
<li>ABER: «Finetunen» von Grafiken oftmals umständlich oder gar nicht möglich</li>
<li>Geeignet für Vektoren (ggplot2 braucht dataframes o.ä)</li>
<li>Geeignet für das Plotten von Modellen (plot(lm())</li>
<li>Einfaches Plotten der Modelldiagnostik (plot(summary())</li>
</ul>
<p>Vorteile ggplot2:</p>
<ul>
<li>Leistungsfähige, universelle Syntax, daher leicht anpassbar an den Bedarf, wenn man das Prinzip erst einmal verstanden hat</li>
<li>Viele Funktionen “out of the box”</li>
<li>Einfachere Gestaltungsmöglichkeit (Farbskalen usw.)</li>
</ul>
</section>
</section>
<section id="zusammenfassung" class="level2">
<h2 class="anchored" data-anchor-id="zusammenfassung">Zusammenfassung</h2>
<ul>
<li>Wissenschaftliche Forschung zielt in der Regel entweder auf das <strong>Generieren oder das Testen von Hypothesen</strong>.</li>
<li><strong>Inferenzstatistik</strong> ist das Set statistischer Verfahren (Tests), das sowohl für das Testen als auch das Generieren von Hypothesen) verwendet wird.</li>
<li>Inferenzstatistik ist notwendig, um zu bestimmen, <strong>wie wahrscheinlich ein beobachtetes Muster durch angenommenen Einflussgrössen (Variablen)</strong> und nicht durch (a) Messfehler oder (b) andere «Störgrössen» <strong>hervorgerufen wurde</strong>.</li>
<li>Der <strong><em>p</em>-Wert ist die Wahrscheinlichkeit eines Typ I-Fehlers</strong>, d.&nbsp;h. einen Effekt zu berichten, wo keiner ist; nach üblicher Konvention wird ein Effekt dann als hinreichend sicher (signifikant) angesehen, wenn <em>p</em> &lt; 0.05.</li>
<li>Mit einem <strong>Chi-Quadrat-Test</strong> (oder besser mit Fishers exaktem Test) kann man auf eine <strong>Assoziation zwischen zwei kategorialen Variablen</strong> testen.</li>
<li>Mit einem <strong><em>t</em>-Test kann man</strong> auf <strong>Unterschiede in den Mittelwerten einer metrischen Variablen</strong> zwischen zwei Gruppen testen.</li>
</ul>
</section>
<section id="weiterführende-literatur" class="level2">
<h2 class="anchored" data-anchor-id="weiterführende-literatur">Weiterführende Literatur</h2>
<ul>
<li>**Crawley, M.J. 2015. *Statistics – An introduction using R<strong>. 2nd ed.&nbsp;John Wiley &amp; Sons, Chichester, UK: 339 pp.</strong>
<ul>
<li>Chapter 1 – Fundamentals</li>
<li>Chapter 6 – Two Samples</li>
</ul></li>
<li>Quinn, G.P. &amp; Keough, M.J. 2002. <em>Experimental design and data analysis for biologists</em>. Cambridge University Press, Cambridge, UK: 537 pp.</li>
</ul>
</section>
</section>
<section id="statistik-2-einführung-in-lineare-modelle" class="level1">
<h1>Statistik 2: Einführung in lineare Modelle</h1>
<p><strong>In Statistik 2 lernen die Studierenden die Voraussetzungen und die praktische Anwendung „einfacher” linearer Modelle in R (sowie teilweise ihrer „nicht-parametrischen” bzw. „robusten” Äquivalente). Am Anfang steht die Varianzanalyse (ANOVA) als Verallgemeinerung des <em>t</em>-Tests, einschliesslich post-hoc-Tests und mehrfaktorieller ANOVA. Dann geht es um die Voraussetzungen parametrischer (und nicht-parametrischer) Tests und Optionen, wenn diese verletzt sind. Dann beschäftigen wir uns mit Korrelationen, die auf einen linearen Zusammenhang zwischen zwei metrischen Variablen testen, ohne Annahme einer Kausalität. Es folgen einfache lineare Regressionen, die im Prinzip das Gleiche bei klarer Kausalität leisten. Abschliessend besprechen wir, was die grosse Gruppe linearer Modelle (Befehl lm in R) auszeichnet.</strong></p>
<section id="lernziele-1" class="level2">
<h2 class="anchored" data-anchor-id="lernziele-1">Lernziele</h2>
<p><em>Ihr…</em></p>
<ul>
<li><em>wisst, welche Voraussetzungen parametrische (und nicht-parametrische) Tests haben und welche Alternativen euch bei wesentlichen Verletzungen zur Verfügung stehen;</em></li>
<li><em>könnt eine ANOVA in R durchführen, versteht ihre Ergebnisse und könnt diese adäquat in Text und Abbildungen dokumentieren;</em></li>
<li><em>habt den Unterschied zwischen Korrelationen und Regressionen verstanden und könnt sie in R implementieren;</em></li>
<li><em>kennt die Voraussetzungen und Gemeinsamkeiten aller linearen Modelle; und</em></li>
<li><em>wisst, warum es nach der Berechnung eines linearen Modelles essenziell ist, die Residuen zu checken, und könnt die diagnostischen Grafiken von R dazu interpretieren.</em></li>
</ul>
</section>
<section id="varianzanalyse-anova-einstieg" class="level2">
<h2 class="anchored" data-anchor-id="varianzanalyse-anova-einstieg">Varianzanalyse (ANOVA): Einstieg</h2>
<section id="einfaktorielle-varianzanalyse-one-way-anova" class="level3">
<h3 class="anchored" data-anchor-id="einfaktorielle-varianzanalyse-one-way-anova">Einfaktorielle Varianzanalyse (One-Way ANOVA)</h3>
<p>Eine ANOVA (<em>Analysis of variance</em>) ist die Verallgemeinerung des <em>t</em>-Tests für mehr als zwei Gruppen (<em>Factor levels</em>). Auch hier wollen wir wissen, <strong>ob/wie sich die Mittelwerte der abhängigen Variablen zwischen den Gruppen unterscheiden</strong>. Varianzanalyse heisst das Verfahren, weil der statistische Test zur Beantwortung der Frage das <strong>Verhältnis zweier Varianzen</strong> testet. Was es mit den zwei Varianzen auf sich hat, ist im Folgenden erklärt.</p>
<p>Gehen wir zurück zu unserem Blumenbeispiel. Die Idee der ANOVA ist, dass die Mittelwerte der Blütengrössen der beiden Sorten dann verschieden sind, wenn die Summe der Abweichungen (Residuen) vom Gesamtmittelwert „signifikant” grösser ist als die Summe der Abweichungen von den Sortenmittelwerten. Das ist in der folgenden Abbildung veranschaulicht. Die Punkte stellen die 20 Messwerte der Blütengrössen dar, wobei sie in der rechten Teilabbildung nach Sorten gruppiert sind. Der Gesamtmittelwert links und die beiden Sortenmittelwerte rechts sind als horizontale Linien dargestellt. Die vertikalen Linien sind die Residuen, als der Anteil der Varianz, welcher durch das jeweilige statistische Modell nicht erklärt wird. Das Modell links ist, dass die Blüten einheitlich gross sind, unabhängig von der Sorte, während das komplexere Modell rechts unterschiedliche Mittelwerte abhängig von der Sorte annimmt.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="./myMediaFolder/media/image26.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="./myMediaFolder/media/image27.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>Varianz ist ein Mass für die Streuung von Werten um ihren Mittelwert. Mathematisch wird die Varianz wie folgt berechnet :</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><span class="math display">\[\text{Varianz} = \text{Summe der Abweichungsquadrate} / \text{Freiheitsgrade}
\]</span></p>
<p>(Summe der Abweichungsquadrate = Sum of squares = SS)</p>
</div>
</div>
</div>
<p>Abweichungsquadrate sind dabei die quadrierten Werte der grünen (bzw. schwarzen und roten) vertikalen Linien in der obigen Abbildung. Die Distanzen werden quadriert, so dass negative Abweichungen gleichermassen zählen. Würde man nur die unquadrierten Werte aufsummieren, wäre das Ergebnis immer 0, da die horizontale Linie (der Mittelwert) ja genaus gelegt wurde, dass die positiven und negativen Abweichungen betragsmässig gleich sind. Ein zentraler Punkt der Varianzanalyse ist, dass sich die Gesamtsumme der Abweichungsquadrate (<em>Total</em> s<em>um of squares</em>) als die Summe zweier Teile (SSE und SSA) darstellen lässt:</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><span class="math display">\[\text{SSY} = \text{SSE} + \text{SSA}\]</span></p>
<ul>
<li>SSY = <em>Total sum of squares</em></li>
<li>SSE = <em>Error sum of squares</em> (entsprechend der unerklärte Varianz = Residuen)</li>
<li>SSA = <em>Sum of squares attributable to treatment</em> (hier: Sorte)</li>
</ul>
</div>
</div>
</div>
<p>Schauen wir das zunächst beim Blumen-Datensatz an. Dazu müssen wir die Daten, die wir bislang im sogenannten <em>wide format</em> hatten (eine Spalte für Blütengrösse A und eine zweite für Blütengrösse B) im <em>long format</em> bereitstellen (eine Spalte für die Sorte und eine für die Blütengrösse). Generell ist das <em>long format</em> empfehlenswert, da viel universeller und von den meisten statistischen Verfahren verlangt.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(blume.long)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>  cultivar size</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>1        a   20</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>2        a   19</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>3        a   25</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>4        a   10</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>[…]</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>11       b    8</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>12       b   12</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>13       b    9</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Schauen wir uns zunächst noch einmal das Ergebnis als „normalen” t-Test an:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(size<span class="sc">~</span>cultivar, blume.long, <span class="at">var.equal=</span>T)&nbsp;</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>    Two Sample t-test</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>data:  size by cultivar</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>t = 2.0797, df = 18, p-value = 0.05212</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>alternative hypothesis: true difference in means between group a and group b is not equal to 0</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>95 percent confidence interval:</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a> -0.03981237  7.83981237</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>sample estimates:</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>mean in group a mean in group b </span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>           15.3            11.4</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Nun nehmen wir dieselben Daten und analysieren sie mit einer Varianzanalyse. Der Befehl dazu ist aov (was für <em>a</em>nalysis <em>o</em>f <em>v</em>ariance steht). Man kann sich die Ergebnisse der ANOVA mit summary und summary.lm anzeigen lassen und bekommt jeweils unterschiedliche Informationen (die wir beide benötigen):</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">aov</span>(size<span class="sc">~</span>cultivar))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb30"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>            Df Sum Sq Mean Sq F value Pr(&gt;F)  </span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>cultivar     1   76.0   76.05   4.325 0.0521 .</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>Residuals   18  316.5   17.58 &nbsp;</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary.lm</span>(<span class="fu">aov</span>(size<span class="sc">~</span>cultivar))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>[…]</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>            Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>(Intercept)   15.300      1.326   11.54 9.47e-10 ***</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>cultivarb     -3.900      1.875   -2.08   0.0521 . </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Beim ersten Output (summary) sehen wir eine typische „ANOVA-Tabelle” wie man sie als Ergebnis linearer Modelle erhält. Die Bedeutung der Abkürzungen ist wie folgt:</p>
<ul>
<li>Df = <em>Degrees of freedom</em> (Freiheitsgrade)</li>
<li>Sum Sq = <em>Sum of squares</em> (Summe der Abweichungsquadrate)</li>
<li>Mean Sq = <em>Sum of squares / degrees of freedom</em> (Quotient der beiden Werte)</li>
<li>F value = <em>Mean Sq (Treatment) / Mean Sq (Residuals)</em> (Quotient derbeiden mittleren Abweichungsquadrate)</li>
<li>Pr(&gt;F) = <em>Probability to obtaine a more extreme F value under the null hypothesis</em> (<em>p</em>-Wert)</li>
</ul>
<p>Der F-Wert ist das Verhältinis der durch die Variable und die Residuen erklärten Varianzen (<em>Mean squares</em>), also 76.05 / 17.58 = 4.33. Der <em>F</em>-Wert (4.33) entsprichtdem quadrierte <em>t</em>-Wert (–2.08) aus der unteren Tabelle. Der <em>p</em>-Wert (0.052) in der obigen Tabelle ist also genau der gleiche wie im <em>t</em>-Test, was die Äquivalenz von ANOVA und <em>t</em>-Test zeigt. Dieser <em>p</em>-Wert steht für die Nullhypothese, dass sich die beiden Sorten nicht in ihrer Blütengrösse unterscheiden.</p>
<p>Derselbe <em>p</em>-Wert taucht im summary.lm-Output unten in der zweiten Zeile auf. Aber für was steht der extrem kleine p-Wert in der ersten Zeile des summary.lm-Outputs (9.47 x 10<sup>–10</sup>)? In der Zeile steht <em>(Intercept)</em>, also Achsenabschnitt. Hier ist der vorhergesagte Mittelwert für die erste Sorte (Cultivar a) gemeint. Die Nullhypothese zu dieser Zeile ist, dass die Blütengrösse dieser Sorte = 0 ist. Da Blütengrössen immer positive Werte haben (nie negativ und für eine existierende Blüte auch nie 0), ist das keine sinnvolle/relevante Nullhypothese. In den allermeisten Fällen bezieht sich der <em>p</em>-Wert in der ersten Zeile eines summary.lm-Outputs auf eine unsinnige/irrelevante Nullhypothese und wir können/müssen ihn ignorieren. Eine weitere wichtige Information liefert uns die zweite Tabelle aber noch: die Effektgrösse und -richtung. Dazu müssen wir in die Spalte <em>Estimates</em> schauen, welche die sogenannten Parameterschätzungen enthält. Im Falle einer ANOVA enthält die <em>(Intercept)</em>-Zeile den geschätzten Mittelwert für die alphabetisch erste Kategorie (bei uns also Cultivar a), währen das <em>Estimate</em> in der Zeile cultivarb für den Unterschied im Mittelwert von Cultivar b vs.&nbsp;Cultivar a steht, hier steht also die biologisch relevante Information, sprich: die Blüten von Cultivar b sind im Mittel 3.9 cm² kleiner als jene von Cultivar a. Allerdings sind wir uns dieser Aussage nicht besonders sicher, da sie statistisch nur marginal signifikant ist (<em>p</em> = 0.052).</p>
<p>Wenn wir eine «echte» ANOVA mit drei oder mehr Kategorien durchführen, die also nicht mehr mit dem t-Test analysiert werden kann, sieht der Output vergleichbar aus, nur hat sich die Zahl der Freiheitsgrade in der ersten Zeile erhöht (immer Zahl der Kategorien – 1, bei 3 Kategorien also 2).</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">aov</span>(size<span class="sc">~</span>cultivar))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>            Df Sum Sq Mean Sq F value   Pr(&gt;F)    </span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>cultivar     2  736.1   368.0    18.8 7.68e-06 ***</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>Residuals   27  528.6    19.6  </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In diesem Fall gibt es also höchstsignifikante Unterschiede in der Blütengrösse zwischen den drei Sorten. Wir könnten das Ergebnis kurz und prägnant wie folgt wiedergeben:</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Die Blütengrösse unterschied sich höchstsignifikant zwischen den drei Sorten (ANOVA, <em>p</em> &lt; 0.001, <em>F</em><sub>2;27</sub> = 18.8; Abb. 1).</p>
</div>
</div>
</div>
<p><img src="./myMediaFolder/media/image28.png" class="img-fluid"></p>
<p><strong>Abb. 1. Boxplots der Blütengrössen der drei verglichenen Cultivare a, b und c (jeweils <em>n</em> = 10).</strong></p>
<p>Zwei Anmerkungen: (1) Bei drei und mehr Kategorien kann man im Text nicht mehr effizient schreiben, welche Sorte sich wie von welcher anderen unterscheidet, deshalb bietet sich hier eher eine Visualisierung an (sofern die ANOVA signifikant ist). (2) Wenn man den <em>F</em>-Wert angeben möchte, so muss man im Subskript nachgestellt die Freiheitsgrade im Zähler (2) und im Nenner (27) angeben, die man der ANOVA-Tabelle entnehmen kann.</p>
</section>
<section id="post-hoc-test-tukey" class="level3">
<h3 class="anchored" data-anchor-id="post-hoc-test-tukey">Post-hoc-Test (Tukey)</h3>
<p>In der vorhergehenden ANOVA wissen wir nun, dass es insgesamt ein signifikantes Muster gibt, dass also nicht alle drei Sorten der gleichen Grundgesamtheit angehören. Was wir nicht wissen, ist, welche Sorte sich von welcher anderen unterscheidet, und ggf. wie stark. Wenn die ANOVA insgesamt signifikant ist, muss das längst nicht heissen, dass jede Sorte sich von jeder anderen unterscheidet. Nun könnte man auf die Idee kommen, einfach für jedes Sortenpaar einen <em>t</em>-Test durchzuführen. Das Problem ist, dass man dann u. U. ziemlich viele Tests mit denselben Daten macht, und da summieren sich die Typ I-Fehlerraten schnell auf, sprich: bei vielen Tests werden rein zufällig manche ein signifikantes Ergebnis ergeben (mit α = 0.05 wird 5 % Irrtum zugelassen, d.&nbsp;h. im Durchschnitt liefert jeder zwanzigste Test ein falsch-positives Ergebnis). Um diesem Problem Rechnung zu tragen, gibt es sogenannte posthoc-Tests, die nach einer signifikanten ANOVA angewandt werden. Wenn die ANOVA nicht signifkant war, darf dagegen kein posthoc-Test angewandt werden! Der gängigste posthoc-Test ist jener von Tukey und findet sich u. a. im agricolae-Paket:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(agricolae)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>aov<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">aov</span>(size<span class="sc">~</span>cultivar, <span class="at">data=</span>blume2)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb36"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>[…]</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>Comparison between treatments means</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>      difference pvalue signif.        LCL       UCL</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>a - b        3.9 0.1388          -1.006213  8.806213</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>a - c       -8.0 0.0011      ** -12.906213 -3.093787</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>b - c      -11.9 0.0000     *** -16.806213 -6.993787</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Das Ergebnis sagt uns, dass sich c von a und c von b, nicht aber b von a signifikant unterscheiden. Bei nur drei Kategorien kann man das noch so formulieren, bei vier, fünf oder mehr wird es aber schnell langatmig und komplex. Das lässt sich mit sogenannten homogenen Gruppen lösen. Hier versieht man die Kategorien mit gleichen Buchstaben, die sich nicht signifikant voneinander unterscheiden, ggf. kann dann eine Kategorie auch mehrere Buchstaben tragen. In unserem Fall wäre die Lösung also:</p>
<ul>
<li>Cultivar a: A</li>
<li>Cultivar b: A</li>
<li>Cultivar c: B</li>
</ul>
<p>Diese Buchstaben kann man in die Ergebnisabbildung plotten oder als Superskript in einer Ergebnistabelle der Mittelwerte. Die folgende Abbildung zeigt ein Beispiel. Hier unterscheiden sich nur <em>High</em> und <em>Low</em> signifikant voneinander, da dies das einzige Paar ist, das keine gemeinsamen Buchstaben hat:</p>
<p><img src="./myMediaFolder/media/image29.png" class="img-fluid"><br>
(aus Quinn &amp; Keough 2002)</p>
<p>Hier ist noch gezeigt, wie man die Beschriftung in die Boxplots bekommt:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>aov<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">aov</span>(Sepal.Width <span class="sc">~</span> Species, <span class="at">data=</span>iris)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">HSD.test</span>(aov<span class="fl">.2</span>, <span class="st">"Species"</span>, <span class="at">console=</span>T)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb38"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>Treatments with the same letter are not significantly different.</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>           Sepal.Width groups</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>setosa           3.428      a</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>virginica        2.974      b</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>versicolor       2.770      c</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Die Buchstaben aus dem Output muss man dann manuell zur jeweiligen Art plotten (Reihenfolge der Arten beachten!)</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(Sepal.Width <span class="sc">~</span> Species, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">5</span>), <span class="at">data=</span>iris)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">1</span>, <span class="fl">4.8</span>, <span class="st">"a"</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">2</span>, <span class="fl">4.8</span>, <span class="st">"c"</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">3</span>, <span class="fl">4.8</span>, <span class="st">"b"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image30.png" class="img-fluid"></p>
</section>
</section>
<section id="voraussetzung-statistischer-verfahren" class="level2">
<h2 class="anchored" data-anchor-id="voraussetzung-statistischer-verfahren">Voraussetzung statistischer Verfahren</h2>
<p>In Statistik 1 wurde kurz erwähnt, dass jeder statistische Test auf bestimmten Annahmen bezüglich der Werteverteilung in der Grundgesamtheit beruht. Beim klassischen <em>t</em>-Test nach Student sind das die Normalverteilung und die Varianzhomogenität.</p>
<section id="parametrische-vs.-nicht-parametrische-verfahren" class="level3">
<h3 class="anchored" data-anchor-id="parametrische-vs.-nicht-parametrische-verfahren">Parametrische vs.&nbsp;nicht-parametrische Verfahren</h3>
<p>Verfahren, die auf dem folgenden gängigen Set von Voraussetzungen beruhen, werden als <strong>parametrische Verfahren</strong> bezeichnet. Es sind dies zugleich die <strong>„linearen Modelle”</strong> (doch zu diesem Begriff später mehr):</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ol type="1">
<li>Normalverteilung der <em>Residuen</em></li>
<li>Varianzhomogenität</li>
<li>Feste <em>x</em>-Werte</li>
<li>Unabhängigkeit der Beobachtungen / Zufällige Beprobung</li>
</ol>
</div>
</div>
</div>
<p>Dem gegenüber gestellt werden so-genannte „nicht-parametrische” Verfahren. Der Begriff ist allerdings sehr irreführend, da nicht-parametrische Verfahren nicht etwa keine Voraussetzungen haben, sondern meist nur geringfügig schwächere als parametrische Verfahren. Die <strong>Voraussetzungen für die Anwendung gängiger nicht-parametrischer Verfahren</strong> sind:</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ol type="1">
<li>Die Verteilung der Residuen kann einer beliebigen Funktion folgen, muss aber für die verschiedenen Faktorlevels (Kategorien) gleich sein</li>
<li>Feste <em>x</em>-Werte</li>
<li>Unabhängigkeit der Beobachtungen / Zufällige Beprobung</li>
</ol>
</div>
</div>
</div>
<p>Diese beiden Listen, weisen auf zwei weitverbreitete Irrtümer in der Statistik hin, die in älteren Statistikbüchern regelmässig falsch dargestellt wurden und die auch heute noch in Statistikursen an Hochschulen oft falsch gelehrt werden:</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>Nur die Residuen des statistischen Models sollten normalverteilt sein. Dagegen ist es gleichgültig, ob die Werte der abhängigen Variablen normalverteilt sind und erst recht gilt das für die unabhängigen Variablen.</li>
<li>Die Varianzhomogenität ist wichtiger als Normalverteilung der Residuen.</li>
<li>Die naive Empfehlung, bei kleinsten Abweichungen von der Varianzhomogenität oder Normalverteilung auf ein nicht-parametrisches Äquivalent auszuweichen, ist im besten Fall unvorteilhaft (da nicht-parametrische Verfahren meist eine geringere Teststärke haben), im schlimmsten Fall falsch (wie die Voraussetzungen des nicht-parametrischen Verfahrens gleichermassen verletzt sind).</li>
</ul>
</div>
</div>
</div>
<p>In der Folge ist zu beobachten, dass vielfach vorschnell und unnötig auf „nicht-parametrische” Verfahren ausgewichen wird. <strong>Dagegen sprechen viele Gründe dafür, in fast allen Fällen mit parametrischen Verfahren zu arbeiten</strong>:</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li><p>Parametrische Verfahren sind recht robust gegen die Verletzung der Voraussetzung, d.&nbsp;h. sie liefern selbst recht starken Abweichungen noch (fast) korrekte <em>p</em>-Werte:</p>
<p>Laut Quinn &amp; Keough (2002) haben Simulationen Folgendes gezeigt:</p>
<ul>
<li><em>n</em><sub>1</sub> = <em>n</em><sub>2</sub> = 6: selbst bei bis zu vierfacher SD noch korrekte <em>p</em>-Werte</li>
<li><em>n</em><sub>1</sub> = 11, <em>n</em><sub>2</sub> = 21: Wenn SD<sub>1</sub> = 4 SD<sub>2</sub>, dann entspricht ein berechneter <em>p</em> = 0.05 in Wirklichkeit <em>p</em> = 0.16</li>
</ul>
<p>mit n1 und n2 = Stichprobengrösse für Faktorlevels 1 und 2 und SD = Standardabweichung</p></li>
<li><p>Die meisten komplexeren statistischen Verfahren existieren ohnehin nur in einer parametrischen Variante.</p></li>
<li><p>Dank Datentransformationen und Generalisierungen linearer Modelle kann man auch mit Nicht-Normalität der Residuen und Varianzinhomogenität = Heteroskedasitzität umgehen.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="wie-testet-man-die-voraussetzungen-klassischer-weg" class="level3">
<h3 class="anchored" data-anchor-id="wie-testet-man-die-voraussetzungen-klassischer-weg">Wie testet man die Voraussetzungen? (klassischer Weg)</h3>
<p>Der <strong>„klassische” (aber nicht zielführende!!!)</strong> Rat in vielen Statistikbüchern/-kursen ist die Anwendung statistischer Tests für Normalität und Varianzhomognität. Für die Normalität (beachten, dass die Residuen, nicht dir Rohdaten getestet werden müssen, also im Fall einer ANOVA die Werte jeder Kategorie für sich). Es gibt u.a. den Kolmogorov-Smirnov-Test (mit Lillefors-Korrektur) und den Sharpiro-Wilks-Test:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(blume<span class="sc">$</span>b)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Für das Testen der Varianzhomogenität gibt es u.a. den <em>F</em>-Test zur Varianzhomogenität und den Levene-Test (im Paket car):</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var.test</span>(blume<span class="sc">$</span>a, blume<span class="sc">$</span>b)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="fu">leveneTest</span>(blume<span class="sc">$</span>a, blume<span class="sc">$</span>b,<span class="at">center =</span> mean)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wenn die <em>p</em>-Werte dieser Tests &lt; 0.05 sind, dann liegt eine statistisch signifikante Abweichung von der jeweiligen Voraussetzung vor. Die klassische Konsequenz war, dann auf ein nicht-parametrisches Verfahren auszuweichen. Studierende und viele PraktikerInnen lieben diese scheinbar simple Schwarz-weiss-Sicht, die ein klares Prozedere vorzugeben scheint. Leider bringen diese Tests für die Entscheidung zwischen parametrischen und nicht-parametrischen Verfahren NICHTS. Die Gründe sind eigentlich einfach:</p>
<ul>
<li>Die genannten Tests testen allesamt die Wahrscheinlichkeit der Abweichung, nicht den Grad der Abweichung (wobei Letzteres der relevante Punkt ist).</li>
<li>Damit werden einerseits bei kleinen Stichproben auch problematische Abweichungen nicht erkannt, bei grossen Stichproben harmlose Abweichungen dagegen „moniert” (man sollte sich bewusst sein, dass Variablen in der realen Welt niemals perfekt normalverteilt oder perfekt varianzhomogen sind)</li>
</ul>
<p>Deshalb wird in modernen Lehrbüchern ausdrücklich davon abgeraten, die genannten Tests für diesen Zweck zu verwenden (z.&nbsp;B. Quinn &amp; Keough 2002).</p>
</section>
<section id="wie-testet-man-die-voraussetzungen-empfohlener-weg" class="level3">
<h3 class="anchored" data-anchor-id="wie-testet-man-die-voraussetzungen-empfohlener-weg">Wie testet man die Voraussetzungen? (empfohlener Weg)</h3>
<p>Da die „klassischen” numerischen Tests nichts helfen, bleibt nur ein Weg, selbst wenn er zunächst unbefriedigend und subjektiv erscheinen mag. Moderne statistische Lehrbücher empfehlen heute, Normalverteilung der Residuen und Varianzhomogenität visuell zu prüfen und nur bei groben Verletzungen über Gegenmassnahmen nachzudenken.</p>
<p>Im Fall von <em>t</em>-Tests bzw. ANOVAs ist die einfachste Möglichkeit, nach Faktorlevels gruppierte Boxplots zu betrachten. Alternativ gingen auch Histogramme, allerdings sind diese nur bei grossen <em>n</em> aussagekräftig:</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="./myMediaFolder/media/image31.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="./myMediaFolder/media/image32.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="./myMediaFolder/media/image33.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>Für die <strong>Beurteilung der Varianzhomogenität</strong> betrachtet man am besten die Höhe der Boxen im Boxplot. Wenn sie ähnlich hoch sind, ist alles OK, wenn sie sehr stark abweichen, hat man evtl. ein Problem. Sehr stark meint aber, siehe oben, wirklich sehr stark, d.&nbsp;h. wenn die Box in einer Kategorie mehr als 4-mal so hoch ist wie in einer anderen (bei gleichen/ähnlichen Replikatzahen), und ab mehr als doppelt so hoch bei erheblich verschiedenen Replikatzahlen. Im vorliegenden Fall ist die Varianz in Gruppe 1 etwa 2.5-mal so hoch wie in Gruppe 2, da die Zahl der Replikate aber identisch war, wäre das noch OK.</p>
<p>Zur <strong>Beurteilung der Normalverteilung</strong> bzw. des entscheidenden Aspekts der Normalverteilung, der Symmetrie, sind ebenfalls die Boxplots aufschlussreich. Eine starke Verletzung liegt vor, wenn der Median weit ausserhalb der Mitte der Box liegt oder wenn der obere «whisker» viel länger als der untere ist.</p>
<p>Ausserdem gibt es noch das <strong><em>Central Limit Theorem</em> (CLT)</strong> in der Statistik. Dieses Theorem besagt, dass wenn eine betrachtete Variable selbst schon ein Mittelwert ist, sie zwingend einer Normalverteilung folgt. In diesem Fall ist also gar kein Test nötig/sinnvoll. Wenn man sich auf das CLT berufen will, kann man z. B. Quinn &amp; Keough (2002) zitieren.</p>
</section>
<section id="was-tun-wenn-die-voraussetzungen-verletzt-sind-nicht-parametrische-verfahren" class="level3">
<h3 class="anchored" data-anchor-id="was-tun-wenn-die-voraussetzungen-verletzt-sind-nicht-parametrische-verfahren">Was tun, wenn die Voraussetzungen verletzt sind? (nicht-parametrische Verfahren)</h3>
<p>Bei Verletzung der Voraussetzungen, kann man auf nicht-parametrische Verfahren ausweichen, was OK ist, wenn man sich völlig klar darüber ist, welche Voraussetzungen diese ihrerseits haben:</p>
<p>Das nicht-parametrische Äquivalent zum <em>t</em>-Test ist der <strong>Wilcoxon-Rangsummen-Test</strong>. Er funktioniert, indem Werte in Ränge transformiert und summiert werden (W-statistic). Nachteile sind, dass er sehr konservativ ist (d.&nbsp;h. tendenziell zu hohe <em>p</em>-Werte schätzt) und zudem keine exakten <em>p</em>-Werte berechnen kann, wenn „Bindungen” (<em>ties</em>) vorliegen (d.&nbsp;h. mehrere Beobachtungen identische Werte aufweisen). Ausserdem sei noch einmal betont, dass der Wilcoxon-Test zwar keine Annahme über die Verteilung der Werte pro Gruppe macht, jedoch voraussetzt, dass diese in jeder Gruppe gleich ist.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wilcox.test</span>(blume<span class="sc">$</span>a, blume<span class="sc">$</span>b)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Ferner gibt es <strong>Randomisierungs-<em>t</em>-Tests</strong>. Diese haben den Vorteil, dass keine Annahme über die Verteilung getroffen werden muss (die Verteilung wird aus den Daten generiert). Zugleich müssen die Beobachtungen noch nicht einmal unabhängig sein. Allerdings testet man hier strenggenommen auch nicht auf Unterschiede in den Grundgesamtheiten, sondern ermittelt die Wahrscheinlichkeit, die beobachteten Unterschiede zufällig erzielt zu haben. Wer mehr über Randomisierungs-Tests wissen will, findet in Logan (2010: 148–150) weitergehende Infos.</p>
<p>Im Fall der ANOVA gibt es zwei Situationen:</p>
<ol type="1">
<li><p>Wir haben starke <strong>Abweichungen von der Normalverteilung</strong> der Residuen, aber <strong>ähnliche Varianzen</strong>. Dann kann der Kruskal-Wallis-Test zum Einsatz kommen (ebenfalls ein Rangsummen-Test). Der zugehörige posthoc-Test ist der Dunn-Test mit Benjamin-Hochberg-Korrektur der <em>p</em>-Werte (wegen multiplem Testen):</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">kruskal.test</span>(<span class="at">data =</span> blume2, size<span class="sc">~</span>cultivar)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(FSA)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="fu">dunnTest</span>(<span class="at">data =</span> blume2, size<span class="sc">~</span>cultivar, <span class="at">method =</span> <span class="st">"bh"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Wenn dagegen die <strong>Varianzen sehr heterogen</strong> sind, die <strong>Residuen aber relativ normal/symmetrisch</strong>, wie in der folgenden Abbildung, kann der <strong>Welch-Test</strong> eingesetzt werden:</p></li>
</ol>
<p><img src="./myMediaFolder/media/image28.png" class="img-fluid"></p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">oneway.test</span>(<span class="at">data=</span>blume2, size<span class="sc">~</span>cultivar, <span class="at">var.equal=</span>F)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="was-tun-wenn-die-voraussetzungen-verletzt-sind-transformationen" class="level3">
<h3 class="anchored" data-anchor-id="was-tun-wenn-die-voraussetzungen-verletzt-sind-transformationen">Was tun, wenn die Voraussetzungen verletzt sind? (Transformationen)</h3>
<p>Statt auf nicht-parametrische Verfahren auszuweichen, kann man auch Transformationen anwenden. Da es um die Verteilung der Residuen geht, muss primär die abhängige Variable für Transformationen in Betracht gezogen werden, manchmal hilft aber auch die Transformation einer unabhängigen Variablen (weitergehende Infos siehe Fox &amp; Weisberg 2019: 161–169).</p>
<p>Wenn man über die Anwendung von Transformationen nachdenkt, sind zwei Aspekte relevant: (1) Entgegen manchen Behauptungen sind untransformierte Daten (linear Skala) nicht <em>per se</em> natürlicher/richtiger. Auch die lineare Skala ist eine Konvention. Viele Naturgesetze (z. B. unsere Sinneswahrnehmung) funktionieren dagegen auf einer Logarithmusskala. (2) Wenn man die abhängige Variable transformiert, muss man sich aber klar darüber sein, dass man dann strenggenommen Hypothesen über die transformierten Daten, nicht über die ursprünglichen Werte testet. Achtung: Wenn man die Analysen mit tranformierten Daten durchführt, darf man <strong>für die Ergebnisdarstellung die Rücktransformation mittels der jeweiligen Umkehrfunktion</strong> nicht vergessen!</p>
<p>Gängige Transformation für die abhängige Variable sind die folgenden:</p>
<p><strong>Logarithmus-Transformation:</strong></p>
<ul>
<li>Gut bei rechtsschiefen Daten/wenn die Varianz mit dem Mittelwert zunimmt.</li>
<li>Die „natürlichste” Transformation.</li>
<li>Natürlicher Logarithmus (log) oder Zehnerlogarithmus (log10) möglich.</li>
<li>Werte müssen &gt; 0 sein.</li>
</ul>
<p><strong>log (<em>x</em> + Konstante)-Transformation:</strong></p>
<ul>
<li>Findet man häufig in der Literatur, wenn abhängige Variablen transformiert werden sollen, die auch Nullwerte enthalten</li>
<li>Es werden unterschiedliche Konstanten (<em>x</em>) addiert, mal 1, mal 0.01. Es ist aber völlig willkürlich, ob man 1000000 oder 0.00000001 oder 3.24567 addiert, hat aber starken Einfluss auf die Ergebnisse</li>
<li>Auch lassen sich die Ergebnisse nach so einer komplexen Transformation schlecht interpretieren (da man dann ja eine Hypothese über die transformierten Daten testet, s.&nbsp;o.)</li>
<li>In Übereinstimmung mit Wilson (2007) rate ich daher dringend von derlei Transformationen ab!</li>
</ul>
<p><strong>Wurzeltransformation:</strong></p>
<ul>
<li>Hat einen ähnlichen Effekt wie die Logarithmus-Transformation, lässt sich im Gegensatz zu dieser auch beim Vorliegen von Nullwerten anwenden (Werte müssen nur positiv sein).</li>
<li>Die „Stärke” der Transformation kann man durch die Art der Wurzel kontinuierlich einstellen: Quadratwurzel, Kubikwurzel, 4. Wurzel,…</li>
</ul>
<p><strong>„arcsine”-Transformation:</strong></p>
<p><code>asin(sqrt(x))\*180/pi</code></p>
<ul>
<li>Wurde traditionell für Prozentwerte (Proportionen) und andere abhängige Variablen empfohlen, die zwischen 0 und 1 bzw. 0 und 100% begrenzt sind (z. B. Quinn &amp; Keough 2002).</li>
<li>Nach neueren Untersuchungen (Warton &amp; Hui 2011) wird eher davon abgeraten.</li>
</ul>
<p><strong>Rangtransformation:</strong></p>
<ul>
<li>Im Prinzip das, was „nicht-parametrische” Verfahren machen.</li>
<li>Grösster Informationsverlust von allen genannten Verfahren (noch grösser wäre der Informationsverlust nur bei Überführung der metrischen abhängigen Variablen in Kategorien oder gar in eine Binärvariable).</li>
</ul>
<p>Die folgenden Abbildungen visualisieren exemplarisch die Effekte unterschiedlicher Transformationen auf die Werteverteilung (ganz links sind jeweils die untransformierten Daten, die Transformation rechts hat jeweils eine deutlich bessere Annäherung an die Normalverteilung erzielt).</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<p><img src="./myMediaFolder/media/image34.png" class="img-fluid"> <img src="./myMediaFolder/media/image35.png" class="img-fluid"> <img src="./myMediaFolder/media/image36.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>(aus Quinn &amp; Keough 2002)</p>
<p>Meist muss man nur die abhängige Variable transformieren. Es gibt aber Spezialfälle, wo man erst nach Transformation der abhängigen und der unabhängigen Variable eine adäquate Residuenverteilung erzielt. Dies ist insbesondere dann der Fall, wenn wir eine in Wirklichkeit nicht-lineare Beziehung mit einem linearen Modell abbilden. Wenn etwa im Falle einer einfachen linearen Regression (s.&nbsp;u.) in Wirklichkeit ein Potenzgesetz (<em>y</em> = <em>a x<sup>b</sup></em>) vorliegt, erzielt man näherungsweise Varianzhomogenität und Normalverteilung der Residuen nur, wenn man a und b logarithmustransformiert.</p>
</section>
</section>
<section id="mehrfaktorielle-anova" class="level2">
<h2 class="anchored" data-anchor-id="mehrfaktorielle-anova">Mehrfaktorielle ANOVA</h2>
<p>Bislang haben wir uns eine ANOVA mit nur einem Prädiktor, d.&nbsp;h. einer kategorialen Variablen mit zwei bis vielen Ausprägungen, angeschaut. Das Prinzip lässt sich aber auch auf zwei und mehr kategoriale Prädiktoren ausweiten. Man spricht dann von einer <strong>mehrfaktoriellen ANOVA</strong>. Im Optimalfall sollten alle Kombinationen Faktorlevels aller Prädiktorvariablen auftreten (dann spricht man von einem <strong>vollfaktoriellen Design</strong>), am besten sogar in gleicher/ähnlicher Häufigkeit.</p>
<p>Betrachten wir exemplarisch die Situation mit zwei Prädiktoren (zweifaktorielle Varianzanalyse, <em>two-way ANOVA</em>). Hierzu haben wir in unserem Blumenbeispiel neben den drei Sorten noch ein weiteres „Treatment” hinzugefügt, nämlich, ob die Pflanzen im Gewächshaus (house = yes) oder im Freiland (house = no) aufgezogen wurden. Der Boxplot in der explorativen Datenanalyse sieht wie folgt aus:</p>
<p><img src="./myMediaFolder/media/image37.png" class="img-fluid"></p>
<p>Wir haben nun zwei Möglichkeiten, die zweifaktorielle Varianzanalyse durchzuführen, <strong>mit oder ohne Berücksichtigung von Interaktionen</strong>:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">aov</span>(size<span class="sc">~</span>cultivar<span class="sc">+</span>house))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb46"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>            Df Sum Sq Mean Sq F value   Pr(&gt;F)    </span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>cultivar     2  417.1   208.5   5.005     0.01 *  </span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>house        1  992.3   992.3  23.815 9.19e-06 ***</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>Residuals   56 2333.2    41.7     </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">aov</span>(size<span class="sc">~</span>cultivar<span class="sc">*</span>house))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb48"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>               Df Sum Sq Mean Sq F value   Pr(&gt;F)    </span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>cultivar        2  417.1   208.5   5.364   0.0075 ** </span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>house           1  992.3   992.3  25.520 5.33e-06 ***</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>cultivar:house  2  233.6   116.8   3.004   0.0579 .  </span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>Residuals      54 2099.6    38.9     </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Ohne Interaktion (oben) verknüpfen wir die beiden Prädiktoren einfach mit „+“; wenn wir die Interaktion auch analysieren wollen (unten), dann verwenden wir „*” zur Verknüpfung. Ein Interaktion läge dann vor, wenn sich die Auswirkung von Gewächshaus vs.&nbsp;Freiland zwischen den Sorten unterschiede, etwa in einem Fall positiv, im anderen neutral oder negativ. Wir sehen, dass die untere ANOVA mit dem Interaktionsterm im Output eine dritte Zeile cultivar:house enhält, welcher die Signifikanz der Interaktion angibt (in unserem Fall also marginal signifikant).</p>
<p>Liegt eine signifikante Interaktion vor, dann nimmt man zur Ergebnisdarstellung am besten eine Grafik, einen sogenannten Interaktionsplot, da sich die Interaktion schon bei zweifaktoriellen ANOVAs schwer in Worte fassen lässt und noch schwerer bei dreifaktoriellen ANOVAs mit potenziell einer Dreifachinteraktion und drei Zweifachinteraktionen:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">interaction.plot</span>(cultivar,house,size)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image38.png" class="img-fluid"></p>
<p>Die Interaktion war nicht signifikant, was sich darin zeigt, dass die Linienzüge für yes und no einigermassen parallel sind, d.&nbsp;h. im Gewächshaus alle drei Kultivare grösser waren. Allerdings haben sich die drei Kultivare nicht völlig konsistent verhalten: der positive Einfluss von Gewächshaus war bei Sorte c viel grösser als bei den anderen beiden (was zu einem <em>p</em>-Wert der Interaktion nahe an der Signifikanzschwelle geführt hat).</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisierung 2-fach-Interaktion etwas elaborierter </span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># mit ggplot</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjPlot)</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_classic</span>())</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>aov <span class="ot">&lt;-</span> <span class="fu">aov</span>(size <span class="sc">~</span> cultivar <span class="sc">*</span> house, <span class="at">data =</span> blume3)</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(aov, <span class="at">type =</span> <span class="st">"pred"</span>, <span class="at">terms =</span> <span class="fu">c</span>(<span class="st">"cultivar"</span>, <span class="st">"house"</span>) )</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image39.png" class="img-fluid"></p>
<p>Mit sjPlot kann man auch gut 3-fach-Interaktionen visualisieren, wie das folgende Beispiel zur Auswirkung von Managment und Hirschbeweidung (fenced = keine Hirsche) über zwei Versuchsjahre auf den Pflanzenartenreichtum zeigt:</p>
<p><img src="./myMediaFolder/media/image40.png" class="img-fluid"></p>
<div class="sourceCode" id="cb51"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>aov.deer &lt;- aov(Species.richness ~ Year * Treatment * Plot.type, data = Riesch)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>plot_model(aov.deer, type = "pred", terms = c("Year", "Treatment", "Plot.type"))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="korrelationen" class="level2">
<h2 class="anchored" data-anchor-id="korrelationen">Korrelationen</h2>
<p><strong>Pearson-Korrelationen</strong> analysieren den Zusammenhang zwischen zwei metrischen Variablen** und beantworten dabei die folgenden Fragen:</p>
<ul>
<li>Gibt es einen <strong>linearen</strong> Zusammenhang?</li>
<li>In welche Richtung läuft er?</li>
<li>Wie stark ist er?</li>
</ul>
<p>Wichtig dabei ist, dass Korrelationen keine Kausalität voraussetzen oder annehmen. Es gibt also keine abhängige und unabhängige Variable, keine Unterscheidung in Prädiktor- und Antwortvariable. Logischerweise liefern Korrelationen dann auch identische Ergebnisse, wenn <em>x</em>- und <em>y-</em>Achse vertauscht werden.</p>
<p>Die folgenden fünf Abbildungen zeigen verschiedene Situationen. Bei (a) liegt eine positive Korrelation vor, bei (b) eine negative und bei (c)–(e) keine Korrelation. Bei (e) erkennt man zwar visuell eine Beziehung (ein «Peak» in der Mittel, also eine unimodale Beziehung), aber das ist eben kein linearer Zusammenhang.</p>
<p><img src="./myMediaFolder/media/image41.png" class="img-fluid"></p>
<p>(aus Quinn &amp; Keough 2002)</p>
<p>Bei der Pearson-Korrelation betrachtet man die beiden Parameter Kovarianz (reicht von −∞ bis +∞) und die Korrelation, welche die Covarianz auf den Bereich von –1 bis +1 standardisiert. Pearsons Korrelationskoeffizient r ist der Schätzer für die Korrelation basierend auf der Stichprobe:</p>
<p><img src="./myMediaFolder/media/image42.png" class="img-fluid"><br>
<br>
(aus Quinn &amp; Keough 2002)</p>
<p>Die implizite Nullhypothese (H<sub>0</sub>) ist nun ρ = 0. Die Teststatistik ist das uns schon bekannte <em>t</em> mit <span class="math inline">\(t = \ \frac{r}{s_{r}}\)</span> , wobei <em>s<sub>r</sub></em> für den Standardfehler von <em>r</em> steht und bei <em>n</em> – 2 Freiheitsgraden gestet wird.</p>
<p>Die Pearson-Korrelation ist die „parametrische” Variante der Korrelationen. Ihre Anwendung hat zwei Voraussetzungen (in Klammern ist angegeben, wie man ihr Vorliegen visuell überprüfen kann):</p>
<ul>
<li><p>Linearität (Überprüfung mit einem <em>xy</em>-Scatterplot)</p></li>
<li><p>Bivariate Normalverteilung (Überprüfung mit Boxplots beider Variablen)</p></li>
</ul>
<p>Wenn diese Voraussetzungen ungenügend erfüllt sind, kann man auf nicht-parametrische Äquivalente ausweichen. Diese testen auf monotone, nicht auf lineare Beziehungen, liefern allerdings keine exakten Ergebnisse bei Bindungen (d.h. wenn der gleiche Wert mehrfach vorkommt):</p>
<ul>
<li><p>Für 7 ≤ <em>n</em> ≤ 30: <strong>Spearman-Rang-Korrrelation (<em>r<sub>s</sub></em>)</strong><br>
(im Prinzip Pearsons <em>r</em> für rangtransformierte Daten)</p></li>
<li><p>Für <em>n</em> &gt; 30: <strong>Kendall’s tao (τ)</strong></p></li>
</ul>
<p>Hier noch der R Code für alle drei Möglichkeiten:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>cor.test(df$Species.richness, df$N.deposition, method = "pearson")</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>cor.test(df$Species.richness, df$N.deposition, method = "spearman")</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>cor.test(df$Species.richness, df$N.deposition, method = "kendall")</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="einfache-lineare-regressionen" class="level2">
<h2 class="anchored" data-anchor-id="einfache-lineare-regressionen">Einfache lineare Regressionen</h2>
<section id="idee" class="level3">
<h3 class="anchored" data-anchor-id="idee">Idee</h3>
<p>Einfache lineare Regressionen sind konzeptionell und mathematisch ähnlich zu Pearson-Korrelationen. Oft werden beide Verfahren daher fälsch auch begrifflich durcheinandergeworfen. Der <strong>entscheidende Unterschied</strong> ist, dass wir für eine Regression eine <strong>theoretisch vermutete Kausalität</strong> haben müssen. Damit haben wir, anders als bei einer Korrelation, eine fundamentalte Unterscheidung in:</p>
<ul>
<li><p><strong><em>X</em>: unabhängige Variable</strong> (<em>independent variable</em>), Prädiktorvariable (<em>predictor</em>)</p></li>
<li><p><strong><em>Y</em>: abhängige Variable</strong> (<em>dependent variable</em>), Antwortvariable (<em>response</em>)</p></li>
</ul>
<p>Bei Visualisierungen ist zu beachten, dass die unabhängige Variable immer auf der <em>x</em>-Achse dargestellt wird, die abhängige dagegen auf der nach oben gerichteten <em>y</em>-Achse.</p>
<p>Mathematisch wird eine lineare Regression analysiert, indem die bestangepasste Gerade durch die Punktwolke des <em>xy</em>-Scatterplots gelegt wird. Dabei sieht das lineare Modell folgendermassen aus:</p>
<ul>
<li><strong>Geradengleichung:</strong> <em>y</em> = <em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em></li>
<li><strong>Statistisches Modell:</strong> <em>y<sub>i</sub></em> = β<sub>0</sub> + β<sub>1</sub> <em>x</em><sub>i</sub> + ε<sub>i</sub>, wobei ε<sub>i</sub> das Residuum des <em>i</em>-ten Daten­punktes ist, d.&nbsp;h. seine vertikale Abweichung vom vorhergesagten Wert</li>
</ul>
<p>Mit einer einfachen linearen Regression testet man die folgenden beiden Nullhypothesen:</p>
<ul>
<li><p>H<sub>0</sub>: <strong>β<sub>0</sub> = 0 (Achsenabschnitt [<em>intercept</em>] der Grundgesamtheit ist Null)</strong> (diese erste Nullhypothese ist, ähnlich wie bei Varianzanalysen, in den meisten Fällen wissenschaftlich nicht relevant)</p></li>
<li><p>H<sub>0</sub>: <strong>β<sub>1</sub> = 0 (Steigung [<em>slope</em>] der Grundgesamtheit ist Null)</strong></p></li>
</ul>
<p>Die folgende Abbildung veranschaulicht die verschiedenen Möglichkeiten:</p>
<p><img src="./myMediaFolder/media/image43.png" class="img-fluid"><br>
(aus Logan 2010)</p>
</section>
<section id="statistische-umsetzung" class="level3">
<h3 class="anchored" data-anchor-id="statistische-umsetzung">Statistische Umsetzung</h3>
<p>Es mag vielleicht zunächst überraschen, aber ähnlich wie beim Vergleich von Mittelwerten zwischen kategorischen Ausprägungen kategorischer Variablen, liegt auch der linearen Regression eine <strong>Varianzanalyse</strong> zugrunde:</p>
<p><img src="./myMediaFolder/media/image44.png" class="img-fluid"><img src="./myMediaFolder/media/image45.png" class="img-fluid"><br>
<br>
(aus Quinn &amp; Keough 2002)</p>
<p>Wiederum ist die Teststatistik ein <em>F</em>-ratio, nämlich <em>F</em> = MS<sub>Regression</sub> / MS<sub>Residual</sub>, wobei MS für die mittleren Quadratsummen steht, also die Quadratsummen (SS) geteilt durch die Freiheitsgrade (df). Wie oben unter der Varianzanalyse schon erwähnt, folgt <em>F</em> einer <em>t</em>²-Verteilung.</p>
</section>
<section id="implementierung-in-r" class="level3">
<h3 class="anchored" data-anchor-id="implementierung-in-r">Implementierung in R</h3>
<p>Das Kommando zum Berechnen einfacher linearer Regressionen lautet lm. Wie bei einem Mittelwertvergleich mittels Varianzanalyse gibt es dann zwei verschiedene Ansichten des Ergebnis-Outputs, die jeweils verschiedene Teilaspekte zeigen (Hier am Beispiel der Beziehung von Pflanzenartenreichtum zur Stickstoffdeposition):</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Species.richness<span class="sc">~</span>N.deposition, <span class="at">data =</span> df)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(lm) <span class="co">#ANOVA-Tabelle, 1. Möglichkeit</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary.aov</span>(lm) <span class="co">#ANOVA-Tabelle, 2. Möglichkeit</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb54"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>Response: Species.richness</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>             Df Sum Sq Mean Sq F value    Pr(&gt;F)    </span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>N.deposition  1 233.91 233.908  28.028 0.0001453 ***</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>Residuals    13 108.49   8.346 </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Die anova-Ansicht liefert uns die oben besprochene ANOVA-Tabelle, einschliesslich der Signifikanz der Steigung (hier <em>p</em> = 0.0001). Weitere erforderliche Aspekte des Ergebnisses sehen wir in der summary-Ansicht:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm) <span class="co">#Regressionskoeffizienten</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb56"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>(Intercept)  25.60502    1.26440  20.251 3.25e-11 ***</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>N.deposition -0.26323    0.04972  -5.294 0.000145 ***</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>[…]</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>Residual standard error: 2.889 on 13 degrees of freedom</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>Multiple R-squared:  0.6831,    Adjusted R-squared:  0.6588 </span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>F-statistic: 28.03 on 1 and 13 DF,  p-value: 0.0001453</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wie wir sehen, tauchen wiederum der <em>F</em>-Wert (28.03) und sogar zweimal der <em>p</em>-Wert der Steigung (0.0001) auf, daneben auch der i.&nbsp;d.&nbsp;R. bedeutungslose <em>p</em>-Wert des Achsenabschnitts (<em>intercept</em>) (3.25 x 10<sup>-11</sup>).</p>
<p>Werfen wir noch einmal einen Blick auf den Output von R:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>(Intercept)  25.60502    1.26440  20.251 3.25e-11 ***</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>N.deposition -0.26323    0.04972  -5.294 0.000145 ***</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>[…]</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>Residual standard error: 2.889 on 13 degrees of freedom</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>Multiple R-squared:  0.6831,    Adjusted R-squared:  0.6588 </span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>F-statistic: 28.03 on 1 and 13 DF,  p-value: 0.0001453</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wir benötigen</p>
<ol type="1">
<li><strong>Name des Verfahrens (Methode)</strong>: Einfache lineare Regression (mit der Methode der kleinsten Quadrate).</li>
<li><strong>Signifikanz (Verlässlichkeit des Ergebnisses)</strong>: <em>p</em>-Wert der Steigung, nicht der <em>p</em>-Wert des Achsenabschnittes (wird nach üblicher Konvention auf drei Nachkommastellen gerundet oder, wenn unter 0.001, dann als <em>p</em> &lt; 0.001 angegeben).</li>
<li><strong>Effektgrösse und -richtung (unser eigentliches Ergebnis!)</strong>: Im Falle einer linearen Regression ist das die Funktionsgleichung, die sich aus den Schätzungen der Koeffizienten ergibt.</li>
<li><strong>Erklärte Varianz (Relevanz des Ergebnisses)</strong>: Wie viel der Gesamtvariabilität der Daten wird durch das Modell erklärt? Ob <em>R</em>² oder <em>R</em>²<sub>adj.</sub> angegeben werden sollte, wird unterschiedlich gesehen, jedenfalls sollte man explizit sagen, was gemeint ist. <em>R</em>² ist übrigens der quadrierte Wert von Pearsons Korrelationskoeffizienten <em>r</em>.</li>
<li><strong>ggf. Wert der Teststatistik mit denFreiheitsgraden(„Zwischenergebnisse”)</strong>: <em>F</em><sub>1,8</sub> = 11.34.</li>
</ol>
<p>Ein adäquater Ergebnistext könnte daher wie folgt lauten:</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Die Variable <em>b</em> nahm hochsignifikant mit der Variablen <em>a</em> zu (Funktionsgleichung: <em>b</em> = 5.02 + 0.42 *<em>a</em>, <em>F</em><sub>1,8</sub> = 11.34, <em>p</em> =0.010, <em>R</em>² = 0.586).</p>
</div>
</div>
</div>
<p>Bei einem signifkanten Ergebnis bietet sich auch noch eine Visualisierung mittels Scatterplot an, in den die Regressionsgerade geplottet ist:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(b<span class="sc">~</span>a,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">25</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">20</span>))</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(b<span class="sc">~</span>a))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image46.png" class="img-fluid"></p>
</section>
<section id="voraussetzungen" class="level3">
<h3 class="anchored" data-anchor-id="voraussetzungen">Voraussetzungen</h3>
<p>Einfache lineare Regressionen basieren auf drei Vorausetzungen:</p>
<ol type="1">
<li><strong>Linearität</strong></li>
<li><strong>Normalverteilung</strong> (der Residuen!)</li>
<li><strong>Varianzhomogenität</strong></li>
</ol>
<p>Für das meistverwendete <strong>Verfahren der kleinsten Abweichungsgquadrate</strong> (wie bislang besprochen; <strong><em>ordinary least squares</em> = OLS</strong>), auch als <strong>Modell I-Regressionen</strong> bezeichnet, muss zudem gelten:</p>
<ol start="4" type="1">
<li><p><strong>Feste <em>x</em>-Werte</strong>, d.&nbsp;h.</p>
<ul>
<li><em>x</em>-Werte vom Experimentator gesetzt ODER</li>
<li>Fehler in den <em>x</em>-Werten viel kleiner als in den <em>y</em>-Werten</li>
</ul>
<p><strong>Sowie auch für folgende Fälle</strong>:</p>
<ul>
<li>Hypothesentest H<sub>0</sub>: β<sub>1</sub> = 0 im Fokus, nicht der exakte Wert vonβ~1</li>
<li>Für prädiktive Modelle</li>
<li>Wenn keine bivariate Normalverteilung vorliegt</li>
</ul></li>
</ol>
</section>
<section id="alternativen-zur-methode-der-kleinsten-quadrate-ols" class="level3">
<h3 class="anchored" data-anchor-id="alternativen-zur-methode-der-kleinsten-quadrate-ols">Alternativen zur Methode der kleinsten Quadrate (OLS)</h3>
<p>Wenn keine der oben unter Punkt 4 genannten Voraussetzungen erfüllt ist, dann sollte eine sogenannte <strong>Modell-II-Regression (Nicht-OLS-Regression)</strong> durchgeführt werden. Hier stehen als Möglichkeiten die <em>Major axis regression</em>, die <em>Ranged major axis regression</em> und die <em>Reduced major axis regression</em> zur Verfügung. Details finden sich in Logan (2010: 173–175), woraus aus die folgende Visualisierung stammt:</p>
<p><img src="./myMediaFolder/media/image47.jpeg" class="img-fluid"><br>
(aus Logan 2010)</p>
<p>In R stehen solche Methoden u. a. im Paket <code>lmodel2</code> zur Verfügung:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmodel2)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lmodel2</span>(b<span class="sc">~</span>a)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb60"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>Regression results</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>  Method Intercept     Slope Angle (degrees) P-perm (1-tailed)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>1    OLS  5.019254 0.4170422        22.63820                NA</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>2     MA  4.288499 0.4648040        24.92919                NA</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>3    SMA  3.067471 0.5446097        28.57314                NA</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wie man sieht, unterscheiden sich die beiden Modell-II-Ergebnisse deutlich von Modell I (OLS).</p>
</section>
</section>
<section id="lineare-modelle-allgemein" class="level2">
<h2 class="anchored" data-anchor-id="lineare-modelle-allgemein">Lineare Modelle allgemein</h2>
<section id="was-macht-ein-lineares-modell-aus" class="level3">
<h3 class="anchored" data-anchor-id="was-macht-ein-lineares-modell-aus">Was macht ein lineares Modell aus?</h3>
<p>Die meisten statistischen Verfahren, die wir bis zu diesem Punkt angeschaut haben, gehören zu den <strong>linearen Modellen</strong>. Dieser Begriff wird häufig weitgehend synonym mit „parametrischen Verfahren” verwendet, ist aber treffender. Von den bisherigen Verfahren gehören die folgenden zu den linearen Modellen:</p>
<ul>
<li><p>Pearson-Korrelation</p></li>
<li><p><em>t</em>-Test</p></li>
<li><p>Varianzanalyse</p></li>
<li><p>Einfache lineare Regression</p></li>
</ul>
<p>Was macht nun lineare Modelle aus:</p>
<ul>
<li><p>Voraussetzungen: <strong>Normalverteilung der Residuen und Varianzhomogenität</strong></p></li>
<li><p>In R kann man sie (mit Ausnahme der Pearson-Korrelation) mit dem <strong>Befehl lm</strong> abbilden (ja, auch die Varianzanalyse!)</p></li>
<li><p>Varianzanalysen und lineare Regressionen nutzen beide <strong>ANOVA-Tabellen mit <em>F</em>-ratios</strong> als Testverfahren</p></li>
<li><p>Lineare Modelle lassen sich als <strong>Linearkombination der Prädiktoren</strong> schreiben, d.&nbsp;h.:<br>
</p>
<ul>
<li>Prädiktoren werden <em>nicht</em> als Multiplikator, Divisor oder Exponent anderer<br>
Prädiktoren verwendet<br>
</li>
<li>die Beziehung muss aber <em>nicht zwingend linear</em> sein.</li>
</ul></li>
</ul>
</section>
<section id="welche-verfahren-gehören-zu-den-linearen-modellen" class="level3">
<h3 class="anchored" data-anchor-id="welche-verfahren-gehören-zu-den-linearen-modellen">Welche Verfahren gehören zu den linearen Modellen?</h3>
<p>Neben den schon besprochenen einfachen Verfahren gehören auch eine ganze Reihe komplexerer Vefahren zu den linearen Modellen, die aber alle den vorstehenden Bedingungen entsprechen. Die meisten werden wir in Statistik 3 besprechen. Logan (2010: 165) hat eine recht umfassende folgende Übersicht erstellt. Darin sind metrische Prädiktoren als x, x1 und x2 bezeichnet, kategoriale als A bzw. B. Was unter <em>R Model formula</em> steht, würde im jeweiligen Fall in die Klammern des lm-Befehls gesetzt:</p>
<p><img src="./myMediaFolder/media/image48.jpeg" class="img-fluid"><br>
(aus Logan 2010)</p>
</section>
<section id="testen-der-voraussetzungen-von-linearen-modellen-modelldiagnostik" class="level3">
<h3 class="anchored" data-anchor-id="testen-der-voraussetzungen-von-linearen-modellen-modelldiagnostik">Testen der Voraussetzungen von linearen Modellen (Modelldiagnostik)</h3>
<p>Wie geschrieben, haben lineare Modelle bestimmte Voraussetzungen. Selbst wenn lineare Modelle recht robust gegen Verletzungen der Vorassetzungen sind, so muss man doch jedes Mal, nachdem man ein lineares Modell gerechnet hat, prüfen, ob die Voraussetzungen erfüllt waren. Es geht hier primär um die Voraussetzungen Varianzhomogenität, Normalverteilung der Residuen und Linearität.</p>
<p>Wichtig ist, zu verstehen, dass man zunächst das lineare Modell rechnen muss und erst nachträglich prüfen kann, ob die Voraussetzungen erfüllt waren. Das liegt daran, dass die Kernannahmen Varianzhomogenität und Normalverteilung der Residuen sich auf das Modell, nicht auf die Originaldaten beziehen. Einzig für <em>t-</em>Tests und ANOVAs kann man diese beiden Punkte auch in der explorativen Datenanalyse vor dem Berechnen des Modells erkunden, für lineare Regressionen und komplexere Modelle geht das nicht. Wenn der nachträgliche Test zeigt, dass eine der Voraussetzungen schwerwiegend verletzt war, bedeutet das, dass man das Modell neu spezifizieren muss, etwa durch eine geeignete Transformation der abhängigen Variablen.</p>
<p>Das <strong>Überprüfen der Voraussetzungen (= Modelldiagnostik)</strong> erfolgt visuell mittels der sogenannten Residualplots, die man mit dem generische plot-Befehl bekommt, wenn man als Argument das Ergebnis eines linearen Modells hat. Man bekommt dann vier Plots, die man am besten in einem 2 x 2-Arrangement ausgibt (das macht der erste Befehl):</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="co">#4 Plots in einem Fenster</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Betrachten wir zwei Fälle, zunächst das Beispiel von eben:</p>
<p><img src="./myMediaFolder/media/image49.png" class="img-fluid"></p>
<p>und die zugehörigen Residualplots:</p>
<p><img src="./myMediaFolder/media/image50.png" class="img-fluid"></p>
<p>In diesem Fall ist <strong>alles OK</strong>. Man muss vor allem die oberen beiden Teilabbildungen betrachten. Links oben kann man gut erkennen, wenn Linearität oder Varianzhomogenität verletzt wären, rechts oben dagegen, wenn die Normalverteilung der Residuen verletzt wäre. Zu berücksichtigen ist, dass reale Daten nie perfekt linear, varianzhomogen und normalverteilt sind.</p>
<p>Uns interessieren nur <strong>massive Abweichungen</strong>. Wir würden sie wie folgt erkennen:</p>
<ul>
<li><p><strong>Linearität:</strong> Eine Verletzung erkennen wir in der linken oberen Abbildung, wenn wir eine <strong>„Wurst” bzw. „Banane”</strong> sehen, also wenn die linken Punkte alle unter der gepunktelten Linie, die mittleren alle darüber und die rechten wieder alle darunter lägen (oder umgekehrt).</p></li>
<li><p><strong>Varianzhomogenität:</strong> Eine Verletzung erkennen wir in der linken oberen Abbildung, wenn die Punktwolke einen starken <strong>Keil</strong> (meist nach rechts offen) beschreibt.</p></li>
<li><p><strong>Normalverteilung der Residuen:</strong> Eine Verletzung erkennen wir in der rechten oberen Abbildung, wenn die Punkte sehr stark von der gestrichelten Linie abweichen, insbesondere wenn sie eine ausgeprägte <strong>Treppenkurve</strong> bilden.</p></li>
</ul>
<p>Die beiden unteren Abbildungen sind für die Diagnostik weniger wichtig. Links unten haben wir eine skalierte Version der Abbildung links oben. Die Abbildung rechts unten zeigt uns, ob bestimmte Datenpunkte übermässigen Einfluss auf das Gesamtergebnis haben. Das wären Punkte mit einer <em>Cook’s distance</em> über 0.5 und insbesondere über 1. In solchen Fällen sollten wir noch einmal kritisch prüfen, ob (a) evtl. ein Eingabefehler vorliegt und (b) der bezeichnete Punkt wirklich zur Grundgesamtheit gerechnet werden sollte. Wenn aber beide Aspekte nicht zu beanstanden sind, dann gibt es auch keinen Grund, den entsprechenden Datenpunkt auszuschliessen; wir müssen uns nur bewusst sein, dass er das Gesamtergebniss übermässig stark beeinflusst.</p>
<p>Zum Schluss kommt noch ein Beispiel, bei dem die Modellvoraussetzungen einer linearen Regression klar nicht erfüllt sind.</p>
<p><img src="./myMediaFolder/media/image51.png" class="img-fluid"></p>
<p><img src="./myMediaFolder/media/image52.emf.png" class="img-fluid"></p>
<p>Hier sind die <strong>Voraussetzungen klar nicht erfüllt</strong>: (a) es liegt starke <strong>Varianzinhomogenität</strong> vor (links oben als nach rechts offener Keil erkennbar, links unten als klar ansteigende Kurve); (b) die <strong>Normalverteilung der Residuen ist auch nicht gegeben</strong> (im Q-Q-Plot rechts oben weichen die Punkte stark von der theoretischen Kurve ab und bilden stattdessen eine Treppenkurve). Schliesslich sehen wir rechte unten auch noch, dass es einen extrem <strong>einflussreichen Datenpunkt</strong> mit <em>Cook’s distance</em> &gt; 1 und einen weiteren mit <em>Cook’s distance</em> &gt; 0.5 gibt.</p>
<p>In diesem Fall schlussfolgern wir, dass das <strong>Modell fehlspezifiziert</strong> war. Da die Varianz mit dem Mittelwert zunimmt, während zugleich keine Null-Werte unter der abhängigen Variablen auftreten, wäre eine Logarithmus-Transformation der abhängigen Variablen hier vermutlich ein zielführendes Vorgehen. Dieses sollten wir ausprobieren und anschliessend wiederum die Residualplots betrachten.</p>
</section>
</section>
<section id="zusammenfassung-1" class="level2">
<h2 class="anchored" data-anchor-id="zusammenfassung-1">Zusammenfassung</h2>
<ul>
<li><p><strong><em>t</em>-Tests und ANOVAs</strong> sind parametrische Verfahren, um auf <strong>Unterschiede in den Mittelwerten einer metrischen Variablen</strong> zwischen zwei bzw. beliebig vielen Gruppen zu testen.</p></li>
<li><p><strong>Korrelationen</strong> testen auf einen linearen Zusammenhang zwischen zwei metrischen Variablen, <strong>ohne Kausalität anzunehmen.</strong></p></li>
<li><p>Einfache <strong>lineare Regressionen</strong> machen das Gleiche unter Annahme eines <strong>gerichteten Zusammenhangs</strong> (d.&nbsp;h. wenn es eine unabhängige und eine abhängige Variable gibt).</p></li>
<li><p><strong>Parametrische Verfahren</strong> basieren auf <strong>bestimmten Annahmen</strong> zur Streuung der Daten, sind aber <strong>robust</strong> gegenüber deren Verletzung.</p></li>
<li><p>Die <strong>Voraussetzungen parametrischer Verfahren</strong> beziehen sich auf die <strong>Residuen</strong>, nicht auf die unabhängigen, noch auf die abhängigen Variablen <em>per se</em>.</p></li>
<li><p>Sowohl lineare Regressionen als auch ANOVAs gehören zu den <strong>linearen Modellen</strong> und können in R mit dem <strong>Befehl lm</strong> spezifiziert werden.</p></li>
</ul>
</section>
<section id="weiterführende-literatur-1" class="level2">
<h2 class="anchored" data-anchor-id="weiterführende-literatur-1">Weiterführende Literatur</h2>
<ul>
<li>Crawley, M.J. 2015. <em>Statistics – An introduction using R</em>. 2nd ed.&nbsp;John Wiley &amp; Sons, Chichester, UK: 339 pp.
<ul>
<li>Chapter 7 – Regression: pp.&nbsp;114–139</li>
<li>Chapter 8 – Analysis of Variance: pp.&nbsp;150–167</li>
</ul></li>
<li>Fox, J. &amp; Weisberg, S. 2019. <em>An R companion to applied regression</em>. 3rd ed.&nbsp;SAGE Publications, Thousand Oaks, CA, US: 577 pp.</li>
<li>Logan, M. 2010. <em>Biostatistical design and analysis using R. A practical guide</em>. Wiley-Blackwell, Oxford, UK: 546 pp.
<ul>
<li>pp.&nbsp;151-166 (lineare Modelle)</li>
<li>pp.&nbsp;167-207 (Korrelation und einfache lineare Regression)</li>
<li>pp.&nbsp;254-282 (Einfaktorielle ANOVA)</li>
<li>pp.&nbsp;311-359 (Mehrfaktorielle ANOVA)</li>
</ul></li>
<li>Quinn, G.P. &amp; Keough, M.J. 2002. <em>Experimental design and data analysis for biologists</em>. Cambridge University Press, Cambridge, UK: 537 pp.</li>
<li>Warton, D.I. &amp; Hui, F.K.C. 2011. The arcsine is asinine: the analysis of proportions in ecology. <em>Ecology</em> 92: 3–10.</li>
<li>Wilson, J.B. 2007. Priorities in statistics, the sensitive feet of elephants, and don’t transform data. <em>Folia Geobotanica</em> 42: 161–167.</li>
</ul>
</section>
</section>
<section id="statistik-3-lineare-modelle-ii" class="level1">
<h1>Statistik 3: Lineare Modelle II</h1>
<p><strong>Statistik 3 fassen wir zu Beginn den generellen Ablauf inferenzstatistischer Analysen in einem Flussdiagramm zusammen. Dann wird die ANCOVA als eine Technik vorgestellt, die eine ANOVA mit einer linearen Regression verbindet. Danach geht es um komplexere Versionen linearer Regressionen. Hier betrachten wir polynomiale Regressionen, die z. B. einen Test auf unimodale Beziehungen erlauben, indem man dieselbe Prädiktorvariable linear und quadriert einspeist. Multiple Regressionen versuchen dagegen, eine abhängige Variable durch zwei oder mehr verschieden Prädiktorvariablen zu erklären. Wir thematisieren verschiedene dabei auftretende Probleme und ihre Lösung, insbesondere den Umgang mit korrelierten Prädiktoren und das Aufspüren des besten unter mehreren möglichen statistischen Modellen. Hieran wird auch der <em>informatian theoretician</em>-Ansatz der Statistik und die <em>multimodel inference</em> eingeführt.</strong></p>
<section id="lernziele-2" class="level2">
<h2 class="anchored" data-anchor-id="lernziele-2">Lernziele</h2>
<p><em>Ihr…</em></p>
<ul>
<li><em>wisst, wofür <strong>ANCOVA</strong> steht, wann dieses statistische Verfahren zum Einsatz kommt und wie das praktisch geht.</em></li>
<li><em>versteht, wann es Sinn macht, <strong>quadratische Terme in eine Regression</strong> einfliessen zu lassen und warum das dann trotzdem noch ein lineares Modell ist;</em></li>
<li><em>könnt <strong>lineare Regressionen mit mehreren Prädiktoren</strong> in R implementieren und wisst, welche Aspekte ihr bei der Modellspezifikation und bei der Auswahl des «besten» Modells beachten müsst; und</em></li>
<li><em>kennt die Gütemasse des <strong>information theoretician approach</strong> und könnt sie interpretieren.</em></li>
</ul>
</section>
<section id="genereller-ablauf-einer-statistischen-analyse" class="level2">
<h2 class="anchored" data-anchor-id="genereller-ablauf-einer-statistischen-analyse">Genereller Ablauf einer statistischen Analyse</h2>
<p>Das folgende Schema zeigt den generellen Ablauf einer statistischen Analyse, wie er für alle schon besprochenen und auch alle noch kommenden Verfahren gilt:</p>
<p><img src="./myMediaFolder/media/image53.emf.png" class="img-fluid"></p>
<p>Ein zentrales Element ist die Modelldiagnostik, die wir in Statistik 2 am Ende behandelt haben. Leider wird sie oft vergessen! Basierend auf den Ergebnissen der Modelldiagnostik kann man entweder die Ergebnisse fertigstellen oder aber man muss zu den initialen Schritten zurückgehen. Möglicherweise war das gewählte statistische Verfahren schon nicht adäquat oder das Verfahren war in Ordnung, nur die Details der Spezifizierung (etwa Transformationen von Daten) müssen nachgebessert werden.</p>
</section>
<section id="covarianzanalyse-ancova" class="level2">
<h2 class="anchored" data-anchor-id="covarianzanalyse-ancova">Covarianzanalyse (ANCOVA)</h2>
<p>Wie wir schon bei „Lineare Modelle allgemein” in Statitik 2 gesehen haben, lassen sich metrische und kategoriale Variablen in einem einzigen linearen Modell kombinieren. Eine ANCOVA macht genau dieses, ist also im Prinzip eine Kombination aus ANOVA und linearer Regression. Stellen wir uns vor, wir hätten einen Datensatz von Körpergewichten von Kindern unterschiedlichen Alters (age: metrisch) und Geschlechts (sex: kategorial/binär, dargestellt als blau und rot). Eine ANCOVA testet nun, ob und wie sich das Gewicht in Abhängigkeit von beiden Faktoren verhält. Dabei gibt es im Prinzip sechs verschiedene Möglichkeiten/Ergebnisse:</p>
<p><img src="./myMediaFolder/media/image54.jpeg" class="img-fluid"><br>
(aus Crawley 2015)</p>
<p>Wie andere lineare Modelle auch, kann man eine ANCOVA mittels aov oder mittels lm spezifizieren. Es ist zu beachten, dass hier die Reihenfolge der Variablen wichtig ist:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">aov</span>(weight<span class="sc">~</span>age\<span class="sc">*</span>sex))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Im vollen Modell (<em>full model,</em> <em>global model</em>) wurden vier Parameter gefittet (2 Steigungen und 2 Achsenabschnitte). Das haben wir durch das „*“-Zeichen spezifiziert. Dieses sagt, dass nicht nur Alter und Geschlecht unabhängig voneinander einen (additiven) Effekt haben, sondern dass der Effekt des Alters je nach Geschlecht unterschiedlich sein könnte, also die Gewichtszunahme mit. Jedoch sind oft nicht alle bedeutsam. Es ist daher wichtig, das Modell so lange zu vereinfachen, bis nur noch bedeutsame Parameter übrig sind. Dann hat man das minimal adäquate Modell.</p>
<p>Für die <strong>Modellvereinfachung</strong> gibt es unterschiedliche Strategien (mehr dazu später bei den „Multiplen linearen Regressionen”). Man muss jedenfalls schrittweise vorgehen, d.&nbsp;h. immer nur einen Parameter löschen und dann das neue Modell anschauen. Wenn von den Parametern welche nicht signifikant sind, könnte man z.&nbsp;B. zunächst den am wenigsten signifikanten löschen und dann das neue Model betrachten, usw.</p>
<p>Alternativ kann man auch ANOVAs zum Vergleich zweier unterschiedlich komplexer Modelle verwenden. Das klingt zunächst schräg, da wir bislang ANOVAs verwendet haben, um innerhalb eines Modelles zu sehen, ob etwa die durch die Steigung erklärte Varianz signifikant ist. Den gleichen Ansatz kann man aber auch verwenden, um zwei unterschiedlich komplexe Modelle miteinander zu vergleichen. Wichtig ist nur, dass das eine Modell im anderen geschachtelt ist:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(<span class="fu">lm</span>(weight<span class="sc">~</span>age\<span class="sc">*</span>sex), <span class="fu">lm</span>(weight<span class="sc">~</span>age<span class="sc">+</span>sex))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Das komplexere Modell ist jenes mit „*“, das einfachere jenes mit „+”, da dort eine einheitliche Gewichtszunahme mit dem Alter angeommen wird. Wenn die ANOVA nun ein signifikantes Ergebnis liefert, heisst das, dass der zusätzliche Parameter des komplexeren Modells (die Interaktion Alter x Geschlecht) mehr erklärt als zufällig zu erwarten und daher beibehalten werden sollte. Wenn die ANOVA ein nicht-signifkantes Ergebnis liefert, sollten wir uns für das einfachere Modell (jenes mit „+“) entscheiden.</p>
</section>
<section id="polynomische-regressionen" class="level2">
<h2 class="anchored" data-anchor-id="polynomische-regressionen">Polynomische Regressionen</h2>
<p>Eine quadratische Regression (Polynom 2. Ordnung) ist die einfachste Möglichkeit, eine sogenannte unimodale (<em>humpshaped</em>) Beziehung von abhängiger zur unabhängigen Variablen mathematisch abzubilden. Unimodal/<em>humpshaped</em> meint, dass die Kurve ein Maximum hat, d.&nbsp;h. die abhängige Variable für mittlere Werte der Prädiktorvariablen den höchsten Wert aufweist. Für viele Beziehungen sind solche unimodalen Kurvenverläufe theoretische vorhergesagt und/oder theoretisch nachgewiesen. In der Ökologie gilt das z. B. für die Beziehung des Artenreichtums zu so unterschiedlichen Faktoren wie Störungshäufigkeit (<em>intermediate disturbance hypothesis</em>, IDH), Boden-pH-Wert und Produktivität/Biomasse.</p>
<p>Das statistische Modell für eine quadratische Beziehung ist:</p>
<p><em>y</em>i = β0 + β1<em>x</em>i + β2<em>x</em>i²</p>
<p>In R wird eine quadratische Regression folgendermassen codiert:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(f<span class="sc">~</span>e<span class="sc">+</span><span class="fu">I</span>(e<span class="sc">^</span><span class="dv">2</span>)))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb65"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>             Estimate Std. Error t value Pr(&gt;|t|)   </span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>(Intercept) -2.239308   3.811746  -0.587  0.56777   </span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>e            1.330933   0.360105   3.696  0.00306 **</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>I(e^2)      -0.031587   0.007504  -4.209  0.00121 **</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wichtig ist, dass man den quadratischen Term im lm-Befehl nicht einfach als <code>e^2</code> eingeben kann, sondern <code>I(e\^2)</code> schreiben muss. Eine signifikante unimodale Beziehung ist dann gegeben, wenn die Parameterschätzung für den Quadratischen Term (also <code>e^2</code>) negativ ist – man hat eine nach unten offene Parabel. Ist der quadratische Term dagegen signifikant positiv, hat man eine nach oben offene Parabel, also eine u-förmige Beziehung (Minimum für die abhängige Variable bei intermediären Werten der Prädiktorvariablen).</p>
<p>Wichtig ist, dass man wie bei allen statistischen Modellen nachträglich die Modellvoraussetzungen prüft.</p>
<p>Im vorhergehenden Beispiel sah es mit einer einfachen linearen Regression so aus (Code, Ergebnisplot und Residualplots):</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(f<span class="sc">~</span>e,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">40</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">20</span>))</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(f<span class="sc">~</span>e),<span class="at">col=</span><span class="st">"blue"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image55.png" class="img-fluid"></p>
<p><img src="./myMediaFolder/media/image56.png" class="img-fluid"></p>
<p>Man ahnt schon im Scatterplot mit der gefitteten einfachen linearen Regression, dass etwas mit dem Modell nicht stimmt, was durch die Bananenform im Residualplot links oben unterstrichen wird: die Beziehung ist evident nicht linear.</p>
<p>Nach Hinzufügen des quadratischen Terms sieht man schon im Scatterplot mit der gefitteten Funktion, dass es viel besser passt, aber erst recht in den Residualplots. Mit predict kann man jede Funktion plotten, die als Ergebnis einer Regressionsanalyse herauskommt. Im Prinzip zerlegt man die <em>x</em>-Achse in viele kleine Segmente und plottet dann jeweils Geraden zwischen zwei aufeinander folgenden vorhergesagten Punkten.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>xv <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">40</span>,<span class="fl">0.1</span>)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(f<span class="sc">~</span>e,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">40</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">20</span>))</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>yv2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm.quad,<span class="fu">list</span>(<span class="at">e=</span>xv))</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xv,yv2,<span class="at">col=</span><span class="st">"red"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image57.png" class="img-fluid"></p>
<p><img src="./myMediaFolder/media/image58.png" class="img-fluid"></p>
<p>Bezüglich des statistische Vorgehens ist zu beachten, dass man den quadratischen Term nur im Modell behalten sollte, wenn er signifikant ist (bei nur einem quadratischen Term der p-Wert aus summary, sonst ggf. mit anova testen oder AICc-Werte (siehe später) vergleichen). Dagegen muss der lineare Term (hier: e) dann beibehalten werden, wenn der quadratische Term signifikant ist, selbst wenn der lineare Term nicht signifkant ist. (Wenn beide nicht signifikant sind, fallen dagegen beide raus).</p>
<p>Wenn es theoretische Gründe gibt, kann man in gleicher Weise auch Polynome höherer Ordnung implementieren. Wichtig ist, im Hinterkopf zu behalten, dass eine polynomische Regression fast immer eine deutliche Simplifizierung der Realität darstellt. Sie ist ein probates und einfaches Mittel, um zu testen, ob die Beziehung signifikant unimodal ist. Dagegen ist sie problematisch als prädiktives Modell, da sie oft negative Werte für die abhängige Variable voraussagt, zumindest ausserhalb des gefitteten Bereichs. Negative Werte sind aber vielfach theoretisch unmöglich (z. B. Artenzahlen, Stoffkonzentrationen,…).</p>
</section>
<section id="multiple-lineare-regressionen" class="level2">
<h2 class="anchored" data-anchor-id="multiple-lineare-regressionen">Multiple lineare Regressionen</h2>
<section id="vorgehen" class="level3">
<h3 class="anchored" data-anchor-id="vorgehen">Vorgehen</h3>
<p>Analog zur mehrfaktoriellen ANOVA, sind multiple lineare Regressionen einfach lineare Regressionen mit mehreren Prädiktoren. Das statistische Modell lautet also folgendermassen (wobei <em>x</em><sub>1</sub> … <em>x</em><sub>i</sub> metrische Variablen sind):</p>
<p><em>y</em>i = β0 + β1<em>x</em>1,i + β2<em>x</em>2,i + (…) + βj<em>x</em>j,i</p>
<p>In R wird das wie folgt codiert:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span> (y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> mydata)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Möglich sind aber auch folgende Modelle:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span> (y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> <span class="fu">I</span>(x2\<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> mydata)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>model3 <span class="ot">&lt;-</span> <span class="fu">lm</span> (y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> <span class="fu">log10</span>(x3), <span class="at">data =</span> mydata)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>model4 <span class="ot">&lt;-</span> <span class="fu">lm</span> (y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x1<span class="sc">:</span>x2, <span class="at">data =</span> mydata)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Und für ein konkretes Beispiel (Abhängigkeit der Vogelabundanz in isolierten Waldinseln von verschiedenen Umweltvariablen (YR.ISOL = year since isolation, ALT = altitude, GRAZE = grazing):</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span> (ABUND <span class="sc">~</span> YR.ISOL <span class="sc">+</span> ALT <span class="sc">+</span> GRAZE, <span class="at">data=</span>loyn)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb71"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>(Intercept) -73.58185  107.24995  -0.686 0.495712    </span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>YR.ISOL       0.05143    0.05393   0.954 0.344719    </span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>ALT           0.03285    0.02679   1.226 0.225618    </span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>GRAZE        -4.01692    0.99881  -4.022 0.000188 ***</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Und wie immer schauen wir die Residualplots an, die eigentlich ziemlich gut aussehen:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image59.png" class="img-fluid"></p>
<p>Allerdings dürfen wir uns hier im Falle einer multiplen Regression noch nicht zufrieden zurücklehnen, sondern müssen uns zunächst noch zwei potenziellen Problemen annehmen: (1) Korrelation zwischen den Prädiktoren und (2) Overfitting.</p>
</section>
<section id="problem-1-korrelation-zwischen-den-prädiktoren" class="level3">
<h3 class="anchored" data-anchor-id="problem-1-korrelation-zwischen-den-prädiktoren">Problem 1: Korrelation zwischen den Prädiktoren</h3>
<p>Damit lm verlässliche Parameterschätzungen liefern kann, müssen die Prädiktoren (hinreichend) <strong>unabhängig</strong> (man spricht auch von: orthogonal) sein. Das muss man vor dem Fitten des Models testen und dann von Paaren hochkorrelierter Variablen jeweils eine ausschliessen.</p>
<p>Es gibt zwei gängige Testmöglichkeiten:</p>
<ol type="1">
<li><p><strong>Korrelationmatrix:</strong> nur Parameter mit |r| &lt; 0.7 werden beibehalten (manchmal findet man auch andere Schwellenwerte, etwa 0.6 oder 0.75: wie eigentlich alles in der Statistik, ist es keine Schwarz-weiss-Welt).</p></li>
<li><p><strong><em>Variance inflation factor</em> (VIF):</strong></p></li>
</ol>
<blockquote class="blockquote">
<p><span class="math inline">\({VIF}_{i}\  = \frac{1}{1 - R_{i}²}\)</span> , mit <em>R<sub>i</sub></em>² aus dem Modell Prädiktor <em>i</em> gegen alle übrigen Prädiktoren</p>
</blockquote>
<p>Der VIF sagt uns, dass der Standardfehler (SE) des Prädiktors um <span class="math inline">\(\sqrt{VIF}\)</span> grösser ist als im orthogonalen Fall. Meist werden Variablen bis VIF = 5, manchmal bis VIF = 10 akzeptiert.</p>
<p>Die Berechnung der Korrelationsmatrix geht in R sehr einfach:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>cor <span class="ot">&lt;-</span> <span class="fu">cor</span>(loyn[,<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>])</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>cor</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Das Ergebnis ist allerdings unübersichtlich. Man kann es vereinfachen, indem man nur jene Werte darstellt, die über dem selbstgewählten Schwellenwert (hier 0.6) liegen.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>cor[<span class="fu">abs</span>(cor)<span class="sc">&lt;</span><span class="fl">0.6</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>cor</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb75"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>        AREA    YR.ISOL DIST LDIST      GRAZE ALT</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>AREA       1  0.0000000    0     0  0.0000000   0</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>YR.ISOL    0  1.0000000    0     0 -0.6355671   0</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>DIST       0  0.0000000    1     0  0.0000000   0</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>LDIST      0  0.0000000    0     1  0.0000000   0</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>GRAZE      0 -0.6355671    0     0  1.0000000   0</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>ALT        0  0.0000000    0     0  0.0000000   1</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wenn man die Schwelle bei 0.6 ansetzt, müsste man also von den beiden Variablen GRAZE und YR.ISOL eine aus dem Modell entfernen, da sie zu stark negativ korreliert sind. Dabei sind drei Dinge wichtig:</p>
<ul>
<li><p>Statistisch gibt es kein klares Argument, welche von mehreren hoch-korrelierten Variablen man im vollen Modell streichen sollte (man könnte höchstens zusätzlich den VIF heranziehen). Inhaltlich macht es Sinn, diejenige Variable beizubehalten, die (a) besser interpretierbar ist oder (b) häufiger in vergleichbaren Studien gebraucht wurde.</p></li>
<li><p>Man sollte im Methodenteil dokumentieren welche Variable(n) wegen positiver/negativer Korrelation mit welcher anderen aus dem vollen Modell gestrichen wurden.</p></li>
<li><p>Bei der Interpretation der Ergebnisse stehen die beibehaltenen Variablen auch für die jeweils gestrichenen hochkorrelierten Variablen (zumindest zu einem erheblichen Teil).</p></li>
</ul>
<p>Die Berechnung der VIF’s geht wie folgt:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(model)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb77"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a> YR.ISOL      ALT    GRAZE </span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>1.679995 1.200372 1.904799 </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Hier sieht man nicht, welche Variable mit welcher anderen korrliert ist, man bekommt nur ein Gesamtranking. Da die VIF-Werte aller drei Variablen unter 5 sind, können alle beibehalten werden. Wenn mehrere Variablen einen VIF &gt; 5 haben, muss man schrittweise immer die Variable mit dem höchsten VIF-Wert entfernen und die VIF-Werte dann neuberechnen. Sie ändern sich, wenn eine Variable wegfällt, da sie die Gesamt-Korrelationsstruktur des Datensatzes widerspiegeln.</p>
</section>
<section id="problem-2-overfitting" class="level3">
<h3 class="anchored" data-anchor-id="problem-2-overfitting">Problem 2: Overfitting</h3>
<p>Das Problem des Overfitting soll mit der folgenden Simulation veranschaulicht werden: zu einer Stichprobe von sechs Beobachtungen mit zwei numerischen Variablen werden schrittweise polynomische Modelle höher Ordnung gefittet.</p>
<p>Der Code dafür ist:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>lm<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x)</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>xy <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span><span class="dv">0</span>,<span class="at">to=</span><span class="dv">10</span>,<span class="at">by=</span><span class="fl">0.1</span>)</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>yv <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm,<span class="fu">list</span>(<span class="at">x=</span>xv))</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xv,yv)</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>lm2<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x<span class="sc">+</span><span class="fu">I</span>(x\<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>xy <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span><span class="dv">0</span>,<span class="at">to=</span><span class="dv">10</span>,<span class="at">by=</span><span class="fl">0.1</span>)</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>yv <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm2,<span class="fu">list</span>(<span class="at">x=</span>xv))</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xv,yv)</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>[usw.]</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Das Ergebnis sieht folgendermassen aus:</p>
<p><img src="./myMediaFolder/media/image60.png" class="img-fluid"><strong><em>R</em>² = 0.012</strong></p>
<p><img src="./myMediaFolder/media/image61.png" class="img-fluid"><strong><em>R</em>² = 0.111</strong></p>
<p><img src="./myMediaFolder/media/image62.png" class="img-fluid"><strong><em>R</em>² = 0.170</strong></p>
<p><img src="./myMediaFolder/media/image63.png" class="img-fluid"><strong><em>R</em>² = 0.875</strong></p>
<p><img src="./myMediaFolder/media/image64.png" class="img-fluid"><strong><em>R</em>² = 1.000</strong></p>
<p>Wir sehen, dass die erklärte Varianz kontinuierlich vom 2-Parameter-Modell (Achsenabschnitt und Steigung) zum 6-Parameter-Modell (Achsenabschnitt, Parameter für <em>x</em> bis <em>x</em><sup>5</sup>) zunimmt. Ein polynomische Modell (<em>n</em> – 1). Ordnung erzielt immer 100% Anpassung and die Daten (<em>R</em><sup>2</sup> = 1), wenn man <em>n</em> Beobachtungen hat. Aber ist das Modell deswegen auch besonders korrekt oder aussagekräftig? Das darf bezweifelt werden. Ein gutes Modell wäre ja eines, das die zugrunde liegende Gesetzmässigkeit erkennt und daher auch für die Interpolation und Extrapolation geeignet ist.</p>
<p>Es zeigt sich, dass die gute Anpassung an die Daten (good fit, hier gemessen als R2) nur der eine Aspekt eines guten Modells ist. Zugleich sollte es möglichst einfach (<em>parsimonous</em>) sein, d.&nbsp;h. das Beobachtete mit möglichst wenigen Annahmen erklären. Es gilt das folgende Prinzip, das auf den mittelalterlichen Philosophen Willliam of Ockham (ca. 1288–1347 zurückgeht).</p>
<p><img src="./myMediaFolder/media/image65.jpeg" class="img-fluid" alt="https://upload.wikimedia.org/wikipedia/commons/a/ab/William_of_Ockham_-_Logica_1341.jpg"><br>
(Skizze aus einer Handschrift von Ockhams <em>Summa logicae</em>)</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Ockham’s razor = Law of parsimony (Sparsamkeitsprinzip)</p>
<p><strong><em>Wesenheiten dürfen nicht über das Notwendige hinaus vermehrt werden</em></strong></p>
<p>Formulierung von Johannes Clauberg (1622–1665)</p>
</div>
</div>
</div>
</section>
<section id="modellvereinfachung" class="level3">
<h3 class="anchored" data-anchor-id="modellvereinfachung">Modellvereinfachung</h3>
<p>Nun stellt sich die Frage, wie wir vom <strong>vollen Modell (<em>full model, global model</em>)</strong> also jenem nach Entfernung hochkorrelierter Variablen zum „besten” Modell gelangt, das also eine bestmögliche Kombination von guter Anpassung an die Daten (Fit) und Parsimonie aufweist. Dieses anzustrebende statistische Modell wird auch <strong>minimal adäquates Modell (<em>mininum adequate model</em>)</strong> genannt.</p>
<p>Ganz generell gilt: Man sollte <strong>maximal <em>p</em> = <em>n</em> / 3 Parameter fitten</strong> (wobei <em>n</em> = Zahl der Datenpunkte/Beobachtungen und bei <em>p</em> auch der Achsenabschnitt [<em>b</em><sub>0</sub>] mitgezählt wird).</p>
<p>Mögliche <strong>Kriterien für das „beste” Modell</strong> (<em>minimum adequate model</em>):</p>
<ol type="1">
<li><p><strong>Höchster <em>R</em>²<sub>adj.</sub> =</strong> <span class="math inline">\(\mathbf{1}\mathbf{-}\)</span> <span class="math inline">\(\frac{\mathbf{SS}_{\mathbf{Residual}}\mathbf{/\lbrack n -}\left( \mathbf{p + 1} \right)\mathbf{\rbrack}}{\mathbf{SS}_{\mathbf{Total}}\mathbf{/(n - 1)}}\)</span><strong><br>
</strong>(vgl. <em>R</em>² = <span class="math inline">\(\frac{{SS}_{Regression}}{{SS}_{Total}} = 1 - \frac{{SS}_{Residual}}{{SS}_{Total}}\)</span>)<br>
Ist nicht wirklich zielführend, da der „Strafterm” (um den <em>R</em>² reduziert wird) zu gering ist, um wirklich für Parsimonität zu sorgen.</p></li>
<li><p><strong>Schrittweise Modellvereinfachung ausgehend vom „maximalen Modell”<br>
</strong>Durch: Entfernen von (a) nicht-signifikanten Interaktionen, (b) nicht-signifikanten quadratischen Termen und schliesslich (c) nicht-signifkanten linearen Variablen.</p></li>
</ol>
<p>Die schrittweise Modellvereinfachung kann wiederum auf drei verschiedene Weisen geschehen (die meist, aber nicht immer, die gleichen Ergebnisse liefern):</p>
<ol type="a">
<li><p><strong>Schrittweise die am wenigsten signifkanten Terme entfernen</strong>, bis alle signifikant sind:<br>
<br>
<strong>model1 &lt;- lm (ABUND ~ YR.ISOL + ALT + GRAZE, data=loyn)<br>
summary(model1)<br>
model2 &lt;- update(model1,~.-YR.ISOL)<br>
summary(model2)</strong></p></li>
<li><p><strong>Mittels ANOVA schrittweise Modelle vergleichen</strong> und Terme hinzufügen, wenn signifikent, bzw. entfernen, wenn nicht<br>
<br>
<strong>anova(model1,model2)</strong></p></li>
<li><p>Eine <strong>automatische Funktion</strong> zum schrittweisen Hinzufügen (<em>forward selection</em>) oder Löschen (<em>backward selection</em>) oder beidem verwenden (es gibt verschiedene Packages, bei Interesse bitte googlen).</p></li>
</ol>
<p>Varianten a bis c sind im Prinzip OK, man muss sich aber bewusst sein, dass gerade bei vielen Variablen dieses schrittweise Vorgehen nicht zwingend das wirklich beste Modell findet, sondern man in einem “lokalen Optimum” landen kann (als Alternative siehe die dredge-Funktion unter „<em>Information theoretician approach</em> und <em>multimodel inference</em>”.</p>
</section>
<section id="varianzpartitionierung" class="level3">
<h3 class="anchored" data-anchor-id="varianzpartitionierung">Varianzpartitionierung</h3>
<p>Wenn man das minimal adäquate Modell gefunden hat, will man oft noch wissen, wie bedeutsam die einzelnen enthaltenen Variablen sind. Bedeutsamkeit/Relevanz haben wir weiter oben als <em>R</em>² (erklärte Varianz) ausgedrückt. Wir können uns also anschauen, <strong>welche Anteile der erklärten Varianz auf welche Variablen zurückgehen</strong>. Da unsere Variablen (auch nach einem Korrelationstest und Ausschluss der besonders hoch korrelierten) nicht völlig orthogonal = unabhängig voneinander sind, verhalten sich die Varianzen nicht additiv. Vielmehr ist die erklärte Varianz in einem Modell mit zwei Variablen meist niedriger als die Summe der Varianzen der beiden Einzelmodelle. In einer Varianzpartitionierung wird die Varianz jeder Variablen daher in eine unabhängige (<em>independent</em>, I) und eine gemeinsame (<em>joint</em>, J) Komponente zerlegt:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hier.part)</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>loyn.preds <span class="ot">&lt;-</span> <span class="fu">with</span>(loyn, <span class="fu">data.frame</span>(YR.ISOL,ALT,GRAZE))</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hier.part</span>(loyn<span class="sc">$</span>ABUND,loyn.preds,<span class="at">gof=</span><span class="st">"Rsqu"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb80"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>$IJ</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>                 I          J     Total</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>YR.ISOL 0.11892853 0.13444049 0.2533690</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>ALT     0.06960132 0.07926823 0.1488696</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>GRAZE   0.30019854 0.16562324 0.4658218&nbsp;</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>$I.perc</span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>               I</span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a>YR.ISOL 24.33428</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>ALT     14.24131</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>GRAZE   61.42441&nbsp;</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Der grösste Teil (61%) der insgesamt erklärten Varianz dieses Drei-Parameter-Models wird hier also durch den Faktor Grazing erklärt.</p>
</section>
<section id="ergebnisdarstellung-partielle-regressionen-und-3-d-grafiken" class="level3">
<h3 class="anchored" data-anchor-id="ergebnisdarstellung-partielle-regressionen-und-3-d-grafiken">Ergebnisdarstellung: partielle Regressionen und 3-D-Grafiken</h3>
<p>Während sich die ermittelte Beziehung zwischen Antwort- und Prädiktor-Variable auch bei nichtlinearen Verläufen einfach mit predict visualisieren lässt, solange man nur eine Prädiktorvariable hat (selbst wenn sie in transformierter Weise im lm eingespeist wird), ist das bei mehreren Prädiktoren eine Herausforderung. Hier seien zwei Möglichkeiten kurz erwähnt:</p>
<ol type="1">
<li><p><strong>Partielle Regressionen</strong> (sie zeigen wie die Beziehung aussähe, wenn all übrigen Faktoren konstant wären</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="fu">avPlots</span>(model, <span class="at">ask=</span>F)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image66.png" class="img-fluid"></p></li>
<li><p><strong>3D Response surfaces </strong>(es gibt Packages, um dasselbe auch für zwei Prädiktoren gleichzeitig zu machen; dies mach insbesondere Sinn, wenn auch quadratische Terme dabei sind; bei Interesse bitte googlen)</p></li>
</ol>
</section>
</section>
<section id="information-theoretician-approach-und-multimodel-inference" class="level2">
<h2 class="anchored" data-anchor-id="information-theoretician-approach-und-multimodel-inference">Information theoretician approach und multimodel inference</h2>
<section id="vergleich-mit-frequentist-statistics" class="level3">
<h3 class="anchored" data-anchor-id="vergleich-mit-frequentist-statistics">Vergleich mit frequentist statistics</h3>
<p>Es gibt zwei grundlegende statistische Philosophien:</p>
<p><strong><em>Frequentist statistics</em> („klassisiche” Statistik)</strong></p>
<ul>
<li>Alles, was wir bislang gemacht haben</li>
<li><em>Grundannahme:</em> Es gibt ein einziges richtiges Modell der Wirklichkeit, dem man sich mit Irrtumswahrscheinlichkeitenannähern kann</li>
<li>Nutzt <strong><em>p</em>-Werte</strong></li>
</ul>
<p><strong>Information theoretician approach</strong></p>
<ul>
<li>Das, was wir in diesem Unterkapitel besprechen</li>
<li><em>Grundannahme:</em> Es kann ähnlich gute Modelle der Wirklichkeit geben, es gibt nicht das eine wahre Modell</li>
<li>Nutzt <strong>keine <em>p</em>-Werte</strong></li>
<li>Dafür <strong>AIC</strong> (<em>Akaike information criterion</em>) oder <strong>BIC</strong> (<em>Bayesian information criterion</em>)</li>
<li><strong>Modellmittelung</strong> (<em>model averaging</em>) möglich</li>
</ul>
</section>
<section id="masse-der-modellgüte-aic-bic-aicc-δi-evidence-ratios-akaike-weights" class="level3">
<h3 class="anchored" data-anchor-id="masse-der-modellgüte-aic-bic-aicc-δi-evidence-ratios-akaike-weights">Masse der Modellgüte: AIC, BIC, AICc, Δ<sub>i</sub>, Evidence ratios, Akaike weights</h3>
<p>Die folgende Übersicht zeigt die wichtigsten Gütemasse im Vergleich. Wie schon besprochen, berücksichtigt R²adj. (nahezu) ausschliesslich den Fit (also die Anpassung der Kurve an die Daten). Dagegen berücksichtigen die Informationskriterien Fit und Komplexität (Komplexität meint das Gegenteil von Parsimonität). Bei AICc und BIC = SC fliesst schliesslich auch noch die Zahl der Datenpunkte ein:</p>
<p><img src="./myMediaFolder/media/image67.png" class="img-fluid"><br>
(aus Johnson &amp; Omland 2004)</p>
<p>Dabei gilt für AIC:</p>
<p><span class="math inline">\(AIC = \text{n}(ln(RSS)) - \text{n} \times ln(n) + 2 (k+1)\)</span> mit:</p>
<ul>
<li>RSS = Residual sum of squares</li>
<li><em>k</em> = Parameter des Models, inkl. Achsenabschnitt</li>
<li><em>n</em> = Anzahl der Beobachtungen/Replikate</li>
</ul>
<p>AICc ist der AIC für „kleine” Stichprobengrössen</p>
<p>(wobei „klein” bis zu 40 <em>k</em> reicht, also bei 2 Parametern wie in einer einfachen linearen Regression „gross” erst bei 81 Datenpunkten begänne). Deshalb und da sich für grosses <em>n</em> AICc asymptotisch AIC nähert, sollte man einfach immer AICc verwenden.</p>
<p>AIC und BIC entstammen wiederum etwas unterschiedlichen Philosophien. Auf die Unterschiede gehen wir nicht im Detail ein. Die Ergebnisse basierend auf BIC und AICc sind in dem Kontext wie wir sie hier vorstellen (BIC mit nicht-informativen <em>priors</em>) nahezu gleich. BIC wird relevant, wenn man informative <em>priors</em> verwenden kann (aber das sprengt den Kurs).</p>
<p>Es gilt folgendes für AIC, AICc und BIC analog:</p>
<ul>
<li><p>Der <strong>absolute Wert eines Informationskriteriums ist belanglos</strong> (ob also -1000, 0.1 oder +1000000). Informationskriterien können nur im Vergleich zweier Modelle für die gleichen Daten sinnvoll angewandt werden. Dann ist das <strong>Modell mit dem niedrigeren Wert das bessere</strong> (bei gemeinsamer Betrachtung von Fit und Komplexität).</p></li>
<li><p><strong>∆<em><sub>i</sub></em> = AIC<em><sub>i</sub></em> – AIC<sub>min</sub>&nbsp;∆<em><sub>i</sub></em></strong> ist die Differenz im AIC (oder eines anderen Informationskriteriums) zwischen einem bestimmten Modell i und dem jeweils besten Modell im Vergleich. Dabei wird meist die folgende Konvention verfolgt:</p>
<ul>
<li>wenn <strong>∆<em><sub>i</sub></em></strong> ≤ 2: Modelle sind statistisch „gleichwertig”</li>
<li>wenn <strong>∆<em><sub>i</sub></em></strong> &gt; 4: Modell nicht relevant</li>
</ul></li>
<li><p><strong><em>Likelihood</em></strong> von Modell <em>g<sub>i</sub></em> für die Daten: <span class="math inline">\(L = exp(-\frac{1}{2}\Delta_i)\)</span></p></li>
<li><p><strong><em>Evidence ratio</em>:</strong> (etwa: wie vielfach besser ist das beste Modell verglichen mit Modell <em>i</em>?) <span class="math inline">\(ER = \frac{L_{best}}{L_i}\)</span></p></li>
<li><p><strong><em>Akaike weights</em>: </strong>Normalisierte <em>Likelihoods</em> über alle verglichenen Modelle: <span class="math inline">\(W_i = \frac{exp(-\frac{1}{2}\Delta_i)}{\sum{[exp(-\frac{1}{2}\Delta_j]}}\)</span></p></li>
</ul>
<p>∆<em><sub>i</sub></em>, Likelihood, ER und Akaike weights stehen alle für die gleiche Information in verschiedenen Darstellungen/Transformationen. Als besonders praktisch erweisen sich die <strong>Akaike weights <em>W<sub>i</sub></em></strong>. Nach ihrer Definition summieren sich die Akaike weights aller verglichenen Modelle zu 1. <em>W<sub>i</sub></em> kann daher als die Wahrscheinlichkeit interpretiert werden, dass Modell <em>i</em> unter den verglichenen Modellen das beste ist.</p>
<p>Da AIC und <em>p</em>-Werte aus verschiedenen und nicht kompatiblen statistischen Philosophien stammen, sollte man in einer mit Informationskriterien arbeitenden Studie nicht zusätzlich auch noch <em>p</em>-Werte angeben. <em>R</em>²-Werte sind dagegen in beiden „statistischen Welten” sinnvoll und wichtig.</p>
</section>
<section id="multimodel-inference" class="level3">
<h3 class="anchored" data-anchor-id="multimodel-inference">Multimodel inference</h3>
<p>Der Charme der Informationskriterien ist, dass sie sich besonders gut dann eignen, wenn man viele verschiedene Modelle vergleicht, etwa weil man ein grössere Zahl von potenziellen Prädiktoren erhoben hat, mit denen man eine abhängige Variable erklären will, etwas in einer multiplen Regression oder einer mehrfaktoriellen ANOVA oder einem sonstigen komplexen Modell. Wenn man sich ein globales Modell mit <em>n</em> Termen (Achsenabschnitt und neun Steigungen für Prädiktorvariablen, transformierte Prädiktorvariablen oder Interaktionen zwischen Prädiktorvariablen) vorstellt, beinhaltet das 2<em><sup>n</sup></em> Einzelmodelle für alle möglichen Kombinationen der Terme von 0 bis <em>n</em> Prädiktoren. Bei <em>n</em> = 10 wären das bereits 1024 verschiedene Modelle. Diese alle zu berechnen ist ein grosser Aufwand, weswegen man früher versucht hat, in solchen Fällen das minimal adäquate Modell in einer weniger rechenaufwändigen Weise zu finden, indem man eine <em>stepwise forward/backward variable selection</em> durchgeführt hat (siehe Kapitel „Modellvereinfachung” oben). Heute ist das Ausrechnen von 1000 Modellen selbst auf einem einfachen Notebook nur noch eine Sache von Sekunden, d.h. man kann seine Entscheidung effektiv auf dem Vergleich aller mit den verfügbaren Variablen möglichen Teilmodelle gründen. Die dredge-Funktion im MuMIn-Paket macht genau dieses. Bis etwa 15 Terme (d. h. 32768 zu vergleichende Modelle) funktioniert dredge auch auf einfachen Notebooks noch im Bereich weniger Minuten (aber man muss schon merklich auf das Ergebnis warten); jeder weitere Term führt aber zu einer Verdopplung der Rechenzeit.</p>
<p>Schauen wir uns das anhand des schon bekannten loyn-Datensatzes (Vogelvorkommen in Waldfragmenten) an:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MuMIn)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>global.model <span class="ot">&lt;-</span> <span class="fu">lm</span> (ABUND <span class="sc">~</span> YR.ISOL <span class="sc">+</span> ALT <span class="sc">+</span> GRAZE, <span class="at">data=</span>loyn)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">na.action=</span><span class="st">"na.fail"</span>)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>allmodels <span class="ot">&lt;-</span> <span class="fu">dredge</span>(global.model)</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>allmodels</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb83"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>Model selection table </span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>     (Int)     ALT    GRA  YR.ISO df   logLik  AICc delta weight</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>3   34.370         -4.981          3 -194.315 395.1  0.00  0.407</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>4   28.560 0.03191 -4.597          4 -193.573 395.9  0.84  0.267</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>7  -62.750         -4.440 0.04898  4 -193.886 396.6  1.46  0.196</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>8  -73.580 0.03285 -4.017 0.05143  5 -193.087 397.4  2.28  0.130</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>6 -348.500 0.07006        0.18350  4 -200.670 410.1 15.03  0.000</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>5 -392.300                0.21120  3 -203.690 413.8 18.75  0.000</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>2    5.598 0.09515                 3 -207.358 421.2 26.09  0.000</span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>1   19.510                         2 -211.871 428.0 32.88  0.000</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wie man sieht, wurde hier zunächst ein globales Modell mit den drei Prädiktoren YR.ISOL, ALT und GRAZE erstellt. Im nächsten Schritt wurde dann mit der dredge-Funktion dann ein Objekt allmodels generiert, das die 2<sup>3</sup> = 8 möglichen Teilmodelle enthält. In der Tabellenausgabe sieht man, dass unter diesen Modell Nr. 3, das nur einen Achsenabschnitt und GRAZE enthält mit einem Akaike weight von 0.407 das beste Modell ist. Allerdings unterscheiden sich die Modelle Nr. 4 und 7 um weniger als 2 AICc-Einheiten, sind also als praktisch gleichwertig zu betrachten. Sie haben daher auch nur etwas geringere Variable importances von 0.267 und 0.196.</p>
<p>Anders als bei der <em>frequentist statistician</em>-Ansatz geht es nicht darum, ein einziges bestes Modell zu finden, sondern eine Aussage über ein Ensemble von plausiblen Modellen zu treffen. Es gibt hier zwei gängige Ansätze, <strong><em>Variable importance</em></strong> und <strong><em>Model averaging</em></strong>.</p>
<p><em>Variable importance</em> steht dabei für die Summe der <em>W<sub>i</sub></em>-Werte aller Teilmodelle, die eine bestimmte Variable enthalten. Da <em>W<sub>i</sub></em> selbst von 0 bis 1 reicht, gilt dies auch für die Variable importance. Eine Variable importance von 1 bedeutet dabei, dass alle plausiblen Modelle die entsprechende Variable beinhalten. Mithin sagt uns die Variable importance wie bedeutsam eine bestimmte Variable innerhalb der Menge der verglichenen Teilmodelle ist. Aber Achtung: <em>Variable importance</em> hat nichts mit Signifikanz oder <em>p</em>-Werten zu tun!!! Es gibt keine generelle Konvention, ab welcher Variable importance eine Variable als bedeutsam angesehen wird, aber häufig wird 50 % als Schwelle verwendet. In R geht das folgendermassen:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(allmodels)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb85"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>                     GRAZE ALT  YR.ISOL</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>Importance:          1.00  0.40 0.33   </span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>N containing models:    4     4    4 </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Während logischerweise jede der drei Variablen in jeweils vier Teilmodellen vorkommt, unterscheiden sie sich erheblich in der Variable importance. Alle nach der obigen Tabelle relevanten Modelle (∆<em><sub>i</sub></em> &lt; 4) enthalten GRAZE, aber nur je zwei von ihnen auch die beiden anderen Variablen. Entsprechend ist die <em>Variable importance</em> von GRAZE nahe 1, während sie von ALT und YR.ISOL unter 0.5 liegt.</p>
<p>Model averiging ist eine andere interessante Möglichkeit des Information theoreticion-Ansatzes und der Multimodel inference. Hier werden quasi alle möglichen Modelle oder alle Modelle mit einem ∆<em><sub>i</sub></em> unter einem bestimmten Schwellenwert zu einem gemittelten Modell zusammengefasst, gewichtet nach ihrem <em>W<sub>i</sub></em>-Wert. Am Ende bekommt man eine einzige gemittelte Funktion, deren Funktionsparameter man interpretieren und die man plotten kann.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>avgmodel <span class="ot">&lt;-</span> <span class="fu">model.avg</span>(<span class="fu">get.models</span>(<span class="fu">dredge</span>(model,<span class="at">rank=</span><span class="st">"AICc"</span>),<span class="at">subset=</span><span class="cn">TRUE</span>))</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(avgmodel)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb87"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>full average) </span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>            Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    </span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>(Intercept) -0.29874   77.23966    78.39113   0.004    0.997    </span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>GRAZE       -4.64605    0.89257     0.91048   5.103    3e-07 ***</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>ALT          0.01282    0.02311     0.02340   0.548    0.584    </span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>YR.ISOL      0.01631    0.03883     0.03941   0.414    0.679 </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Man beachte, dass der Output auch einen <em>p</em>-Wert enthält, obwohl dieser im AIC-Kontext nicht sinnvoll ist.</p>
</section>
</section>
<section id="zusammenfassung-2" class="level2">
<h2 class="anchored" data-anchor-id="zusammenfassung-2">Zusammenfassung</h2>
<ul>
<li><p>Eine <strong>ANCOVA</strong> kommt zur Anwendung, wenn auf die abhängige Variable sowohl eine kategoriale als auch eine metrische Prädiktorvariable einwirken.</p></li>
<li><p>Auch eine <strong>polynomiale Regression</strong> ist ein lineares Modell und kann u.&nbsp;a. dazu dienen, auf einfache Weise einen unimodalen Zusammenhang zu beschreiben.</p></li>
<li><p><strong>Multiple Regressionen</strong> sind lineare Regressionen mit mehreren Prädiktoren.</p></li>
<li><p>Bei multiplen Regressionen muss man die <strong>weitgehende Unabhängigkeit</strong> der ins globale Modell eingespeisten Variablen sicherstellen.</p></li>
<li><p>Für die Suche nach dem <strong>minimalen adäquaten Modell</strong> kommen unterschiedliche Strategien infrage, wie die schrittweise Entfernung nicht-signifikanter Terme aus dem globalen Modell oder Auswahl des besten Modells aus allen möglichen Modellen mittels AICc.</p></li>
<li><p><strong>AICc</strong> ist ein Gütemass im <strong><em>information theoretician approach</em></strong>. AICc-Werte sind nur im Vergleich mit anderen AICc-Werten für die gleichen Daten informativ; dann bezeichnet der niedrigste AICc-Wert das beste Modell.</p></li>
<li><p>«Frequentist approach» («Standardstatistik») und «information theoretician approach» sind <strong>zwei verschiedene statistische «Philosophien»</strong>, die man nicht in ein und derselben Auswertung kombinieren sollte: also entweder <em>p</em>-Werte oder AICc-Werte; <em>R</em>² macht dagegen in beiden «Welten» Sinn.</p></li>
</ul>
</section>
<section id="weiterführende-literatur-2" class="level2">
<h2 class="anchored" data-anchor-id="weiterführende-literatur-2">Weiterführende Literatur</h2>
<ul>
<li><p><strong>Crawley, M.J. 2015. <em>Statistics – An introduction using R</em>. 2nd ed.&nbsp;John Wiley &amp; Sons, Chichester, UK: 339 pp.</strong></p>
<ul>
<li>Chapter 7: Regression (pp.&nbsp;140–141)</li>
<li>Chapter 9: Analysis of Covariance</li>
<li>Chapter 10: Multiple Regression</li>
<li>Chapter 12: Other Response Variables (p.&nbsp;233 [AIC])</li>
</ul></li>
<li><p>Burnham, K.P. &amp; Anderson, D.R. 2002. <em>Model selection and multimodel inference – a practical information-theoretic approach</em>. 2nd ed.&nbsp;Springer, New York, US: 488 pp.</p></li>
<li><p>Johnson, J.B. &amp; Omland, K.S. 2004. Model selection in ecology and evolution. <em>Trends in Ecology and Evolution</em> 19: 101–108.</p></li>
<li><p>Logan, M. 2010. <em>Biostatistical design and analysis using R. A practical guide</em>. Wiley-Blackwell, Oxford, UK: 546 pp., v.a.<br>
</p>
<ul>
<li>pp.&nbsp;208-253 (Multiple und nicht-lineare Regressionen)</li>
</ul></li>
<li><p>Quinn, P.Q. &amp; Keough, M.J. 2002. <em>Experimental design and data analysis for biologists</em>. Cambridge University Press, Cambridge, UK: 537 pp.</p></li>
</ul>
<!-- HIER WEITERMACHEN -->
</section>
</section>
<section id="statistik-4-komplexere-regressionsmethoden" class="level1">
<h1>Statistik 4: Komplexere Regressionsmethoden</h1>
<p><strong>Heute geht es hauptsächlich um <em>generalized linear models</em> (GLMs), die einige wesentliche Limitierungen von linearen Modellen überwinden. Indem sie Fehler- und Varianzstrukturen explizit modellieren, ist man nicht mehr an Normalverteilung der Residuen und Varianzhomogenität gebunden. Bei <em>generalized linear regressions</em> muss man sich zwischen verschiedenen Verteilungen und link-Strukturen entscheiden. Spezifisch werden wir uns die Poisson-Regressionen für Zähldaten und die logistische Regression für ja/nein-Daten anschauen. Danach folgt ein Einstieg in nicht-lineare Regressionen, die es erlauben, etwa Potenzgesetze oder Sättigungsfunktionen direkt zu modellieren. Zum Abschluss gibt es einen Ausblick auf Glättungsverfahren (LOWESS) und <em>general additive models</em> (GAMs).</strong></p>
<section id="lernziele-3" class="level2">
<h2 class="anchored" data-anchor-id="lernziele-3">Lernziele</h2>
<p><em>Ihr…</em> - <em>habt den Unterschied zwischen linearen und nicht-linearen Regressionen verstanden und könnt eine einfache <strong>nicht-lineare Regression</strong> in R implementieren;</em> - <em>habt verstanden, worin sich <strong>GLMs</strong> von linearen Regressionen unterscheiden und wann sie zur Anwendung kommen; könnt die beiden häufigsten GLM-Typen l<strong>ogistische Regression</strong> und <strong>(Quasi-) Poisson-Regression</strong> in R richtig anwenden und die Ergebnisse interpretieren; und</em></p>
<ul>
<li><em>wisst, wofür <strong>LOWESS</strong> und <strong>GAM</strong> stehen und wie man sie anwendet.</em></li>
</ul>
</section>
<section id="von-linearen-modellen-zu-glms" class="level2">
<h2 class="anchored" data-anchor-id="von-linearen-modellen-zu-glms">Von linearen Modellen zu GLMs</h2>
<section id="zwei-beispiele" class="level3">
<h3 class="anchored" data-anchor-id="zwei-beispiele">Zwei Beispiele</h3>
<p>Nehmen wir an, wir wollten modellieren, wie viele Besucher an einem Strandabschnitt zur Mittagszeit in Abhängigkeit von der herrschenden Lufttemperatur anzutreffen sind. Unsere Daten sehen folgendermassen aus und mit den bekannten Methoden können wir ein lm rechnen, dessen Ergebnis signifikant ist und sogar recht viel der Gesamtvarianz erklärt:</p>
<p><img src="./myMediaFolder/media/image68.emf.png" class="img-fluid"><img src="./myMediaFolder/media/image69.png" class="img-fluid"></p>
<p>Unsere abhängige Variable ist eine Zählung und verhält sich daher anders als eine echte metrische Variable (etwa einer Messung des pH-Wertes). <strong>Zähldaten</strong> stellen lineare Modelle (lm) vor <strong>vier Probleme:</strong></p>
<ul>
<li><p>Lineare Modelle sagen immer auch das Auftreten <strong>negativer Werte</strong> voraus, wohingegen <strong>absolute Häufigkeiten immer positive Ganzzahlen</strong> sind (im obigen Beispiel würde das Modell bereits im gefitteten Bereich, unter etwa 12&nbsp;°C, negative Menschen vorhersagen).</p></li>
<li><p>Nahezu immer sind Zähldaten <strong>rechtsschief verteilt</strong>, also nicht normalverteilt und auch nicht symmetrisch</p></li>
<li><p>Bei Zähldaten nimmt nahezu immer die <strong>Varianz mit dem Mittelwert zu</strong>.</p></li>
<li><p>Zähldaten folgen keiner kontinuierlichen (wie die Normalverteilung), sondern einer <strong>diskreten Verteilung</strong>.</p></li>
</ul>
<p>Theoretisch sind also die Voraussetzungen für ein lineares Modell bei Zähldaten nie erfüllt. In der Praxis gibt es aber Situationen, wo die Verletzung der Annahmen für das Modell nicht weiter problematisch ist und man mit einem lm zu korrekten Aussagen gelangen kann. Relativ problemlos funktioniert das (und wird auch noch häufig getan), wenn (a) alle Werte der Antwortvariablen weit von 0 entfernt sind und (b) die Werte der Antwortvariable um deutlich weniger als eine Grössenordnung (d.h. Faktor 10) variieren. Im obigen Beispiel beträgt der Quotient des grössten und kleinsten Wertes der Antwortvariablen 2000 / 12 = 167. Mit etwas Erfahrung sehen wir schon im Scatterplot, dass hier Linearität und Varianzhomogenität verletzt sind.</p>
<p>Ein anderes Beispiel, bei dem ein lineares Modell offensichtlich und immer scheitern würde, wäre eine Befragung von Touristen an Tagen unterschiedlicher Temperatur, ob sie schwimmen gegangen sind. Das Ergebnis könnte wie folgt aussehen (stark gekürzte Tabelle, an jedem Tag (d.h. bei gleicher Temperatur) wurden jeweils mehrere Touristen befragt):</p>
<p><img src="./myMediaFolder/media/image70.emf.png" class="img-fluid"></p>
<p>Bei solchen „binären Daten” bestehen zwei hauptsächliche Probleme für lineare Modelle:</p>
<ul>
<li><p>Die Werteverteilung ist nach unten und nach oben begrenzt.</p></li>
<li><p>Es gibt überhaupt nur zwei mögliche Werte, nein und ja, als 0 und 1 codiert.</p></li>
</ul>
</section>
<section id="die-idee-der-generalized-linear-models-glms" class="level3">
<h3 class="anchored" data-anchor-id="die-idee-der-generalized-linear-models-glms">Die Idee der Generalized linear models (GLMs)</h3>
<p><em>Generalized linear models</em> (GLMs)** verallgemeinern lineare Modelle (LMs)**, um Fälle wie die geschilderten (Zähldaten, Binärdaten, für weitere Beispiele siehe Crawley (2015)) modellieren zu können. „Generalisiert” heissen die GLMs aus folgenden drei Gründen:</p>
<ul>
<li><p>Alle LMs sind im Begriff GLM eingeschlossen (aber viele GLMs sind keine LMs).</p></li>
<li><p>Die <strong>Verteilung der „Zufallskomponente”</strong> (= Residuen) kann sich <strong>von einer Normalverteilung unterscheiden</strong> (muss aber aus der exponentiellen Familie von Verteilungen sein).</p></li>
<li><p>Die abhängige Variable kann <strong>auf verschiedene Weise mit den Prädiktoren verknüpft</strong> (<em>linked</em>) sein.</p></li>
</ul>
</section>
<section id="die-drei-komponenten-eines-glm" class="level3">
<h3 class="anchored" data-anchor-id="die-drei-komponenten-eines-glm">Die drei Komponenten eines GLM</h3>
<p>Ein GLM setzt sich aus drei Komponenten zusammen, die relativ frei kombiniert werden können (aber für bestimmte Zufallskomponenten gibt es Standard-Link-Funktionen):</p>
<ol type="1">
<li><strong>Zufallskomponente (d.&nbsp;h. die Verteilung der Residuen):</strong>
<ul>
<li>normal</li>
<li>binomial: z. B. ja/nein, tot/lebendig</li>
<li>Poisson: Zähldaten (funktioniert aber nicht immer)</li>
<li>gamma</li>
<li>negativ binomial (Dispersionsparameter muss geschätzt werden)</li>
</ul></li>
<li><strong>Systematische Komponente (d.&nbsp;h. die <em>x</em>-Werte):</strong> es ist alles möglich, was wir schon von LMs her kennen:
<ul>
<li>kontinuierliche (metrische) Prädiktoren</li>
<li>kategoriale Prädiktoren</li>
<li>Interaktionen von Prädiktoren</li>
<li>polynomiale Funktionen</li>
<li>jewede Kombination aus den vorhergehenden Elementen</li>
</ul></li>
<li>Link-Funktion:
<ul>
<li>Identität (<em>identity</em>)</li>
<li>log (für Zähldaten)</li>
<li>logit (für Binärdaten)</li>
</ul></li>
</ol>
</section>
<section id="mögliche-verteilungen-von-werten-und-von-varianzen" class="level3">
<h3 class="anchored" data-anchor-id="mögliche-verteilungen-von-werten-und-von-varianzen">Mögliche Verteilungen von Werten und von Varianzen</h3>
<p>Was mit verschiedenen <strong>Verteilungen der Residuen</strong> gemeint ist, veranschaulichen die folgenden beiden Abbildungen von vier Häufigkeitsverteilungen mit dem gleichen Mittelwert. Oben sind die <strong>kontinuierliche Normalverteilung</strong> und unten drei unterschiedliche diskrete Verteilungen (Poisson, negativ-binomial) zu sehen:</p>
<p><img src="./myMediaFolder/media/image71.emf.png" class="img-fluid"></p>
<p>Auch die <strong>Beziehung von Varianzen zum (vorhergesagten) Mittelwert</strong> müssen keinesfalls immer konstant sein, wie wir das von den linearen Modellen kennen. Vielmehr zeigen viele Datentypen eine systematische Veränderung der Varianz mit dem Mittelwert:</p>
<p><img src="./myMediaFolder/media/image72.jpeg" class="img-fluid"><br>
(aus Crawley 2015)</p>
</section>
<section id="typen-von-glms" class="level3">
<h3 class="anchored" data-anchor-id="typen-von-glms">Typen von GLMs</h3>
<p>Eine Übersicht gängige GLM-Typen bietet die folgende Tabelle (man beachte die uneinheitliche Gross-/Kleinschreibung der Verteilungen):</p>
<p><img src="./myMediaFolder/media/image73.emf.png" class="img-fluid"><br>
(übersetzt und modifiziert nach Šmilauer 2017)</p>
<p>Man beachte, dass ein GLM mit Normalverteilung (gaussian) und identity-Link identisch mit einem LM ist.</p>
<p>Wenn man dieser Anleitung strikt folgen würde (was auch Smilauer 2017 nicht tut), dürfte man LMs nur dann verwenden, wenn die Antwortvariable auch negative Werte annehmen kann und ansonsten ein Gamma-GLM rechnen. In Realität werden Gamma-GLMs aber fast ausschliesslich für <em>death and failure</em>-Daten verwendet, bei denen die Varianz mit dem Quadrat des Mittelwertes zunimmt.</p>
<p>GLMs mit binomialer, Poisson, Gamma- und Gauss (Normal)-Verteilung sind in Base R implementiert, für negative.binomial benötigt man das Package MASS. In diesem Kurs gehen wir im Detail nur auf die beiden meistbenutzten GLM-Typen ein, <strong>Poisson-Regression für Zähldaten</strong> und <strong>logistische Regression für Binärdaten</strong>. Mehr zu den übrigen Typen findet man u. a. in Crawley (2015), Dunn &amp; Smyth (2018) und Fox &amp; Weisberg (2019)</p>
</section>
<section id="das-fitten-und-die-modellgüte-von-glms" class="level3">
<h3 class="anchored" data-anchor-id="das-fitten-und-die-modellgüte-von-glms">Das Fitten und die Modellgüte von GLMs</h3>
<p>Bei einem <strong>linearen Modell (LM)</strong> wird die Lösung durch <strong>Minimierung der Summe der Abweichungsquadrate</strong> erzielt. Diese Lösung lässt sich direkt, immer eindeutig und sogar von Hand ausrechnen. GLMs dagegen fitten die Modelle in einem iterativen Verfahren, indem die <strong><em>Likelihood</em> maximiert</strong> wird. Deswegen spricht man auch von <em>Maximum likelihood</em> (ML). Nach erfolgtem Fitten werden die Werte mit der <strong>Umkehrfunktion der Link-Funktion</strong> auf die originale Skala zurücktransformiert.</p>
<p>Als Mass der Variabilität oder lack of fit wird bei GLMs die Devianz <em>D</em> verwendet, die folgendermassen definiert ist:</p>
<blockquote class="blockquote">
<p><em>D<sub>i</sub></em> = –2 × log likelihood (Modell<em><sub>i</sub></em> | Daten)</p>
</blockquote>
<p>Je nach GLM-Typ wird die Devianz anders berechnet:</p>
<p><img src="./myMediaFolder/media/image74.jpeg" class="img-fluid"><br>
(aus Crawley 2015)</p>
</section>
</section>
<section id="poisson-regressionen-für-zähldaten" class="level2">
<h2 class="anchored" data-anchor-id="poisson-regressionen-für-zähldaten">Poisson-Regressionen für Zähldaten</h2>
<section id="berechnung" class="level3">
<h3 class="anchored" data-anchor-id="berechnung">Berechnung</h3>
<p>Die Struktur des glm-Befehls in R ist genau identisch mit jenem des lm-Befehls. Nur muss man zusätzlich die Verteilung (family) und ggf. die Link-Funktion (wenn nicht die Standard-Link-Funktion der jeweiligen Verteilung) angeben. Schauen wir uns nun die Ergebnisse für unsere Zähldaten der Strandbesucher an, zunächst mit einem LM, dann mit einem Gauss-GLM und schliesslich mit einem Poisson-GLM:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>lm.strand <span class="ot">&lt;-</span> <span class="fu">lm</span>(Besucher<span class="sc">~</span>Temperatur)</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>glm.gaussian <span class="ot">&lt;-</span> <span class="fu">glm</span>(Besucher<span class="sc">~</span>Temperatur,<span class="at">family=</span>gaussian)</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>glm.poisson <span class="ot">&lt;-</span> <span class="fu">glm</span>(Besucher<span class="sc">~</span>Temperatur,<span class="at">family=</span>poisson)</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm.strand)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb89"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>            Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>(Intercept)  -855.01     290.54  -2.943 0.021625 *  </span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>Temperatur     67.62      11.80   5.732 0.000712 ***</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm.gaussian)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb91"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>            Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>(Intercept)  -855.01     290.54  -2.943 0.021625 *  </span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>Temperatur     67.62      11.80   5.732 0.000712 ***</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm.poisson)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb93"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>            Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>(Intercept) 3.500301   0.056920   61.49   &lt;2e-16 ***</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>Temperatur  0.112817   0.001821   61.97   &lt;2e-16 ***</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wie nach den Erläuterungen im vorigen Kapitel zu erwarten war, sind die Ergebnisse des LMs und des Gauss-GLMs vollkommen identisch. Jene des Poisson-GLMs sind dagegen anders, insbesondere viel höher signifikant.</p>
</section>
<section id="interpretation-und-visualisierung-der-ergebnisse" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-und-visualisierung-der-ergebnisse">Interpretation und Visualisierung der Ergebnisse</h3>
<p>Im Falle des lm können wir aus den Parameter-Schätzungen (Spalte Estimate im summary) direkt die sich ergebende Funktionsgleichung aufschreiben:</p>
<blockquote class="blockquote">
<p>Besucher = –855 + 68 ∙ Temperatur/°C</p>
</blockquote>
<p>Bei einem glm sind die Parameter-Schätzungen dagegen nicht direkt interpretierbar, da sie sich auf eine transformierte Skala beziehen, welche durch die Link-Funktion angegeben ist. Die Standard-Link-Funktion bei einem Poisson-GLM ist log, also der natürliche Logarithmus (ln). Unser Ergebnis lässt sich damit wie folgt schreiben:</p>
<blockquote class="blockquote">
<p>ln (Besucher) = 3.50 + 0.11 ∙ Temperatur/°C</p>
</blockquote>
<p>Da uns aber nicht ln (Besucher), sondern die Besucherzahl selbst interessiert, müssen wir die Umkehrfunktion der Link-Funktion anwenden, bei ln also exp. Es ergibt sich:</p>
<blockquote class="blockquote">
<p>Besucher = exp (3.50 + 0.11 ∙ Temperatur/°C)</p>
</blockquote>
<p>Damit können wir auch die vorhergesagten Werte für verschiedene Temperaturen berechnen:</p>
<blockquote class="blockquote">
<p>0 °C: Besucher = exp (3.50) = 33</p>
<p>30 °C: Besucher = exp (3.50 + 30 ∙ 0.11) = exp. (6.83) = 925</p>
</blockquote>
<p>Wenn wir das Ganze Plotten wollen, benötigen wir den predict- und den lines-Befehl. Wie man, sieht muss auch hier auf die vorhergesagten Werte beim Plotten noch die Umkehrfunktion (exp) angewandt werden:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>xv <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">40</span>,<span class="at">by=</span>.<span class="dv">1</span>)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Temperatur,Besucher,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">40</span>))</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>yv <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm.strand,<span class="fu">list</span>(<span class="at">Temperatur=</span>xv))</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xv, yv,<span class="at">lwd=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">"blue"</span>)</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>yv2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(glm.poisson,<span class="fu">list</span>(<span class="at">Temperatur=</span>xv))</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(xv, <span class="fu">exp</span>(yv2),<span class="at">lwd=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">"red"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image75.png" class="img-fluid"></p>
</section>
<section id="overdispersion-als-problem" class="level3">
<h3 class="anchored" data-anchor-id="overdispersion-als-problem">Overdispersion als Problem</h3>
<p>Mathematisch beschreibt die Poisson-Verteilung Ereignisse pro Zeiteinheit, wenn sie mit einer bestimmten Rate (Mittelwert) erfolgen, die Ereignisse selbst aber unabhängig voneinander sind. Für ökologische/umweltwissenschaftliche Zähldaten sind diese Voraussetzungen oft nicht exakt gegeben, sie folgen daher nicht immer genau einer Poisson-Verteilung, sondern weisen teilweise eine <em>Overdispersion</em> auf. Für eine Poisson-Regression wird eine <strong>Dispersion = <em>Residual deviance</em> / <em>Residual degrees of freedom</em> = 1</strong> angenommen. Wenn die Dispersion wesentlich/signifkant grösser als 1 ist, liegt <em>Overdispersion</em> vor. Residual deviance und Residual degrees of freedom findet man im summary des glm:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm.poisson)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb96"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>[…]</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>(Dispersion parameter for poisson family taken to be 1)</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>    Null deviance: 6011.8  on 8  degrees of freedom</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>Residual deviance: 1113.7  on 7  degrees of freedom</span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>AIC: 1185.1</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Man sieht hier, dass der Quotient von 1113.7 und 7 weit höher als 1 ist. Mit dem Dispersionstest im Package AER kann man formal auf einen signifikanten Unterschied testen:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AER)</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dispersiontest</span>(glm.poisson)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb98"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>data:  glm.poisson</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>z = 3.8576, p-value = 5.726e-05</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>alternative hypothesis: true dispersion is greater than 1</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>sample estimates:</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>dispersion </span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>  116.5467 </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wenn man eine signifikante <em>Overdispersion</em> gefunden hat, gibt es zwei Lösungsmöglichkeiten:</p>
<ol type="1">
<li><strong>Quasi-Poisson-Verteilung</strong>. Hierbei schätzt der Algorithmus den Dispersionsparameter aus den Daten und passt die angenommene Verteilung entsprechend an. Die Methode ist im Befehl glm in Base R implementiert:</li>
</ol>
<div class="sourceCode" id="cb99"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>glm.quasi <span class="ot">&lt;-</span> <span class="fu">glm</span>(Besucher<span class="sc">~</span>Temperatur,<span class="at">family=</span>quasipoisson)</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm.quasi)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb100"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>            Estimate Std. Error t value Pr(&gt;|t|)   </span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>(Intercept)  3.50030    0.69639   5.026  0.00152 **</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>Temperatur   0.11282    0.02227   5.065  0.00146 **</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>(Dispersion parameter for quasipoisson family taken to be 149.6826)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Man sieht, dass im Vergleich zur Berechnung mit einem einfachen Poisson-GLM die Parameterschätzungen nicht verändert haben, jedoch die Signifikanzen niedriger ausgefallen sind (d.&nbsp;h. höhere <em>p</em>-Werte).</p>
<ol start="2" type="1">
<li><strong>Negativ-binomiale Verteilung:</strong> Oftmals erzielt man damit ähnliche, in besonderen Fällen allerdings auch deutlich andere Ergebnisse. Was besser ist, hängt vom Einzelfall ab und ist u. U. recht „tricky”. Weitere Details, siehe Ver Hoef &amp; Boveng (2007).</li>
</ol>
</section>
</section>
<section id="logistische-regressionen-für-binärdaten" class="level2">
<h2 class="anchored" data-anchor-id="logistische-regressionen-für-binärdaten">Logistische Regressionen für Binärdaten</h2>
<p>Logistische Regressionen werden für alle binären Antwortvariablen verwendet, etwa für Vorkommensdaten (Inzidenzdaten). Das folgende Abbildungspaar zeigt links, was passieren würde, wenn man solche Daten mit einem lm fitten würde und rechts, die korrekte Modellierung mit einem logistischen glm:</p>
<p><img src="./myMediaFolder/media/image76.jpeg" class="img-fluid"><br>
(aus Logan 2010)</p>
<section id="prinzipielles-vorgehen" class="level3">
<h3 class="anchored" data-anchor-id="prinzipielles-vorgehen">Prinzipielles Vorgehen</h3>
<ul>
<li><p>Die abhängige Variable muss als Vektor vorliegen, der entweder nur 0 und 1 enthält oder aber ein Faktor mit genau zwei Level ist.</p></li>
<li><p>Es wird ein <strong>glm mit family=binomial</strong> gerechnet.</p></li>
<li><p>Der voreingestellte <strong>Link ist logit</strong>, alternativ geht auch log-log.</p></li>
<li><p>Overdispersion ist bei Binärdaten nicht relevant.</p></li>
<li><p>Wie bei allen (multiplen) Modellen müssen wir eine <strong>Modellvereinfachung</strong> des vollen Modells vornehmen, wofür im Prinzip die gleichen drei Methoden zur Verfügung stehen, die wir schon kennen:</p>
<ul>
<li><p><strong>Modellselektion I:</strong> sukzessive Vereinfachung durch Entfernen nicht-signifkanter Terme.</p></li>
<li><p><strong>Modellselektion II:</strong> sukzessive Vereinfachung mittels Vergleich der Devianzen zweier Modelle mit Chi-Quadrat-Test (Achtung: Unterschied zu lm, wo wir eine ANOVA, d.&nbsp;h. eine F-Test verwendet haben).</p></li>
<li><p><strong>Modellselektion III:</strong> mittels AICc: Berechnung aller möglichen Modelle und dann entweder Auswahl jenes mit dem niedrigsten AICc oder Multimodel inference.</p></li>
</ul></li>
</ul>
</section>
<section id="die-theorie-dahinter" class="level3">
<h3 class="anchored" data-anchor-id="die-theorie-dahinter">Die Theorie dahinter</h3>
<p>Das <strong>„logit” (<em>L</em>)</strong> ist ein zentrales Element der logistischen Regression. Ein logit ist als der natürliche Logarithmus eines „odds” definiert. <strong>„Odds”</strong> hatten wir schon kurz beim Vierfelder-Assoziationstest (Chi-Quadrat- bzw. Fishers exakter Test). Sie bezeichnen die Wahrscheinlichkeit eines Ereignisses durch die „Gegenwahrscheinlichkeit”. Es gilt also Folgendes:</p>
<p><span class="math display">\[L = \ln\left( \frac{p}{1 - p} \right)\]</span></p>
<p>Warum arbeitet man mit „odds” und „logits”? Wenn man nur p modellieren würde, wären die möglichen Werte auf 0 … 1 begrenzt. „Odds” dagegen können Werte zwischen 0 und ∞ annehmen. Der Logarithmus schliesslich sorgt für eine symmetrische Verteilung der originalen Wahrscheinlichkeiten unter 50&nbsp;% (jetzt zwischen –∞ und 0) und der originalen Wahrscheinlichkeiten über 50&nbsp;% (jetzt zwischen 0 und +∞).</p>
<p>Bei GLMs wir ja immer die abhängige Variable mit der Link-Funktion transformiert. Damit modelliert eine logistische Regression das folgende Modell (in einer multiplen logistischen Regression ggf. auch mit <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub> usw.):</p>
<p><span class="math display">\[\ln\left( \frac{\pi(y)}{1 - \pi(y)} \right) = \ \beta_{0} + \beta_{1}x\]</span></p>
</section>
<section id="modelldiagnostik-und-ergebnisse" class="level3">
<h3 class="anchored" data-anchor-id="modelldiagnostik-und-ergebnisse">Modelldiagnostik und Ergebnisse</h3>
<p>Die Beurteilung von Validität und Güte/Relevanz eines logistischen Modells unterscheidet sicher erheblich von einem lm:</p>
<ul>
<li><p>Eine visuelle Inspektion der Residualplots ist hier nicht informativ.</p></li>
<li><p>Es gibt diverse numerische <strong><em>Goodness-of-fit</em>-Tests</strong> für das Modell, am einfachten der Vergleich der Abweichung der Devianz (<em>G</em>²) von der geforderten Χ²-Verteilung.</p></li>
<li><p>Das konventionelle Gütemass <em>R</em>² funktioniert ebenfalls nicht. Statt dessen kann man die Modellgüte mit einem <strong>Pseudo-<em>R</em>²</strong> ausdrücken:</p></li>
</ul>
<blockquote class="blockquote">
<p><span class="math inline">\(R^{2}\)</span>= <span class="math inline">\(1 -\)</span> <span class="math inline">\(\frac{Devianz\ Total}{Devianz\ Residuen}\)</span></p>
</blockquote>
<p>Da nicht die abhängige Variable (d.&nbsp;h. die Auftretenswahrscheinlichkeit), sondern ihr <em>logit</em> modelliert wurde, muss man die beiden Parameterschätzungen erst in informative Grössen übersetzen. Es sind dies:</p>
<ul>
<li><p><strong>Lagemass</strong> (d.&nbsp;h. bei welchem <em>x</em><sub>1</sub>-Wert ist die Wahrscheinlichkeit von 0 und 1 gleich hoch; auch als „LD50” = „lethal” does for 50% of the individuals” bezeichnet, basierend auf Anwendungen on logistischen Regressionen in Toxizitätstests): <strong>–β<sub>0</sub> / β<sub>0</sub></strong></p></li>
<li><p><strong>Steilheitsmass</strong> (d.h. wie scharf/steil ist der Übergang von 0 zu 1, ausgedrückt als die relative Änderung der „odds” bei Zunahme von <em>x</em><sub>1</sub> um eine Einheit): <strong>exp (β<sub>1</sub>)</strong></p></li>
</ul>
</section>
<section id="umsetzung-in-r" class="level3">
<h3 class="anchored" data-anchor-id="umsetzung-in-r">Umsetzung in R</h3>
<p>Schauen wir uns diese ganzen Schritte im Fall unseres Bade-Beispiels an, also der Wahrscheinlichkeit, dass eine Person am Strand schwimmen geht in Abhängigkeit von der Temperatur. Die Definition des Modells in R ist wie gehabt einfach:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">glm</span>(bathing<span class="sc">~</span>temperature,<span class="at">data=</span>bathing,<span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb102"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>Coefficients</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>            Estimate Std. Error z value Pr(&gt;|z|)  </span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>(Intercept)  -5.4652     2.8501  -1.918   0.0552 .</span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>temperature   0.2805     0.1350   2.077   0.0378 *</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Die uns interessierenden Aspekte <strong>Modelldiagnostik, Modellgüte und Kurvenverlauf</strong> müsse wir uns daher erst händisch aus dem abgespeicherten Objekt model extrahieren, indem wir auf einzelne darin abgespeicherte Daten zurückgreifen:</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Modeldiagnostik (wenn nicht signifikant, dann OK)</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span> (model<span class="sc">$</span>deviance,model<span class="sc">$</span>df.resid)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb104"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>[1] 0.6251679</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb105"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Modellgüte (pseudo-R²)</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> (model<span class="sc">$</span>dev <span class="sc">/</span> model<span class="sc">$</span>null)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb106"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>[1] 0.4775749</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Steilheit der Beziehung (relative Änderung der </span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a><span class="co"># odds von x + 1 vs.x)</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(model<span class="sc">$</span>coefficients[<span class="dv">2</span>])</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb108"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>temperature</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>1.323807</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb109"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co">#LD50 (also hier: Temperatur, bei der 50% der Touristen baden)</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span>model<span class="sc">$</span>coefficients[<span class="dv">1</span>]<span class="sc">/</span>model<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb110"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>(Intercept)</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>19.48311</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Der erste Wert gibt die Steilheit der Beziehung an und ob sie ansteigend oder fallend ist, wobei 1 keinen Effekt, &gt;1 eine ansteigende Häufigkeit und &lt; 1 eine fallende Häufigkeit bezeichnen. Der zweite Wert (man beachte das Minus-Zeichen in der Formel!) gibt den <em>x</em>-Wert an, für den die berechnete Wahrscheinlichkeit (Vorkommenswahrscheinlichkeit, Sterbewahrscheinlichkeit, usw.) genau 50 % ist.</p>
<p>Ganz einfach vorzustellen ist eine logistische Funktion auch mit diesen Werten noch nicht. Deswegen sollten wir im Falle signifkanter logistischer Regressionen immer zwei Dinge tun: (1) Die Funktionsgleichung angeben und (2) Das Ergebnis visualisieren.</p>
<ol type="1">
<li>Die Funktionsgleichung zu extrahieren, ist etwas vertrackt, da wir ja nicht die Auftretenswahrscheinlichkeit <em>y</em>, sondern ihren <em>logit</em> modelliert haben. Übersetzt bedeuten die Estimate-Werte unseres summary also:</li>
</ol>
<blockquote class="blockquote">
<p>ln (<em>y</em> / (1 – <em>y</em>)) = <em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em></p>
</blockquote>
<p>Wir formen sukzessive um, um nach y aufzulösen:</p>
<blockquote class="blockquote">
<p><em>y</em> / (1 – <em>y</em>) = exp (<em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em>)</p>
<p><em>y</em> = (exp (<em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em>) (1 – y)</p>
<p><em>y</em> = exp (<em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em>) – y exp (<em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em>)</p>
<p><em>y</em> + y exp (<em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em>) = exp (<em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em>)</p>
<p><em>y</em> (1 + exp (<em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em>)) = exp (<em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em>)</p>
<p><em>y =</em> exp (<em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em>) / (1 + exp (<em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> <em>x</em>))</p>
</blockquote>
<p>Oder mit den Werten in unserem Fall:</p>
<blockquote class="blockquote">
<p><em>y =</em> exp (–5.47 + 0.28 <em>x</em>) / (1 + exp (–5.47 + 0.28 <em>x</em>))</p>
</blockquote>
<ol start="2" type="1">
<li>Das Visualisieren geht relativ einfach mit dem predict-Befehl (hier einschliesslich Standardfehler):</li>
</ol>
<div class="sourceCode" id="cb111"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>xs <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">30</span>,<span class="at">l=</span><span class="dv">1000</span>)</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>model.predict <span class="ot">&lt;-</span><span class="fu">predict</span>(model,<span class="at">type=</span><span class="st">"response"</span>,<span class="at">se=</span>T,<span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">temperature=</span>xs))</span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bathing<span class="sc">~</span>temperature,<span class="at">data=</span>bathing,<span class="at">xlab=</span><span class="st">"Temperature (°C)"</span>,<span class="at">ylab=</span>„% Bathing<span class="st">",pch=16, col="</span>red<span class="st">")</span></span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a><span class="st">points(model.predict$fit ~ xs,type="</span>l<span class="st">")</span></span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a><span class="st">lines(model.predict$fit+model.predict$se.fit ~ xs, type="</span>l<span class="st">",lty=2)</span></span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a><span class="st">lines(model.predict$fit-model.predict$se.fit ~ xs, type="</span>l<span class="st">",lty=2)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image77.png" class="img-fluid"></p>
</section>
</section>
<section id="nicht-lineare-regressionen" class="level2">
<h2 class="anchored" data-anchor-id="nicht-lineare-regressionen">Nicht-lineare Regressionen</h2>
<section id="beispiele" class="level3">
<h3 class="anchored" data-anchor-id="beispiele">Beispiele</h3>
<p>Nicht-lineare Regressionen finden für funktionelle Beziehungen Anwendung, bei der sich die abhängige Grösse nicht als Linearkombination der Prädiktorvariable(n) darstellen lässt, z. B. wenn diese in Potenzen oder Quotienten auftaucht. (Eine polynomiale Regression ist dagegen, wie wir gesehen haben, immer noch ein lineares Modell, wenngleich eine nicht-lineare Beziehung modelliert wird.)</p>
<p>Zwei häufige Anwendungen nicht-linearer Regressionen sind die Potenzfunktion und verschiedene Sättigungsfunktionen:</p>
<p><strong>Beispiel 1: Potenzfunktion</strong></p>
<p><span class="math inline">\(y=b_0x^b\)</span>, oft auch als <span class="math inline">\(y = c x^z\)</span></p>
<ul>
<li><p>Dieses dürfte die am häufigeten verwendet nicht-lineare Funktion sein; sie tritt in fast allen Wissensdisziplinen auf (Nekola &amp; Brown 2007).</p></li>
<li><p><em>b</em><sub>0</sub> bzw. <em>c</em> bezeichnen dabei den vorhergesagten Wert der abhängigen Variable, wenn die unabhängige den Wert 1 hat (da log (1) = 0); der Exponent <em>b</em><sub>1</sub> bzw. <em>z</em> beschreibt dagegen die Geschwindigkeit der relativen Zunahme (<em>z</em> = 1 wäre eine lineare Beziehung).</p></li>
<li><p>Solange nicht-lineare Regressionen nicht als einfach verfügbares statistisches Tool bereitstanden, wurden Potenzgesetze durch Logarithmierung beider Achsen in eine lineare Beziehung überführt und mit linearen Modellen analysiert (log <em>y</em> = log <em>b</em><sub>0</sub> + <em>b</em><sub>1</sub> log <em>x</em>).</p></li>
<li><p>Das geht gut, solange keine Nullwerte von <em>y</em> vorliegen (für die der Logarithmus nicht definiert wäre).</p></li>
<li><p>Man muss aber beachten, dass sich die Ergebnisse unterscheiden, je nachdem, ob man <em>y</em> oder log (<em>y</em>) als abhängige Variable hat. Die beiden Parameterschätzungen sind meist ähnlich, <em>p</em>- und <em>R</em>²-Werte können sich dagegen erheblich unterscheiden und sind zwischen beiden Herangehensweisen nicht vergleichbar. Je nach Situation können aber beide ihre Berechtigung haben (vgl. Dengler 2009).</p></li>
</ul>
<p><strong>Beispiel 2: Sättigungsfunktionen</strong></p>
<ul>
<li><p>Sogenannte Sättigungsfunktionen finden Anwendung, wenn es nach der Theorie einen oberen Grenzwert für <em>y</em> gibt, dem sich die Funktion mit zunehmendem <em>x</em> asymptotisch annähert.</p></li>
<li><p>Eine aus der Enzymkinetik stammende, wegen ihrer Einfachheit aber auch in diversen anderen Disziplinen angewandte Sättigungsfunktion ist die Michaelis-Menten-Funktion:</p></li>
</ul>
<p><span class="math display">\[
y = \frac{b_0}{b_1+x}
\]</span></p>
<ul>
<li><p>Hierbei steht <em>b</em><sub>0</sub> für den oberen Grenzwert, <em>b</em><sub>1</sub> steht für die Steilheit des Anstiegs.</p></li>
<li><p>Es gibt zahlreiche weitere Sättigungsfunktionen, etwa auch eine Verallgemeinerung der logistischen Funktion (die wir als eines der GLM-Modelle kennengelernt haben). Siehe dazu das Unterkapitel „Umsetzung in R” unten.</p></li>
</ul>
</section>
<section id="unterschiede-von-linearen-und-nicht-linearen-regressionen" class="level3">
<h3 class="anchored" data-anchor-id="unterschiede-von-linearen-und-nicht-linearen-regressionen">Unterschiede von linearen und nicht-linearen Regressionen</h3>
<p><strong>Lineare Regression</strong></p>
<p><em>Y</em> ~ β<sub>0</sub> + β<sub>1</sub> <em>X</em><sub>1</sub> + β<sub>2</sub> <em>X</em><sub>2</sub> + β<sub>3</sub> <em>X</em><sub>3</sub> <em>+ …</em></p>
<p><em>X<sub>i</sub></em> kann sein - ein einzelner Prädiktor<br>
- ein transformierter Prädiktor, z.B. log (<em>X</em>), <em>X</em>²<br>
- eine Interaktion <em>X<sub>j</sub></em> × <em>X<sub>k</sub></em></p>
<p><strong>Nicht-lineare Regression</strong></p>
<p><em>Y</em> ~ beliebige Funktion von <em>X</em><sub>1</sub><em>, X</em><sub>2</sub><em>, …</em></p>
<p>„beliebige Funktion” schliesst ein:<br>
- Verhältnisse, z. B.: 1/<em>X</em>; <em>X<sub>i</sub></em>/<em>X<sub>j</sub></em><br>
- Potenzen, z. B. <em>X<sup>b</sup></em>, <em>b<sup>X</sup></em><br>
- <em>breakpoints</em>, z. B.: for <em>X</em> &lt; <em>b</em>: …; for <em>X</em> ≥ <em>b</em>: …</p>
<p>Bei der Berechnung von linearen vs.&nbsp;nicht-linearen Regressionen gelten folgende Besonderheiten:</p>
<ul>
<li><p><strong>Lineare Regressionen</strong> haben eindeutige Ergebnisse, die <strong>direkt berechnet</strong> werden können.</p></li>
<li><p>Ergebnisse <strong>nicht-linearer Regressionen</strong> sind nicht direkt analytisch zugängiglich, sondern nur über eine <strong>iterative Optimierungsprozedur</strong>. Das hat folgende Implikationen:</p>
<ul>
<li><p>Für die Iteratation sind Startwerte und (anfängliche) Schrittweiten erforderlich</p></li>
<li><p>Man weiss nie sicher, ob man das globale Optimum gefunden hat (oder in einem lokalen Optimum geendet ist).</p></li>
<li><p>Bei ungünstig gewählten Startwerten konvergiert die Iteration möglicherweise gar nicht.</p></li>
</ul></li>
</ul>
</section>
<section id="umsetzung-in-r-1" class="level3">
<h3 class="anchored" data-anchor-id="umsetzung-in-r-1">Umsetzung in R</h3>
<p>Der Befehl für nicht-lineare Regressionen ist nls, seine Syntax ganz ähnlich zu lm und glm. Die zu schätzenden Parameter muss man selbst benennen. Da die Lösung iterativ gefunden wird, muss man dem Befehl Startwerte für diese Parameter mitgeben.</p>
<p>Man kann beliebige Funktionen selbst definieren, hier gezeigt am Beispiel einer Potenzfunktion:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Selbsdefinierte Funktionen#</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>power.model <span class="ot">&lt;-</span> <span class="fu">nls</span>(ABUND<span class="sc">~</span>c<span class="sc">*</span>AREA<span class="sc">^</span>z, <span class="at">start=</span>(<span class="fu">list</span>(<span class="at">c=</span><span class="dv">0</span>,<span class="at">z=</span><span class="dv">1</span>)))</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(power.model)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb113"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>Formula: ABUND ~ c * AREA^z</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>Parameters:</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>  Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>c 13.39416    1.30721  10.246 2.87e-14 ***</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>z  0.16010    0.02438   6.566 2.09e-08 ***</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Oder man greift auf die in R bereits vordefinierten Funktionen (sogenannte <strong>Selbststartfunktionen</strong> [SS] zurück). Hier am Beispiel der logistischen Funktion als einer möglichen Sättigungsfunktion gezeigt (Man beachte, dass diese logistische Funktion nicht identisch mit jener aus der logistischen Regression ist, da wir es (a) mit einer nicht-binären Antwortvariable zu tun haben und (b) der Sättigungswert nicht automatisch 1 ist, sondern aus den Daten geschätzt wird). Mehr zu Selbststartfunktionen von nls findet man in der R-Hilfe, im Buch von Ritz &amp; Streibig (2008), sowie dem Auszug daraus, der in Moodle bereitsteht.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Vordefinierte "Selbststartfunktionen"#</span></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>logistic.model <span class="ot">&lt;-</span> <span class="fu">nls</span>(ABUND<span class="sc">~</span><span class="fu">SSlogis</span>(AREA, Asym, xmid, scal))</span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(logistic.model)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb115"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>Formula: ABUND ~ SSlogis(ABUND, Asym, xmid, scal)</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>Parameters:</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>     Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a>Asym   31.306      2.207  14.182  &lt; 2e-16 ***</span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a>xmid    6.501      2.278   2.854  0.00614 ** </span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a>scal    9.880      3.152   3.135  0.00280 ** </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Die grösste Herausforderung bei nls sind die <strong>Startwerte</strong>, da bei ungeeigneten Startwerten, das <strong>Modell möglicherweise gar nicht konvegiert oder in einem lokalen Optimum hängen bleibt</strong> und das globale Optimum nicht findet. Hier ist es wichtig, ein gutes Verständnis für die Funktionsparameter der jeweiligen Funktion zu haben und damit eine Erwartungshaltung, wie gross sie im Allgemeinen sind bzw. wie gross sie im konkreten Fall sein könnten. Für’s Allgemeine können wir die Theorie und ähnliche Untersuchungen in der Literatur konsultieren. Für den <em>z</em>-Wert einer Artenzahl-Areal-Beziehung, die mit Potenzgesetz modelliert wird, sagt uns die Theorie, dass dieser zwischen 0 und 1 liegen muss, und empirische Ergebnisse zeigen, dass er meist zwischen 0.2 und 0.25 liegt. Wenn wir hier also einen Startwert für <em>z</em> von –1 oder 1000 eingeben würden, hätte nls vermutlich ein Problem und würde kein Ergebnis oder ein falsches Ergebnis ausspucken. Bei der logistischen Regression wissen wir, dass der Parameter Asym für den Sättigungswert steht. In unserem Fall wäre also die maximale tatsächliche Artenzahl ein brauchbarer Startwert, den wir mit Blick auf die Originaldaten (summary oder Scatterplot) ermitten können.</p>
<p>Wenn wir zwischen unterschiedlichen nicht-linearen Modellen auswählen wollen, dann kommen dafür nur die Informationskriterien in Frage, da eine ANOVA hier nicht funktioniert (diese funktioniert nur für geschachtelte Modelle). Wollen wir unsere beiden zuvor berechneten Modelle vergleichen, brauchen wir das Package AICcmodavg:</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AICcmodavg)</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>cand.models <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>cand.models[[<span class="dv">1</span>]] <span class="ot">&lt;-</span> power.model</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>cand.models[[<span class="dv">2</span>]] <span class="ot">&lt;-</span> logistic.model</span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>Modnames <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Power"</span>, <span class="st">"Logistic"</span>)</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a><span class="fu">aictab</span>(<span class="at">cand.set =</span> cand.models, <span class="at">modnames =</span> Modnames)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb117"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>         K   AICc Delta_AICc AICcWt Cum.Wt      LL</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>Logistic 4 386.86       0.00   0.99   0.99 -189.04</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>Power    3 396.17       9.31   0.01   1.00 -194.86</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In unserem Fall wäre also das logistische Modell trotz einem zusätzlichen gefitteten Parameter (<em>k</em> = 4 statt <em>k</em> = 3; hier ist die geschätzte Varianz mitgezählt) das klar bessere Modell (<em>Akaike Weight</em> von 0.99).</p>
</section>
</section>
<section id="glättungsfunktionen-und-gams" class="level2">
<h2 class="anchored" data-anchor-id="glättungsfunktionen-und-gams">Glättungsfunktionen und GAMs</h2>
<section id="glättungsfunktionen" class="level3">
<h3 class="anchored" data-anchor-id="glättungsfunktionen">Glättungsfunktionen</h3>
<p><strong>Glättungsfunktionen (<em>smoother</em>)</strong> sind keine statistischen Verfahren** im eigentlichen Sinn. Vielmehr dienen sie der Visualisierung eines komplexen Zusammenhanges und können so helfen, geeignete inferenzstatistische Verfahren auszuwählen. Es gibt zahlreiche solche <em>smoother</em>:</p>
<ul>
<li>Gleitender Median</li>
<li>LOESS</li>
<li>LOWESS</li>
<li>Kernel</li>
<li>Splines</li>
<li>[…]</li>
</ul>
<p>Anhand von <strong>LOWESS (<em>Locally weighte scatterplot smoothing</em>)</strong> soll gezeigt werden, was ein smoother macht. In der Regel hat eine Glättungsfunktion zumindest einen wählbaren Parameter, welcher bestimmt, wie stark die Glättung ausfällt, im Fall von LOWESS ist dies f:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ABUND<span class="sc">~</span>log_AREA)</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(log_AREA,ABUND,<span class="at">f=</span><span class="fl">0.25</span>), <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">"red"</span>)</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(log_AREA,ABUND,<span class="at">f=</span><span class="fl">0.5</span>), <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">"blue"</span>)</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(log_AREA,ABUND,<span class="at">f=</span><span class="dv">1</span>), <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">"green"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image78.emf.png" class="img-fluid"></p>
</section>
<section id="gams-generalized-additive-models" class="level3">
<h3 class="anchored" data-anchor-id="gams-generalized-additive-models">GAMs (Generalized additive models)</h3>
<p><em>Generalised additive modesls</em> (GAMs) arbeiten auf den ersten Blick ähnlich wie <em>Smoother</em>, doch handelt es sich bei GAMs um ein inferenzstatistisches Verfahren:</p>
<ul>
<li><p>Bei einem GAM handelt es sich im Prinzip um ein lineares Modell (oder ein GLM), bei dem die einzelnen <strong>Parameter nicht fix, sondern eine <em>smoothing function</em></strong> sind:<br>
<em>y</em> = <em>β</em><sub>0</sub> + <em>f</em><sub>1</sub> (<em>x</em>) + <em>f</em><sub>2</sub> (<em>x</em>) + …</p></li>
<li><p>Man bekommt ein Modell mit den üblichen Gütemassen wie <em>p</em> oder AICc.</p></li>
<li><p>Die Freiheitsgrade sind geschätzt und nicht ganzzahlig.</p></li>
<li><p>Man muss <em>smoothing function</em> und <em>smoothing parameter</em> definieren.</p></li>
<li><p>(Man muss auch Link-Funktion und Wahrscheinlichkeitsverteilung angeben, wie bei GLMs).</p></li>
</ul>
<p>In R geht das folgendermassen (für den gleichen Datensatz, über den wir vorhin die <em>Smoother</em> haben laufen lassen). Da das Festlegen der smoothing parameter eine Kunst für sich ist, nehmen wir hier die default-Werte des Programms.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">gam</span>(ABUND<span class="sc">~</span><span class="fu">s</span>(log_AREA))</span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb120"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>Parametric coefficients:</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>            Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>(Intercept)  19.5143     0.9309   20.96   &lt;2e-16 ***</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a>Approximate significance of smooth terms:</span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a>              edf Ref.df     F  p-value    </span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a>s(log_AREA) 2.884  3.628 21.14 6.63e-11 ***</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a>R-sq.(adj) =  0.579   Deviance explained = 60.1%</span>
<span id="cb120-12"><a href="#cb120-12" aria-hidden="true" tabindex="-1"></a>GCV = 52.145  Scale est. = 48.529    n = 56</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wie wir sehen, bekommen wir für die Beziehung geschätzte Freiheitsgrade und einen geschätzten p-Wert. Der eigentliche Kurvenverlauf wird dagegen nicht in Parametern ausgedrückt und ist nicht direkt zugänglich. Wir können ihn jedoch plotten:</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(log_AREA, ABUND, <span class="at">pch=</span><span class="dv">16</span>) </span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>xv <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">4</span>, <span class="at">by=</span><span class="fl">0.1</span>) </span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>yv <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="fu">list</span>(<span class="at">log_AREA=</span>xv)) <span class="fu">lines</span>(xv, yv, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">"red"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image79.emf.png" class="img-fluid"></p>
<p>Zusammenfassend lässt sich sagen, dass GAMs zwar zu den inferenzstatistischen Verfahren gehörten, aber anders als alle anderen derartigen Verfahren, die wir im Kurs kennenlernen kein direkt zugängliches und interpretierbares Modell auspucken. Es ist also kaum möglich, GAMs zwischen verschiedenen Situationen zu vergleichen oder GAMs heranzuziehen, um ein mechanistisches Verständnis der zugrundeliegenden Prozesse zu entwickeln. GAMs sind vor allem dann beliebt, wenn man mutmasslich komplexe Beziehungen mit vielen Prädiktoren hat und es einem nicht um das Modell und seine Parameter an sich geht, sondern um möglichst gute Inter- und Extrapolation auf neue <em>x</em>-Werte. Ein beliebtes Feld sind sogenannte <em>species distribution models</em> (SDMs), die mit aktuellen Artvorkommens- und Umweltdaten „gefüttert” werden, um dann vorherzusagen, wie die Artverbreitung sich unter geänderten Umweltbedingungen (<em>global change</em>-Szenarien) ändern wird.</p>
</section>
</section>
<section id="zusammenfassung-3" class="level2">
<h2 class="anchored" data-anchor-id="zusammenfassung-3">Zusammenfassung</h2>
<ul>
<li><p><strong><em>Generalized linear models</em> (GLMs)</strong> erlauben Regressionen mit <strong>anderen Varianzstrukturen und Residuenverteilungen</strong> als lineare Regressionen.</p></li>
<li><p>Unter den GLMs sind zwei besonders gebräuchlich: <strong>logistische Regressionen</strong> werden für <strong>binäre Daten</strong>, <strong>(Quasi-) Poisson-Regressionen</strong> für <strong>Zähldaten</strong> verwendet.</p></li>
<li><p><strong>Nicht-lineare Regressionen</strong> erlauben die direkte <strong>Modellierung nicht-linearer und nicht-polynomialer Beziehungen</strong>.</p></li>
<li><p>Typische Fälle für nicht-lineare Regressionen sind die <strong>Potenzfunktion</strong> und verschiedene <strong>«Sättigungsfunktionen»</strong> (z. B. Michaelis-Menten-Funktion).</p></li>
<li><p><strong>LOWESS</strong> dient der <strong>Visualisierung eines Trends</strong> (explorative Datenanalyse).</p></li>
<li><p><strong><em>Generalized additive models</em> (GAMs)</strong> können sowohl zum selben Zweck aber auch zum Aufbauen von <strong>prädiktiven Modellen</strong> verwendet werden, haben aber anders als typische Regressionstechniken keine leicht interpretier- und vergleichbare Parameter.</p></li>
</ul>
</section>
<section id="weiterführende-literatur-3" class="level2">
<h2 class="anchored" data-anchor-id="weiterführende-literatur-3">Weiterführende Literatur</h2>
<ul>
<li><p><strong>Crawley, M.J. 2015. <em>Statistics – An introduction using R</em>. 2nd ed.&nbsp;John Wiley &amp; Sons, Chichester, UK: 339 pp.</strong></p>
<ul>
<li>Chapter 7: Regression (pp.&nbsp;142–145 [Non-linear regression], pp.&nbsp;146–148 [GAMs])**</li>
<li>Chapter 12: Other Response Variables</li>
<li>Chapter 13: Count Data</li>
<li>Chapter 15: Binary Response Variable</li>
</ul></li>
<li><p>Dengler, J. 2009. Which function describes the species-area relationshipbest? – A review and empirical evaluation. <em>Journal of Biogeography</em> 36: 728–744.</p></li>
<li><p>Dunn, P.K. &amp; Smyth, G.K. 2018. <em>Generalized linear models with examples in R</em>. Springer, New York, US: 562 pp.</p></li>
<li><p>Fox, J. &amp; Weisberg, S. 2019. <em>An R companion to applied regression</em>. 3rd ed.&nbsp;SAGE Publications, Thousand Oaks, CA, US: 577 pp.</p></li>
<li><p>Logan, M. 2010. <em>Biostatistical design and analysis using R. A practical guide</em>. Wiley-Blackwell, Oxford, UK: 546 pp., v.a.</p>
<ul>
<li>pp.&nbsp;178-179 (Smoother)</li>
<li>pp.&nbsp;208-253 (Multiple und nicht-lineare Regressionen)</li>
<li>pp.&nbsp;525-530 (GAMs)</li>
<li>pp.&nbsp;483-530 (GLMs)</li>
</ul></li>
<li><p>Nekola, J.C. &amp; Brown, J.H. 2007. The wealth of species: ecological communities, complex systems and the legacy of Frank Preston. <em>Ecology Letters</em> 10: 188–196.</p></li>
</ul>
<p>Quinn, P.Q. &amp; Keough, M.J. 2002. <em>Experimental design and data analysis for biologists</em>. Cambridge University Press, Cambridge, UK: 537 pp.</p>
<ul>
<li><p>Ritz, C. &amp; Streibig, J.C. 2008. <em>Nonlinear regression with R</em>. Springer, New York, US: 114 pp.</p></li>
<li><p>Šmilauer, P. 2017. <em>Modern regression methods. Chapter 2: Generalised linear models for counts and ratios</em>. Unpublished script, České Budějovice<em>,</em> CZ.</p></li>
<li><p>Ver Hoef, J.M. &amp; Boveng, P.L. 2007. Quasi-Poisson vs.&nbsp;negative binomial regression: how should we model overdispersed count data? <em>Ecology</em> 88:2766–2772.</p></li>
</ul>
</section>
</section>
<section id="statistik-5-von-linearen-modellen-zu-glmms" class="level1">
<h1>Statistik 5: Von linearen Modellen zu GLMMs</h1>
<p><strong>In Statistik 5 lernen die Studierenden Lösungen kennen, welche die diversen Limitierungen von linearen Modellen überwinden. Während <em>generalized linear models</em> (GLMs) aus Statistik 4 bekannt sind, geht es jetzt um <em>linear mixed effect models</em> (LMMs) und <em>generalized linear mixed effect models</em> (GLMMs). Dabei bezeichnet <em>generalized</em> die explizite Modellierung anderer Fehler- und Varianzstrukturen und <em>mixed</em> die Berücksichtigung von Abhängigkeiten bzw. Schachtelungen unter den Beobachtungen. Einfachere Fälle von LMMs, wie <em>split-plot</em> und <em>repeated-measures</em> ANOVAs, lassen sich noch mit dem aov-Befehl in Base R bewältigen, für komplexere Versuchsdesigns/Analysen gibt es spezielle R packages. Abschliessend gibt es eine kurze Einführung in GLMMs, die eine Analyse komplexerer Beobachtungsdaten z. B. mit räumlichen Abhängigkeiten, erlauben.</strong></p>
<section id="lernziele-4" class="level2">
<h2 class="anchored" data-anchor-id="lernziele-4">Lernziele</h2>
<p><em>Ihr…</em></p>
<ul>
<li><p><em>habt verstanden, welche Versuchsdesigns mit einer <strong>normalen (Typ I) zweifaktoriellen ANOVA</strong> analysiert werden können und welche die <strong>Spezifikation eines random factors</strong> erfordern;</em></p></li>
<li><p><em>könnt einfache Fälle von <strong>Repeated measures- und Split-plot ANOVAs</strong> in R spezifizieren und durchführen (mit aov bzw. lme); und</em></p></li>
<li><p><em>wisst, wann man <strong>generalized linear mixed effect models (GLMMs)</strong> anwenden sollte und wie das im Prinzip geht.</em></p></li>
</ul>
</section>
<section id="split-plot-und-repeated-measures-anovas" class="level2">
<h2 class="anchored" data-anchor-id="split-plot-und-repeated-measures-anovas">Split-plot und Repeated-measures ANOVAs</h2>
<section id="die-idee" class="level3">
<h3 class="anchored" data-anchor-id="die-idee">Die Idee</h3>
<p>Beginnen wir mit einer <strong>konventionellen 2-faktoriellen ANOVA</strong> wie wir sie aus Statistik 2 kennen. Wie in allen linearen Modellen (und ebenso in GLMs) ist eine wesentliche Modellvoraussetzung die Unabhängigkeit der Beobachtungen voneinander. In der folgenden Abbildung ist das für ein experimentelles Setting veranschaulicht, etwa unseren Sortenversuch mit Sorte A und B und den beiden Treatments Freiland und Gewächshaus:</p>
<p><img src="./myMediaFolder/media/image80.png" class="img-fluid"><br>
(aus Logan 2010)</p>
<p>Wir sehen, dass alle denkbaren Faktorenkombinationen (hier vier) auftreten (optimalerweise gleich häufig: balanciertes Design), sie aber räumlich zufällig, d.&nbsp;h. voneinander unabhängig angeordnet sind.</p>
<p>Im Gegensatz dazu stehen mehrfaktorielle ANOVAs, bei denen <strong>nicht alle Faktorenkombinationen existieren oder es Abhängigkeiten zwischen den Treatments</strong> gibt. Hier gibt es zwei Typen:</p>
<ol type="1">
<li><em>Split plot</em>-Design: Dies bezeichnet Situationen, bei denen die Kombinationen der beiden Faktoren nicht unabhängig voneinander räumlich verteilt sind, etwa weil dies mit zu grossem Aufwand verbunden wäre. Stellen wir etwa das Beispiel mit dem Gewächshaus-Freiland-Versuch von oben vor: Schon für die extrem geringe Replizierung von nur drei Wiederholungen pro Faktorenkombination müsste man sechs Gewächshäuser haben, jedes entweder mit Sorte A oder mit Sorte B, die man zudem räumlich zufällig platzieren kann. Logischerweise geht das oftmals nicht. Stattdessen könnte man drei Gewächshäuser haben, in denen man jeweils beide Sorten pflanzt. Dann wäre das Gewächshaus bzw. das entsprechende Freilandbeet der „<em>plot</em>”, der dann zwischen den beiden Sorten aufgeteilt (<em>split</em>) wird. Damit ist aber die Unabhängigkeitsannahme linearer Modelle verletzt, da sich ja die Gewächshäuser unterscheiden könnten, etwa in ihrer Thermoregulation, ihrer Lichtdurchlässigkeit oder ihrer Beschattung durch umstehende Bäume oder Gebäude. Deshalb hat potenziell die Frage, in welche Gewächshaus die Pflanzen standen, auch einen Einfluss auf das Ergebnis, muss mithin im statistischen Modell berücksichtigt werden</li>
</ol>
<p><img src="./myMediaFolder/media/image81.png" class="img-fluid"><br>
(aus Logan 2010)</p>
<ol start="2" type="1">
<li><em>Repeated measures</em>-Design: Hier geht es nicht um eine räumliche Bindung (enges Nebeneinander), sondern um eine zeitliche Bindung (zeitliches Nacheinander). Das heisst, an bestimmten Untersuchungsobjekten (Personen, Pflanzenindividuen, Untersuchungsflächen) wird zu verschiedenen Zeitpunkten eine Untersuchung vorgenommen, wie die folgende Abbildung es veranschaulicht:</li>
</ol>
<p><img src="./myMediaFolder/media/image82.png" class="img-fluid"><br>
(aus Logan 2010)</p>
<p>Während <em>split plot</em>-Design und <em>repeated measures</em>-Design auf den ersten Blick wie etwas Verschiedenes aussehen, so sind sie statistisch doch äquivalent.</p>
<p><img src="./myMediaFolder/media/image5.png" class="img-fluid"></p>
</section>
<section id="ein-beispiel-1" class="level3">
<h3 class="anchored" data-anchor-id="ein-beispiel-1">Ein Beispiel</h3>
<p>Fragestellung: Uns interessiert die Reaktionszeit von Personen auf Signale in Abhängigkeit von der Art der Signale (akustisch, visuell).</p>
<p>Versuchsanordnung:</p>
<ul>
<li><p>8 Versuchspersonen (VP1–VP8)</p></li>
<li><p>Je 4 davon zufällig den beiden Signaltypen (akustisch, visuell) zugeordnet</p></li>
<li><p>Messung der Reaktionszeit nach 1, 2, 3 und 4 h (H1–H4)</p></li>
</ul>
<p><strong>Wir haben hier drei wesentliche Abweichungen von einer normalen Typ I-ANOVA:</strong></p>
<ul>
<li><p>Wir sind nicht am spezifischen Verhalten der Versuchspersonen VP1–VP8 interessiert, sondern haben sie „zufällig” ausgewählt um alle möglichen Personen zu repräsentieren.</p></li>
<li><p>Jede Versuchsperson bekommt nur ein „Treatment”, d.&nbsp;h. es gibt nicht alle VP × Signal-Kombinationen.</p></li>
<li><p>Die vier gemessenen Reaktionszeiten einer Person sind nicht unabhängig voneinander: So könnten bestimmte Personen vielleicht immer etwas schneller oder langsamer sein als andere.</p></li>
</ul>
</section>
<section id="umsetzung-in-r-2" class="level3">
<h3 class="anchored" data-anchor-id="umsetzung-in-r-2">Umsetzung in R</h3>
<p>In unserem Fall ist also der Block-Faktor die Versuchperson (VP), einerseits, da jede Person nur einem der beiden Signaltypen ausgesetzt wurde, andererseits, weil wir mehrere Messungen über die Zeit mit ihr durchgeführt haben. Im aov-Befehl lässt sich das mit dem Error-Term spezifizieren:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>spf.aov <span class="ot">&lt;-</span> <span class="fu">aov</span>(Reaktion<span class="sc">~</span>Signal\<span class="sc">*</span>Messung <span class="sc">+</span> <span class="fu">Error</span>(VP), <span class="at">data =</span> spf)<span class="er">)</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(spf.aov)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb123"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>Error: VP</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>          Df Sum Sq Mean Sq F value Pr(&gt;F)</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a>Signal     1  3.125   3.125       2  0.207</span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a>Residuals  6  9.375   1.562               </span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a>Error: Within</span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true" tabindex="-1"></a>          Df Sum Sq Mean Sq F value   Pr(&gt;F)    </span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true" tabindex="-1"></a>Messung         3 194.50   64.83  127.89 2.52e-12 ***</span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true" tabindex="-1"></a>Signal:Messung3  19.37    6.46   12.74 0.000105 ***</span>
<span id="cb123-9"><a href="#cb123-9" aria-hidden="true" tabindex="-1"></a>Residuals 18   9.13    0.51</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Im Ergebnis erhalten wir eine zweigeteilte ANOVA-Tabelle: Der obere Teil sagt uns, dass der Effekt von Signal (Art des Signals), der in den Personen (VP) geblockt ist, nicht signifikant (<em>p</em> = 0.207) ist. Der untere Teil sagt uns, dass es einen signifikanten Effekt der Zeit sowie eine signifikante Interaktion Signaltyp × Zeit gibt. Ein Interkationsplot zeigt uns genau dieses:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">interaction.plot</span>(spf<span class="sc">$</span>Messung, spf<span class="sc">$</span>Signal, spf<span class="sc">$</span>Reaktion)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image83.png" class="img-fluid"></p>
<p>Der Plot macht klar, dass sich die Reaktionsheiten zwischen akustisch und optisch im Mittel nicht unterscheiden, sie aber im Fall von A2 schneller ansteigen als im Fall von A1</p>
<p>Mit dem Error-Term kann man auch mehrfache Schachtelungen codieren, jeweils links beginnend mit der obersten Ebene der Schachtelung:</p>
<p><strong>model2 &lt;- aov (Y ~ A * B * C + Error (Block/A/B), data = beispiel)</strong></p>
</section>
</section>
<section id="linear-mixed-effect-models-lmms" class="level2">
<h2 class="anchored" data-anchor-id="linear-mixed-effect-models-lmms">Linear mixed effect models (LMMs)</h2>
<section id="die-idee-1" class="level3">
<h3 class="anchored" data-anchor-id="die-idee-1">Die Idee</h3>
<p><em>Linear mixed effect models</em> (LMMs) verallgemeinern LMs, um Folgendes modellieren zu können:</p>
<ul>
<li><p>Abhängigkeiten/Schachtelungen zwischen Faktoren (um der Verletzung der LM-Voraussetzungen Rechnung zu tragen).</p></li>
<li><p>Faktoren, die uns nicht interessieren. Diese werden als sogenannte random factors modelliert, damit „sparen” wir Freiheitsgrade und gewinnen Teststärke für die uns interssierenden Faktoren.</p></li>
</ul>
<p>Die einfachsten LMMs, d.&nbsp;h. <em>Repeated measures</em>- und <em>Split plot</em>-ANOVA gehen (mit Limitierungen) noch mit dem aov-Befehl. Für komplexere Situationen bzw. im allgemeinen Fall (einschliesslich Regressionen und ANCOVAs) benötigt man dagegen lme aus dem Package nlme.</p>
<p>Analog zum Error-Term in aov spezifiziert man hier einen random-Term, wobei es zusätzlich die Möglichkeit gibt, zu entscheiden, ob man nur einen zufälligen Achsenabschnitt (<em>random intercept</em>) oder auch eine zufällige Steigung (<em>random slope</em>) modellieren möchte:</p>
</section>
<section id="umsetzung-in-r-3" class="level3">
<h3 class="anchored" data-anchor-id="umsetzung-in-r-3">Umsetzung in R</h3>
<div class="sourceCode" id="cb125"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nlme)</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>spf.lme<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lme</span>(Reaktion<span class="sc">~</span>Signal<span class="sc">*</span>Messung, <span class="at">random =</span> <span class="sc">~</span>Messung <span class="sc">|</span> VP, <span class="at">data =</span> spf) <span class="co">#mit random intercept (VP) und random slope (Messung)</span></span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>spf.lme<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lme</span>(Reaktion<span class="sc">~</span>Signal<span class="sc">*</span>Messung, <span class="at">random =</span> <span class="sc">~</span><span class="dv">1</span> <span class="sc">|</span> VP, <span class="at">data =</span> spf) <span class="co">#nur random intercept</span></span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(spf.lme<span class="fl">.1</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb126"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>               numDF denDF   F-value p-value</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>(Intercept)        1    18 1488.1631  &lt;.0001</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>Signal             1     6    2.0808  0.1993</span>
<span id="cb126-4"><a href="#cb126-4" aria-hidden="true" tabindex="-1"></a>Messung            3    18   70.7887  &lt;.0001</span>
<span id="cb126-5"><a href="#cb126-5" aria-hidden="true" tabindex="-1"></a>Signal:Messung     3    18   11.8592  0.0002</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb127"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(spf.lme<span class="fl">.2</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb128"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>               numDF denDF  F-value p-value</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>(Intercept)        1    18 591.6800  &lt;.0001</span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a>Signal             1     6   2.0000  0.2070</span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a>Messung            3    18 127.8904  &lt;.0001</span>
<span id="cb128-5"><a href="#cb128-5" aria-hidden="true" tabindex="-1"></a>Signal:Messung     3    18  12.7397  0.0001 </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>LMMs, ihr korrekte Implementierung und Interpretation können u.&nbsp;U. sehr komplex sein, weswegen wir sie in unserem Kurs nicht mit viel Details besprechen können. Wer weitergehende benutzerfreundliche Informationen sucht, sei insbesondere auf Logan (2010: pp.&nbsp;360–447) verwiesen.</p>
</section>
</section>
<section id="generalized-linear-mixed-effect-models-glmms" class="level2">
<h2 class="anchored" data-anchor-id="generalized-linear-mixed-effect-models-glmms">Generalized linear mixed effect models (GLMMs)</h2>
<section id="die-idee-2" class="level3">
<h3 class="anchored" data-anchor-id="die-idee-2">Die Idee</h3>
<p><em>Generlized linear mixed effect models</em> (GLMMs) verallgemeinern GLMs, um Folgendes modellieren zu können:</p>
<ul>
<li><p>Geschachtelte Daten</p></li>
<li><p>Zeitliche Korrelationen zwische Beobachtungen</p></li>
<li><p>Räumliche Korrelationen zwischen Beobachtungen</p></li>
<li><p>Heterogenität</p></li>
<li><p>Messwiederholungen</p></li>
</ul>
<p>Während dies alles wundervolle und oft benötigte Eigenschaften sind, sollte man sich auch der Nachteile/Limitierungen bewusst sein, wie die folgenden Zitate aus einem der führenden Lehrbücher zu GLMMs (Zuur et al.&nbsp;2009) zeigen:</p>
<ul>
<li><p><em>„GLMM are at the frontier of statistical research”</em></p></li>
<li><p><em>„This means that available documentation is rather technical and there are only few, if any, textbooks aimed at ecologists”</em></p></li>
<li><p><em>„There are multiple approaches for obtaining estimated parameters”</em></p></li>
<li><p><em>„There are at least four packages in R that can be used for GLMM”</em></p></li>
<li><p><em>„This makes model selection in GLMM more of an art than a science”</em></p></li>
</ul>
<p>Bezüglich der Anwendung von GLMMs, kommen Zuur et al.&nbsp;(2009) daher zu folgendem Schluss (der natürlich auch sonst in der Statistik gilt, hier aber besonders wichtig ist): <strong><em>When applying GLMM, try to keep the models simple or you may get numerical estimation problems</em></strong>.</p>
</section>
<section id="ein-beispiel-und-seine-umsetzung-in-r" class="level3">
<h3 class="anchored" data-anchor-id="ein-beispiel-und-seine-umsetzung-in-r">Ein Beispiel und seine Umsetzung in R</h3>
<p>Befall von Rothirschen (<em>Cervus elaphus</em>) in spanischen Farmen mit dem Parasiten <em>Elaphostrongylus cervi</em>. Modelliert wird Vorkommen/Nichtvorkommen von L1-Larven dieser Nematode in Abhängigkeit von Körperlänge und Geschlecht der Hirsche. Erhoben wurden die Daten auf 24 Farmen.</p>
<p>Wir können das Ganze wie bisher mit einem binomialen GLM analysieren:</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>DE.glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(Ecervi<span class="fl">.01</span> <span class="sc">~</span> CLength <span class="sc">*</span> fSex<span class="sc">+</span>fFarm,</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">family =</span> binomial, <span class="at">data =</span> DeerEcervi)</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(DE.glm)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb130"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>Coefficients:</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>                Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>(Intercept)   -1.796e+00  5.900e-01  -3.044 0.002336 ** </span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true" tabindex="-1"></a>CLength        4.062e-02  7.132e-03   5.695 1.24e-08 ***</span>
<span id="cb130-5"><a href="#cb130-5" aria-hidden="true" tabindex="-1"></a>fSex2          6.280e-01  2.292e-01   2.740 0.006150 ** </span>
<span id="cb130-6"><a href="#cb130-6" aria-hidden="true" tabindex="-1"></a>fFarmAU        3.340e+00  7.841e-01   4.259 2.05e-05 ***</span>
<span id="cb130-7"><a href="#cb130-7" aria-hidden="true" tabindex="-1"></a>fFarmBA        3.510e+00  7.150e-01   4.908 9.19e-07 ***</span>
<span id="cb130-8"><a href="#cb130-8" aria-hidden="true" tabindex="-1"></a>[…]</span>
<span id="cb130-9"><a href="#cb130-9" aria-hidden="true" tabindex="-1"></a>fFarmVY        3.974e+00  1.257e+00   3.162 0.001565 ** </span>
<span id="cb130-10"><a href="#cb130-10" aria-hidden="true" tabindex="-1"></a>CLength:fSex2  3.618e-02  1.168e-02   3.097 0.001953 ** </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Das Modell, das wir erzeugt haben, liesse sich folgendermassen visualisieren:</p>
<p><img src="./myMediaFolder/media/image84.emf.png" class="img-fluid"><br>
(aus Zuur et al.&nbsp;2009)</p>
<p>Für unseren Zweck hat die Lösung mit einem GLM zwei Nachteile:</p>
<ul>
<li><p>fFarm „verbraucht” 23 Freiheitsgrade, obwohl wir nicht am Farmeffekt interessiert sind.</p></li>
<li><p>Wir bekommen ein Modell für jede einzelne Farm, aber kein farmunabhängiges Modell.</p></li>
</ul>
<p>Beispiehaft analysieren wir dieses GLMM mit glmm.PQL aus dem Package MASS:</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>DE.PQL <span class="ot">&lt;-</span> <span class="fu">glmmPQL</span>(Ecervi<span class="fl">.01</span> <span class="sc">~</span> CLength <span class="sc">*</span> fSex,</span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">random =</span> <span class="sc">~</span> <span class="dv">1</span> <span class="sc">|</span> fFarm, <span class="at">family =</span> binomial, <span class="at">data =</span> DeerEcervi)</span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(DE.PQL)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb132"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>Random effects:</span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a> Formula: ~1 | fFarm</span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a>        (Intercept)  Residual</span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a>StdDev:    1.462108 0.9620576</span>
<span id="cb132-5"><a href="#cb132-5" aria-hidden="true" tabindex="-1"></a>[…]</span>
<span id="cb132-6"><a href="#cb132-6" aria-hidden="true" tabindex="-1"></a>Fixed effects: Ecervi.01 ~ CLength * fSex </span>
<span id="cb132-7"><a href="#cb132-7" aria-hidden="true" tabindex="-1"></a>                  Value Std.Error  DF  t-value p-value</span>
<span id="cb132-8"><a href="#cb132-8" aria-hidden="true" tabindex="-1"></a>(Intercept)   0.8883697 0.3373283 799 2.633547  0.0086</span>
<span id="cb132-9"><a href="#cb132-9" aria-hidden="true" tabindex="-1"></a>CLength       0.0378608 0.0065269 799 5.800768  0.0000</span>
<span id="cb132-10"><a href="#cb132-10" aria-hidden="true" tabindex="-1"></a>fSex2         0.6104570 0.2137293 799 2.856216  0.0044</span>
<span id="cb132-11"><a href="#cb132-11" aria-hidden="true" tabindex="-1"></a>CLength:fSex2 0.0350666 0.0108558 799 3.230228  0.0013</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wie wir das schon von ANOVAs mit Error-Term oder LMMs kennen, ist die Ergebnistabelle in einen Teil für die Random effects und einen Teil für die Fixed effects aufgeteilt. Für fFarm gibt es jetzt aber anders als beim GLM nicht 23 Schätzwerte, sondern nur einen für die Standardabweichung. Der untere Teil entspricht dagegen dem Output eines GLMs, wenn wir fFarm völlig ignoriert hätten: wir haben die Effekte von Grösse, Geschlecht und deren Interaktion (alle signifikant).</p>
<p>Was sagen uns die Ergebnisse nun?</p>
<ul>
<li>Wahrscheinlichkeit des Parasitenbefalls für weibliche Hirsche:</li>
</ul>
<blockquote class="blockquote">
<p>logit (<em>p<sub>ij</sub></em>) = 0.888 + 0.037 ∙ Length<em><sub>ij</sub></em></p>
</blockquote>
<ul>
<li>Wahrscheinlichkeit des Parasitenbefalls für männliche Hirsche:</li>
</ul>
<blockquote class="blockquote">
<p>logit (<em>p<sub>ij</sub></em>) = (0.888 + 0.610) + (0.037 + 0.035) ∙ Length<em><sub>ij</sub></em></p>
<p>logit (<em>p<sub>ij</sub></em>) = 1.498 + 0.072 ∙ Length<em><sub>ij</sub></em></p>
</blockquote>
<p>Da die Codierung Sex2 = „männlich” war und wir sowohl ein „random intercept” als auch ein „random slope” modelliert haben, ergibt sich der Achsenabschnitt für die männlichen Hirsche durch die Addition des allgemeinen Achsenabschnitts (der sich auf Sex1 = „weiblich” bezieht) und dem Effekt von Sex2, während sich die Steigung für die männlichen Hirsche aus jener für die weiblichen + den Interkationsterm ergibt.</p>
<p>Da wir es mit einem Binomial-GLMM zu tun haben, sagen uns die gefundenen Gleichungen immer noch nicht unmittelbar etwas über die Beziehungen, da auf der linken Seite der Gleichung jeweils logit (<em>p<sub>ij</sub></em>) und nicht <em>p<sub>ij</sub></em> steht. Wir könnten wie in Statistik 4 nach <em>p<sub>ij</sub></em> auflösen oder wir nutzen eine Visualisierung. Im Folgenden ist z.&nbsp;B. die GLMM-Vorhersage für weibliche Hirsche mit Konfidenzintervall geplottet, was schön den Unterschied zum GLM zeigt:</p>
<p><img src="./myMediaFolder/media/image85.png" class="img-fluid"><br>
(aus Zuur et al.&nbsp;2009)</p>
</section>
<section id="verschiedene-r-packages-für-glmms" class="level3">
<h3 class="anchored" data-anchor-id="verschiedene-r-packages-für-glmms">Verschiedene R-packages für GLMMs</h3>
<p>Es gibt mehrere R-packages für GLMMs, von denen die folgenden die gängisten sind:</p>
<ul>
<li><p><strong>library(MASS): glmmPQL</strong></p></li>
<li><p><strong>library(lme4): glmer</strong></p></li>
<li><p><strong>library(glmmML): glmmML</strong></p></li>
</ul>
<p>Die Syntax der verschiedenen Packages unterscheidet sich im Detail, bitte bei Bedarf die jeweilige Hilfe-Funktion konsultieren.</p>
<p>Da ein GLMM ein sehr komplexes Verfahren ist, sind die verschiedenen Implementierungen nicht genau gleich. Insofern kann es auch leichte Divergenzen in den Parameterschätzungen und den Parametern geben, wie die folgende Auswertung für unser Hirschbeispiel zeigt:</p>
<p><img src="./myMediaFolder/media/image86.emf.png" class="img-fluid"><br>
(aus Zuur et al.&nbsp;2009)</p>
<p>In diesem Fall (und meist) sind die Abweichungen zwischen den drei GLMMs aber gering. Dagegen ist die Aussage deutlich verschieden von der mit dem GLM ermittelten (massiv andere Parameterschätzung für Sex, etwas andere für Length und Length × Sex).</p>
</section>
<section id="random-vs.-fixed-factors" class="level3">
<h3 class="anchored" data-anchor-id="random-vs.-fixed-factors">Random vs.&nbsp;fixed factors</h3>
<p>Wann sollten wir <em>random factors</em> nehmen, wann <em>fixed factors</em>? Im Hirsch-Beispiel ist statistisch klar, dass wir die Farm-Identität in unser statistisches Modell aufnehmen müssen, da auf jeder Farm mehrere Hirsche untersucht wurden und unser wissen über as universelle Phänomen der <strong>räumlichen Autokorrelation</strong> es höchstwahrscheinlich macht, dass sich die Hirsche einer einzelnen Farm (wg. räumlicher Nähe) ähnlicher verhalten als zufällig herausgegriffene Paare von Farm-Hirschen aus ganz Spanien.</p>
<p>Ob wir die Farm-Identität dagegen als <em>fixed factor</em> aufnehmen (d.&nbsp;h. ein GLM rechnen) oder als <em>random factor</em> (d.&nbsp;h. ein GLMM rechnen), hängt von unserer Frage ab. In der Beschreibung der Studie wurde suggeriert, dass es uns um ein allgemeines farmunabhängiges Modell ging, wie sich der Parasitenbefall in Abhängigkeit von Geschlecht und Grösse entwickelt. Dann wäre unser Vorgehen richtig, fFarm als <em>random factor</em> zu definieren. Wir dürfen und können dann aber keine Aussage über eine einzelne Farm treffen. Wenn uns dagegen interessiert, ob und wie sich die Farmen bezüglich Parasitenbefall unterscheiden, etwa weil sie unterschiedliche Hygienekonzepte oder Populationsdichten haben, dann müssen wir fFarm als <em>fixed factor</em> einführen (also ein GLM rechnen). Ob wir in einer solchen Situation ein GLM oder ein GLMM rechnen, hängt also von unserer genauen Frage ab.</p>
</section>
</section>
<section id="lms-glms-lmms-und-glmms-im-rückblick-und-überblick" class="level2">
<h2 class="anchored" data-anchor-id="lms-glms-lmms-und-glmms-im-rückblick-und-überblick">LMs, GLMs, LMMs und GLMMs im Rückblick und Überblick</h2>
<p>Zum Abschluss der fünf inferenzstatistischen Lektionen seien noch einmal die grundlegenden Ähnlichkeiten und Unterschiede von LMs, GLMs, LMMs und GLMMs zusammengefasst:</p>
<ul>
<li>LMs: <em>Linear models</em></li>
<li>GLMs: <em>Generalized linear models</em></li>
<li>LMMs: <em>Linear mixed effect models</em></li>
<li>GLMMs: <em>Generalized linear mixed effects models</em></li>
</ul>
<p><img src="./myMediaFolder/media/image87.emf.png" class="img-fluid"></p>
</section>
<section id="zusammenfassung-4" class="level2">
<h2 class="anchored" data-anchor-id="zusammenfassung-4">Zusammenfassung</h2>
<ul>
<li><p>Wenn in einem ANOVA-Design <strong>Schachtelungen oder Abhängigkeiten</strong> vorliegen, muss man diese im Modell spezifizieren, was entweder als <em>Error</em> in <em>aov</em> oder als <em>random</em> in <em>lme</em> (package <em>nlme</em>) geht.</p></li>
<li><p>Während GLMs lineare Modelle bezüglich der geforderten Residuen- und Varianzstruktur verallgemeinern, leisten <strong><em>linear mixed effect models</em> (LMMs)</strong> dies bezüglich unterschiedlichster Abhängigkeiten zwischen Beobachtungen.</p></li>
<li><p><strong><em>Generalized linear mixed effect models</em> (GLMMs)</strong> schliesslich ermöglichen, beide Typen von Abweichungen von den Voraussetzungen linearer Modelle zu berücksichtigen.</p></li>
</ul>
</section>
<section id="weiterführende-literatur-4" class="level2">
<h2 class="anchored" data-anchor-id="weiterführende-literatur-4">Weiterführende Literatur</h2>
<ul>
<li><p><strong>Crawley, M.J. 2015. <em>Statistics – An introduction using R</em>. 2nd ed. John Wiley &amp; Sons, Chichester, UK: 339 pp.</strong></p>
<ul>
<li>Chapter 8: Analysis of Variance (pp.&nbsp;173–182)</li>
</ul></li>
<li><p>Logan, M. 2010. <em>Biostatistical design and analysis using R. A practical guide</em>. Wiley-Blackwell, Oxford, UK: 546 pp., v.a.<br>
</p>
<ul>
<li>pp.&nbsp;399-447 (split-plot und repeated measures ANOVAs)</li>
</ul></li>
<li><p>Zuur, A. E., Ieno, E. N., Walker, N. J., Saveliev, A. A., Smith, G. M. (eds.) 2009. <em>Mixed effects models and extension in ecology with R</em>. Springer, New York: 576 pp.</p></li>
<li><p>Zuur, A.E., Hilbe, J.M. &amp; Ieno, E.N. 2013. <em>A beginner’s guide to GLM and GLMM with R – A frequentist and Bayesian perspective for ecologists</em>. Highland Statistics, Newburgh: 253 pp.</p></li>
</ul>
</section>
</section>
<section id="statistik-6-einführung-in-multivariate-methoden-und-ordinationen-i" class="level1">
<h1>Statistik 6: Einführung in „multivariate” Methoden und Ordinationen I</h1>
<p><strong>Statistik 6 führt in multivariat-deskriptive Methoden ein, die dazu dienen Datensätze mit multiplen abhängigen und multiplen unabhängigen Variablen effektiv zu analysieren. Dabei betonen Ordinationen kontinuierliche Gradienten und fokussieren auf zusammengehörende Variablen, während Cluster-Analysen Diskontinuitäten betonen und auf zusammengehörende Beobachtungen fokussieren. Es folgt eine konzeptionelle Einführung in die Idee von Ordinationen als einer Technik der deskriptiven Statistik, die Strukturen in multivariaten Datensätzen via Dimensionsreduktion visualisiert. Das Prinzip und die praktische Implementierung wird detailliert am Beispiel der Hauptkomponentenanalyse (PCA) erklärt. Danach folgen kurze Einführungen in weitere Ordinationstechniken für besondere Fälle, welche bestimmte Limitierungen der PCA überwinden, namentlich CA, DCA und NMDS.</strong></p>
<section id="lernziele-5" class="level2">
<h2 class="anchored" data-anchor-id="lernziele-5">Lernziele</h2>
<p><em>Ihr…</em></p>
<ul>
<li><p><em>versteht, <strong>was Ordinationen sollen</strong>, was sie leisten können und was nicht;</em></p></li>
<li><p><em>könnt das <strong>Prinzip einer PCA</strong> beschreiben, sie implementieren, und ihren Ergebnisoutput interpretieren;</em></p></li>
<li><p><em>Die Annahmen einer PCA kennt, und wisst welche «Artefakte» bei einer Verletzung herauskommen; und</em></p></li>
<li><p><em>habt das Vorgehen im Prinzip verstanden, wie <strong>DCA und NMDS</strong> diese Probleme angehen.</em></p></li>
</ul>
</section>
<section id="einführung-in-multivariate-methoden" class="level2">
<h2 class="anchored" data-anchor-id="einführung-in-multivariate-methoden">Einführung in „multivariate” Methoden</h2>
<section id="was-ist-mit-multivariat-gemeint" class="level3">
<h3 class="anchored" data-anchor-id="was-ist-mit-multivariat-gemeint">Was ist mit „multivariat” gemeint?</h3>
<p>Was ist mit <strong>„multivariat”</strong> gemeint? Zunächst einmal sagt das nur, dass pro Beobachtung (<em>observation</em>) <strong>mehr als zwei</strong> Variablen erhoben werden, deren Beziehungen zueinander analysiert werden. Im Wortsinne waren also auch schon die zweifaktorielle ANOVA und die multiple Regression „multivariate” Methoden.</p>
<p>Die folgende Tabelle fasst die schon besprochenen und noch kommenden statistischen Verfahren bezüglich der Anzahl von Prädiktor- und Antwortvariablen zusammen:</p>
<p><img src="./myMediaFolder/media/image88.emf.png" class="img-fluid"></p>
<p>In der Literatur wird der Begriff <strong>„multivariat”</strong> jedoch oft nur für die letzte Gruppe von Verfahren, also <strong>Ordinationen und Cluster-Analysen</strong>, gebraucht. Diese bilden den Gegenstand von Statistik 6–8.</p>
</section>
<section id="inferenzstatistik-vs.-deskriptive-statistik" class="level3">
<h3 class="anchored" data-anchor-id="inferenzstatistik-vs.-deskriptive-statistik">Inferenzstatistik vs.&nbsp;deskriptive Statistik</h3>
<p>Bislang haben wir statistische Verfahren überwiegend zum Testen von Hypothesen verwendet (inklusive des impliziten Hypothesentestens, wenn man eine offene Forschungsfrage beantwortet): <strong>Inferenzstatistik (schliessende Statistik)</strong>.</p>
<p>Ordinationen und Cluster-Analysen** sind überwiegend deskriptive Statistik** (ohne spezielle Zusatzschritte erlauben sie kein Testen von Hypothesen!).</p>
</section>
<section id="beispiele-multivariater-datensätze" class="level3">
<h3 class="anchored" data-anchor-id="beispiele-multivariater-datensätze">Beispiele multivariater Datensätze</h3>
<p>Multivariate Datensätze sind in unserer „datenreichen” Welt allgegenwärtig z. B.:</p>
<ul>
<li><p><strong>Bodenproben</strong>, an denen viele unterschiedliche physikalische und chemische Variablen, ggf. auch noch in verschiedenen Horizonten gemessen wurden.</p></li>
<li><p><strong>Klimadaten</strong> von Messstationen: zahlreiche Variablen wie Mittel/Minima/Maxima von Temperatur/Niederschlag/Sonnenschein/Bewölkung/Windstärke usw. und das für jeden Monat.</p></li>
<li><p>Zusammensetzungen von lokalen <strong>Pflanzengesellschaften oder Tiergemeinschaften</strong>: hier sind die Deckungen bzw. Individuenzahlen der einzelnen Arten die Variablen</p></li>
<li><p>Ergebnisse von <strong>Befragungen von Konsumenten</strong>: viele Variablen zu Präferenzen, Einstellungen usw.</p></li>
</ul>
</section>
<section id="ziele-multivariat-deskriptiver-analysen" class="level3">
<h3 class="anchored" data-anchor-id="ziele-multivariat-deskriptiver-analysen">Ziele multivariat-deskriptiver Analysen</h3>
<p>Im Prinzip können wir auch bei solchen Beobachtungsdaten mit vielen abhängigen Variablen wie bisher jede einzeln testen:</p>
<ul>
<li><p>Das kann <strong>vorteilhaft</strong> sein, <strong>wenn man konkrete Hypothesen testen will</strong> (was ja mit multivariat-deskriptiven Methoden normalerweise nicht geht).</p></li>
<li><p>Ein Problem sind die vielen Tests mit dem gleichen Datensatz, die zu einer <strong>„Inflation” der Typ I-Fehlerrate</strong> führen (wenn ich 20 Tests durchführe, würde ja bei α = 0.05 einer rein zufällig eine Signifikanz anzeigen, selbst wenn eigentlich für keinen einen Beziehung besteht). Für dieses Problem gibt es aber Korrekturmöglichkeiten (z. B. „Bonferroni”-Korrektur).</p></li>
<li><p>Problematischer ist, dass es sehr <strong>schwierig</strong> ist, <strong>aus den vielen Einzelergebnissen am Ende ein aussagekräftiges Gesamtbild zu synthetisieren</strong>.</p></li>
</ul>
<p>Hier setzen die multivariat-deskriptiven Methoden mit ihren beiden Hauptzielen an:</p>
<ul>
<li><p><strong>Muster und Beziehungen</strong> im <em>n</em>-dimensionalen Hyperraum erkennen und beschreiben.</p></li>
<li><p><strong>Dimensionsreduktion</strong>: die wesentliche Information aus den n Dimensionen wird auf 2 bis wenige Dimensionen reduziert, die vorstellbar und visualisierbar sind.</p></li>
</ul>
<p>Der <strong><em>n</em>-dimensionale Hyperraum</strong> ist das Konzept, das uns durchgängig bei den multivariat-deskriptiven Methoden begleitet. Dahinter verbirgt sich die Idee, dass jede der <em>n</em> Variablen eine orthogonale Achse ist, auf der die Ausprägungen der Variablen (metrisch oder kategorial) aufgetragen sind. Während wir uns einen 3-dimensionalen Raum noch vorstellen können, ist es mit der Vorstellungskraft bei vier oder gar 100 Dimensionen schnell zu Ende. Aber das ist ja genau der Grund für die multivariat-deskriptiven Methoden…</p>
</section>
<section id="zwei-komplementäre-ansätze" class="level3">
<h3 class="anchored" data-anchor-id="zwei-komplementäre-ansätze">Zwei komplementäre Ansätze</h3>
<p>Innerhalb der multivariat-deskriptiven Statistik stellen <strong>Ordinationen</strong> und <strong>Cluster-Analysen (Klassifikationen)</strong> zwei <strong>komplementäre Ansätze</strong> dar. Sie betonen unterschiedliche Aspekte des Datensatzes und können oftmals sogar sinnvoll parallel verwendet werden. Die wesentlichen Unterschiede zeigt die folgende Tabelle:</p>
<p><img src="./myMediaFolder/media/image89.emf.png" class="img-fluid"></p>
</section>
</section>
<section id="die-idee-von-ordinationen" class="level2">
<h2 class="anchored" data-anchor-id="die-idee-von-ordinationen">Die Idee von Ordinationen</h2>
<p>Ordinationen versuchen nun im Prinzip im <em>n</em>-dimensionalen Raum der (Antwort-) Variablen <strong>diejenigen Ebenen zu finden, welche die meiste Varianz erklären</strong>. Dies geschieht durch die folgenden Schritte:</p>
<ul>
<li><p><strong>Zentrieren</strong> der Punktwolke, so dass der Schwerpunkt im Ursprung des Koordinatensystems liegt.</p></li>
<li><p><strong>Rotieren</strong> der Punktwolke, bis die erste Achse die maximal mögliche Varianz abbildet.</p></li>
<li><p>Nach Fixierung der ersten Achse Fortsetzen des Rotierens, bis die zweite Achse wiederum das maximal Mögliche der verbleibenden Varianz abbildet, usw. bis zur <em>n</em>-ten Achse.</p></li>
<li><p><strong>Visualisierung</strong> der Ergebnisse bei Beschränkung auf die relevanten ersten Achsen.</p></li>
</ul>
<p>Um diese Idee zu visualisieren, nehmen wir ein System von nur zwei Variablen, da wir diese noch auf einer Ebene (d.&nbsp;h. im gedruckten Skript) visualisieren können. Stellen wir uns sechs Beobachtungspunkte entlang eines Umweltgradienten (z. B. Meereshöhe) vor. An jedem dieser Beobachtungspunkte wird die Häufigkeit von zwei Arten ermittelt, etwa folgendermassen:</p>
<p><img src="./myMediaFolder/media/image90.png" class="img-fluid"></p>
<p>Wenn wir das jetzt <strong>im „Artenraum”</strong> zeigen, also mit der Häufigkeit von Art 1 auf der <em>x</em>-Achse und der Häufigkeit von Art 2 auf der <em>y</em>-Achse, dan bekämen wir das <strong>grüne</strong> Muster. <strong>Zentriert</strong> (d.&nbsp;h. so dass die Mittelwerte aller <em>x</em>- und <em>y</em>-Werte jeweils 0 sind), ergibt sich die <strong>rote</strong> Figur. Dies wird schliesslich so <strong>rotiert</strong>, dass die maximale Varianz (hier im simplen Fall einfach die Distanz zwischen den extremen Punkten) paralle zur <em>x</em>-Achse liegt (<strong>blau</strong>).</p>
<p><img src="./myMediaFolder/media/image91.png" class="img-fluid"></p>
</section>
<section id="hauptkomponentenanalyse-pca" class="level2">
<h2 class="anchored" data-anchor-id="hauptkomponentenanalyse-pca">Hauptkomponentenanalyse (PCA)</h2>
<section id="das-prinzip" class="level3">
<h3 class="anchored" data-anchor-id="das-prinzip">Das Prinzip</h3>
<p>Das im vorigen Abschnitt skizzierte Vorgehen, ist genau das, was eine <strong>Hauptkomponentenanalyse (<em>Principal component analysis</em>, PCA)</strong> macht:</p>
<ul>
<li><p>Basiert auf einer <strong>linearen Beziehung</strong> zwischen den Attributen.</p></li>
<li><p>Achsen sind <strong>orthogonal</strong> (und die Varianzen daher additiv).</p></li>
<li><p>Die ursprünglichen <strong>Distanzen</strong> zwischen den Objekten (Beobachtungen) bleiben daher <strong>unverändert</strong>.</p></li>
</ul>
<p>PCAs eignen sich für:</p>
<ul>
<li><p>Einfache Visualisierung, wenn die Linearität gegeben ist.</p></li>
<li><p>Bei multiplen Regressionen mit vielen, korrelierten Prädiktoren kann man die PCA-Achsen als <strong>synthetische Prädiktoren</strong> verwenden, da sie vollständig unkorreliert sind.</p></li>
</ul>
<p>PCAs eignen sich <em>nicht</em>(und das gilt fast immer für für Daten zur Artenzusammensetzung ökologischer Gemeinschaften) für:</p>
<ul>
<li><p>Nicht-lineare Beziehungen.</p></li>
<li><p>Viele Nullen in der Matrix.</p></li>
</ul>
<p>Die PCA findet die beste Rotation mittels der sogenannten <strong>„Eigenanalyse”</strong>, wie die folgende Abbildung veranschaulicht:</p>
<p><img src="./myMediaFolder/media/image92.jpeg" class="img-fluid"><img src="./myMediaFolder/media/image93.jpeg" class="img-fluid"><br>
(aus Wildi 2013)</p>
<p>Dabei gilt:</p>
<blockquote class="blockquote">
<p><strong>α = Eigenvektormatrix<br>
</strong>= Korrelationskoeffizient (der Arten/Variablen) mit den Ordinationsachsen</p>
<p><strong>Eigenwerte einre Achse = <em>Sum of squares</em> dieser Achse</strong></p>
</blockquote>
</section>
<section id="in-r" class="level3">
<h3 class="anchored" data-anchor-id="in-r">In R</h3>
<p>PCAs sind z. B. im Package labdsv implementiert:</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(labdsv)</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>o.pca <span class="ot">&lt;-</span> <span class="fu">pca</span>(raw)</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>o.pca<span class="sc">$</span>scores</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb134"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>          PC1         PC2</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>r1 -1.9216223 -0.09357697</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>r2 -0.6353776 -0.68143293</span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>r3  0.4762699 -0.80076373</span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>r4  2.3503705 -0.10237502</span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a>r5  0.8895287  0.95400610</span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a>r6 -1.1591692  0.72414255</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb135"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>o.pca<span class="sc">$</span>loadings</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb136"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>             PC1        PC2</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>spec<span class="fl">.1</span> <span class="fl">0.3491944</span> <span class="sc">-</span><span class="fl">0.9370503</span></span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a>spec<span class="fl">.2</span> <span class="fl">0.9370503</span>  <span class="fl">0.3491944</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb137"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Erklärte Varianz der Achsen</span></span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>E <span class="ot">&lt;-</span> o.pca<span class="sc">$</span>sdev<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>o.pca<span class="sc">$</span>totdev<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb137-3"><a href="#cb137-3" aria-hidden="true" tabindex="-1"></a>E</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb138"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>[1] 82.40009 17.59991</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Zunächst wird die PCA ausgeführt und das Ergebnis in einem Objekt (o.pca) gespeichert. Die uns Interessierten Informationen kann man wie oben gezeigt abrufen: …<span class="math inline">\(scores enthält die resultierenden Koordinaten der Beobachtungen nach der Ordination; ...\)</span>loadings gibt die Vektoren wieder, die nach der Rotation den beiden Arten entsprechen (Art 1 hat also den Vektor 0.35/–0.94). Die erklärte Varianz ist ein uns schon bekanntes Konzept. Die Gesamtvarianz ist alles, was im Datensatz mit seinen <em>n</em> Achsen drin steckt (100%), hier wird dieser Wert auf die Achsen aufgeteilt, also 82 % auf der ersten Achse, 18 % auf der zweiten. Alle <em>n</em> Achsen zusammen ergeben immer 100 %.</p>
<p>Ziel einer PCA ist ja meist eine Visualisierung. Für unsere sechs Beobachtungen von zwei Arten haben wir das oben ja schon gemacht (und da hat es auch keine Dimensionsreduktion gebracht, da es eh nur zwei Arten waren). Wenn wir uns nun aber einen Datensatz mit 63 Beobachtungspunkten (hier: Vegetationsaufnahmen) und 119 Variablen (hier: Pflanzenarten) anschauen, dann haben wir eine Dimensionsreduktion von 119 auf 2. Das aufbereitete Ergebnis kann dann wie folgt aussehen (den R Code dazu gibt es im Demoskript):</p>
<p><img src="./myMediaFolder/media/image94.png" class="img-fluid"><img src="./myMediaFolder/media/image95.png" class="img-fluid"></p>
<p>Bitte beachten, dass wir hier eine PCA für einen Fall gerechnet haben (ökologische Gemeinschaftsdaten), für den sie mit seltenen Ausnahmen ungeeignet ist. Warum sie hier problematisch war, werden wir weiter unten ansehen wie auch Lösungen dafür.</p>
</section>
<section id="beispiele-von-anwendungen-von-pcas" class="level3">
<h3 class="anchored" data-anchor-id="beispiele-von-anwendungen-von-pcas">Beispiele von Anwendungen von PCAs</h3>
<p>Zunächst sollen aber einige gängige und korrekte Anwendungen auf sehr grossen Datensets gezeigt werden:</p>
<ol type="a">
<li>Visualisierung 1: Hier wurden etwa 20 verschiedene bioklimatische Variablen für alle Rasterzellen der Erdoberfläche (Farbkodierung gibt die Häufigkeit wieder) einer PCA unterworfen. Die Klimadaten sind so hoch korreliert, dass die ersten beiden Achen (Hauptkomponenten) PC1 und PC2 zusammen 76&nbsp;% der Varianz im Gesamtdatensatz kodieren. Es wäre also unsinnig, die 20 Variablen einzeln zu analysieren. Durch die rechts gezeigten Korrelationen der Originalvariablen mit PC1 und PC2 kann man die beiden synthetischen Achsen näherungsweise interpretieren (siehe die Achsenbeschriftung links).</li>
</ol>
<p><img src="./myMediaFolder/media/image96.emf.png" class="img-fluid"><img src="./myMediaFolder/media/image97.emf.png" class="img-fluid"><br>
(aus Bruelheide et al.&nbsp;2019)</p>
<ol start="2" type="a">
<li>Visualisierung 2: Hier wurden 6 funktionelle Merkmale (<em>traits</em>) von Pflanzenarten weltweit einer PCA unterworfen. Diese erweisen sich so weit korreliert, dass die ersten beiden Achen (Hauptkomponenten) PC1 und PC2 zusammen 74% der Varianz kodieren. Der eine wesentliche Gradient (etwas gegen PC1 nach links verdreht) ist jender von winizigen, kleinsamigen Arten zu grossen Arten mit schweren Samen. Dazu weitgehend orthogonal ist der Gradient von Pflanzen mit stickstoffreichen Blättern (links oben) zu Pflanzen mit stickstoffarmen Blättern (rechts unten).</li>
</ol>
<p><img src="./myMediaFolder/media/image98.emf.png" class="img-fluid"><br>
(aus Díaz et al.&nbsp;2016)</p>
<ol start="3" type="a">
<li>Principal Components (PCs) in multiplen Regressionen: Hier rechnet man zunächst eine PCA mit vielen Umweltvariablen ohne Rücksicht auf ihre wechselseitigen Korrelationen. Dann nimmt man die (ersten) PC-Achsen mit der meisten Information als sogenannte „synthetische” Prädiktoren.</li>
</ol>
<ul>
<li><p><strong>Vorteil:</strong> Die PC-Achsen sind vollständig unkorreliert.</p></li>
<li><p><strong>Nachteil:</strong> Die PC-Achsen sind nicht so direkt interpretierbar wie die Original-Umweltparameter, das sie zwar oft stark mit mehreren Umweltparametern korrelieren, aber eben nicht 100 %.</p></li>
<li><p><strong>Wichtig:</strong> Hochladende Achsen sind nicht unbedingt auch die wichtigsten für die Regression.</p></li>
</ul>
</section>
</section>
<section id="ordinationen-für-problematische-fälle" class="level2">
<h2 class="anchored" data-anchor-id="ordinationen-für-problematische-fälle">Ordinationen für „problematische” Fälle</h2>
<section id="wann-sind-pcas-problematisch" class="level3">
<h3 class="anchored" data-anchor-id="wann-sind-pcas-problematisch">Wann sind PCAs problematisch?</h3>
<p>Wie schon erwähnt, ist die Anwendung von PCAs problematisch/falsch, wenn einer oder beide der folgenden Fälle vorliegen:</p>
<ul>
<li><p>Nicht-lineare Beziehungen.</p></li>
<li><p>Vielen Nullen in der Matrix.</p></li>
</ul>
<p>In der Ökologie ist das besonders relevant, da beides für Artdaten in der Gemeinschaftsökologie (<em>community ecology</em>) nicht die Ausnahme, sondern der Normalfall ist. Arten reagieren auf Umweltfaktoren meist nicht linear, sondern unimodal (<em>humpshaped</em>) und in grossen Matrizen von Artvorkommen in Vegetationsaufnahmen und Gebieten ist es normal, dass die meisten Arten in den meisten Aufnahmeflächen nicht vorkommen, also ihre Deckung oder Abundanz Null ist. Dagegen lassen sich Matrizen von Umweltdaten der Untersuchungsgebiete (etwa von Boden- und Klimadaten) problemlos mit einer PCA analysieren (siehe Beispiel (a) im vorigen Abschnitt, da es ja keine Nullwerte gibt).</p>
<p>Warum sind nicht-lineare Beziehungen in einer PCA problematisch? Sehen wir uns dazu noch einmal unser Eingangsbeispiel der zwei Arten entlang eines Umweltgradienten von 1 bis 6 an:</p>
<p><img src="./myMediaFolder/media/image90.png" class="img-fluid"><img src="./myMediaFolder/media/image91.png" class="img-fluid"></p>
<p>Aufgrund des Umweltgradienten sollten die Beobachtungen/Standorte 1 und 6 maximal unähnlich sein. Tatsächlich kommen sie aber im Ordinationsdiagramm sehr nahe beieinander zu liegen. Das liegt daran, dass beide Arten unimodal (mit einer Optimumskurve) auf den Umweltgradienten reagieren. Wenn der Umweltgradient etwa die Bodenfeuchte wäre, hiesse das, dass beide bei mittlerer Bodenfeuchte am häufigsten sind und Richtung sehr nasser oder sehr trockener Böden seltener werden. Das heisst, an den Standorten 1 und 6 sind beide relativ selten, wenn auch aus unterschiedlichen Gründen, die Artenzusammensetzung daher ingesamt ähnlich.</p>
<p>Man bezeichnet dieses Phänomen/Problem: als <strong>Hufeisen- oder Bogeneffekt</strong> (<strong><em>horse shoe/arch effect</em></strong>).</p>
</section>
<section id="korrespondenzanalyse-ca" class="level3">
<h3 class="anchored" data-anchor-id="korrespondenzanalyse-ca">Korrespondenzanalyse (CA)</h3>
<p>Ein Verfahren, um solche Probleme (vor allem in der Gemeinschaftsökologie) anzugehen, ist die <strong>Korrespondenzanalyse (<em>Correspondence Analysis</em>, CA)</strong>. Sie wird auch als <strong><em>Reciprocal Averging</em></strong> bezeichnet. Wichtige Aspekte der CA sind:</p>
<ul>
<li><p>Hier wie in allen folgenden Ordinationsmethoden wird der <strong>Ordinationsraum transformiert</strong> (im Gegensatz zur PCA) durch die Anwendung eines <strong>Distanzmasses</strong>.</p></li>
<li><p>CA hat als Distanzmass implizit die <strong>Χ²-Metrik</strong>.</p></li>
<li><p>CA ist spezifisch gedacht für <strong>Artenverteilungen entlang von Umweltgradiente</strong>n, wobei jede Art für sich <strong>unimodal</strong> reagiert.</p></li>
<li><p>Wie die meisten weiteren Ordinationstechniken implementiert im package vegan für <em>community ecology</em>.</p></li>
</ul>
<p>In R wird das wie folgt umgesetzt (man beachte, dass häufig die Artdeckungen eingangs noch wurzeltransformiert werden (^0.5), um Arten mit geringer Deckung relativ mehr Gewicht zu geben):</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>ca<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">cca</span>(sveg<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Arten (o) und Communities (+) plotten</span></span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ca<span class="fl">.1</span>)</span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a><span class="co">#Nur Arten plotten</span></span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ca<span class="fl">.1</span>, <span class="at">display =</span> <span class="st">"species"</span>, <span class="at">type =</span> <span class="st">"points"</span>) </span>
<span id="cb139-9"><a href="#cb139-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Anteilige Varianz, die durch die ersten beiden Achsen erklärt wird</span></span>
<span id="cb139-10"><a href="#cb139-10" aria-hidden="true" tabindex="-1"></a>o.ca<span class="sc">$</span>CA<span class="sc">$</span>eig[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]<span class="sc">/</span><span class="fu">sum</span>(o.ca<span class="sc">$</span>CA<span class="sc">$</span>eig)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wenn wir jetzt die Anwendung der PCA und der CA auf den Moordatensatz (63 Vegetationsaufnahmen mit 119 Arten) anschauen, den wir oben schon einmal kurz hatten, dann zeigt sich, dass aus dem Hufeisen im Prinzip ein (umgekehrtes) U oder V wird, die extremen Punkte des Gradienten also nicht mehr so nahe beisammen stehen:</p>
<p><img src="./myMediaFolder/media/image99.emf.png" class="img-fluid"></p>
<p>Wie dieser Unterschied zustande kommt, visualisiert die folgende konzeptionelle Abbildung mit drei Arten:</p>
<p><img src="./myMediaFolder/media/image100.jpeg" class="img-fluid"><br>
(aus Wildi 2013)</p>
</section>
<section id="dca" class="level3">
<h3 class="anchored" data-anchor-id="dca">DCA</h3>
<p>Wie wir im vorigen Abschnitt gesehen haben, löst die CA die Probleme der PCA bei <em>Community</em>-Daten in der Ökologie, aber eben nur teilweise. Aus einem Hufeisen wird ein U, aber eigentlich war der Umweltgradient (hier von feucht nach trocken) ja linear, nur die Artantworten waren eben unimodal. Insofern wurde die CA noch weiter verfeinert, um den sich ergebenden Hauptumweltgradienten möglichst linear abzubilden. Wir landen bei der <strong>Detrended Correspondence Analysis (DCA)</strong>, man könnte auf Deutsch von einer <strong>„trendbereinigten Korrespondenzanalyse”</strong> sprechen, aber dieser deutsche Begriff wird eigentlich nie gebraucht.</p>
<p>Es gibt verschiedene <em>Detrending</em>-Methoden, die gängigste ist „<em>detrending by segments</em>”. wie sie in folgendem Schema visualisiert ist:</p>
<p><img src="./myMediaFolder/media/image101.emf.png" class="img-fluid"><br>
(aus Leyer &amp; Wesche 2007)</p>
<p>Die mathematischen Schritte dahinter und die daraus resultierenden methodischen Entscheidungen sind etwas komplexer, so dass wir sie nicht im Detail behandeln. Wer die Dinge im Einzelnen nachvollziehen möchte, sei auf Leyer &amp; Wesche (2007) bzw. Oksanen (2015) verwiesen. Der R Code (Funktion decorana im Package vegan) ist auch etwas länger, sodass wir ihn nicht hier im Skript wiedergeben, sondern nur in den R-Demos.</p>
<p>Aus dem Gesagten wird evident, dass eine DCA nach all den erfolgten Transformationen des Ordinationsraumes keine Methode der schliessenden Statistik ist, sondern ein (durchaus leistungsfähiges) Visualisierungstool komplexer Community-Daten. Da, wie geschildert, eine CA die Probleme der Ordination von Community-Daten nur unzureichend löst, findet sie als solche hier eigentlich nie Anwendung (siehe jedoch die CCA in Statistik 7), sondern entweder PCA oder DCA (oder eben NMDS, vgl. folgenden Abschnitt).</p>
<p>Warum wird jetzt doch wieder die PCA für Community-Daten genannt, nachdem sie bislang mehrfach als ungeeignet angeführt wurde? Meist passt sie methodisch nicht, aber es gibt Fälle, bei denen die Umweltgradienten so kurz sind, dass die Artenreaktionen auf den oder die Umweltgradienten in guter Näherung als linear betrachtet werden können. Das ist dann der Fall, wenn man lauter sehr ähnliche Standorte untersucht hat, dann ist eine PCA ausnahmsweise das bessere Modell. Wie weiss man, ob das bei einem bestimmten Datensatz der Fall ist?</p>
<p>Zunächst vielleicht etwas überraschend lautet die Antwort: man berechnet zuerst eine DCA. Ein Standard-Output der DCA ist die geschätzte Gradientenlänge der ersten Achse. Die Länge des Gradienten wird in Standardabweichungen (SD) quantifiziert, was zunächst „schräg” klingt. Das bezieht sich auf die Annahme, dass die Artenhäufigkeit entlang des Umweltgradienten näherungsweise einer Normalverteilung folgt. Vielleicht habt ihr im Hinterkopf, dass 95 % aller Werte einer Normalverteilungskurve im Bereich von Mittelwert ± 2 SD liegt. Wenn der geschätzte Gradient also 4 SD-Einheiten oder mehr ist, gibt es zwischen den beiden Enden des untersuchten Umweltgradienten praktisch keine gemeinsamen Arten (bzw. sie treten mit weniger als 1&nbsp;% ihrer Maximalhäufigkeit auf), man spricht von einem vollständigen Arten-Turnover. Bei einer Gradientenlänge von 8 SD-Einheiten hätte man sogar zwei vollständige Arten-Turnovers, also letztlich drei komplett verschiedene Gesellschaften ohne Überlappung.</p>
<p>Die Faustregel für die Anwendung von DCA vs.&nbsp;PCA besagt, dass bei einer Länge der ersten Achse von &lt; 3 SD-Einheiten mit der PCA gearbeitet werden sollte, bei einer Länge von 3–4 SD-Einheiten beide Methoden gehen und bei &gt;4 SD-Einheiten man bei der DCA bleiben sollte. Man könnte aber auch argumentieren, dass die Annahmen der PCA theoretisch für solche Datensätze nie zutreffen, man also <em>per se</em> mit der DCA arbeiten sollte.</p>
<p>Schauen wir uns den Effekt noch im Fall unseres Moor-Datensatzes an:</p>
<p><img src="./myMediaFolder/media/image102.emf.png" class="img-fluid"></p>
<p>Wie wir sehen, wurde aus dem umgekehrten U und eine relativ homogene Punktwolke, mit der längsten Ausdehnung entlang der ersten Achse (was ja die Grundidee einer Ordination ist). Die Gradientenlänge können wir auf der <em>x</em>-Achse ablesen, sie beträgt etwa 3.2 SD-Einheiten (Differenz der Position zwischen dem Punkt ganz links und dem Punkt ganz rechts).</p>
</section>
<section id="nmds" class="level3">
<h3 class="anchored" data-anchor-id="nmds">NMDS</h3>
<p>NMDS** steht für **<em>Non-metric Multi-Dimensional Scaling</em>, wofür es keine gute/gängige deutsche Übersetzung gibt. Die wichtigsten Aspekte einer NMDS sind:</p>
<ul>
<li><p><strong>„Non-metric”</strong>, da mit <strong>Rängen</strong>, nicht mit Distanzen gearbeitet wird.</p></li>
<li><p>NMDS arbeitet mit einem Iterationsalgorithmus, der jedes Mal ein geringfügig anderes Ergebnis liefert.</p></li>
<li><p>Startet mit einer beliebigen vorgegebenen Ordination, etwa einer PCA.</p></li>
<li><p>Danach werden sukzessive die Punkte im niedrig-dimensionalen Ordinationsraum (meist 2D) geringfügig verschoben und geschaut, ob die originale Distanzmatrix besser wiedergegeben wird, so lange, bis ein (lokales) Optimum erreicht ist.</p></li>
</ul>
<p>In R geht das folgendermassen. Dabei steht der Parameter <em>k</em> für die Zahl der gewünschten Dimensionen (normalerweise wählt man 2) (weitere Details dann in der Demo im Klassenverband):</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Distanzmatrix als Start erzeugen</span></span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>mde <span class="ot">&lt;-</span> <span class="fu">vegdist</span>(sveg, <span class="at">method=</span><span class="st">"euclidean"</span>)</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>mde</span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Zwei verschiedene NMDS-Methoden</span></span>
<span id="cb140-6"><a href="#cb140-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>) <span class="co">#macht man, wenn man bei einer Wiederholung exakt die gleichen Ergebnisse will</span></span>
<span id="cb140-7"><a href="#cb140-7" aria-hidden="true" tabindex="-1"></a>imds <span class="ot">&lt;-</span> <span class="fu">isoMDS</span>(mde, <span class="at">k=</span><span class="dv">2</span>)</span>
<span id="cb140-8"><a href="#cb140-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb140-9"><a href="#cb140-9" aria-hidden="true" tabindex="-1"></a>mmds <span class="ot">&lt;-</span> <span class="fu">metaMDS</span>(mde, <span class="at">k=</span><span class="dv">2</span>)</span>
<span id="cb140-10"><a href="#cb140-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-11"><a href="#cb140-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(imds<span class="sc">$</span>points)</span>
<span id="cb140-12"><a href="#cb140-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mmds<span class="sc">$</span>points)</span>
<span id="cb140-13"><a href="#cb140-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-14"><a href="#cb140-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-15"><a href="#cb140-15" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(o.imds<span class="sc">$</span>points)</span>
<span id="cb140-16"><a href="#cb140-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(o.mmds<span class="sc">$</span>points)</span>
<span id="cb140-17"><a href="#cb140-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-18"><a href="#cb140-18" aria-hidden="true" tabindex="-1"></a><span class="co">#Stress = S² = Abweichung der zweidimensionalen NMDS-Lösung von der originalen Distanzmatrix</span></span>
<span id="cb140-19"><a href="#cb140-19" aria-hidden="true" tabindex="-1"></a><span class="fu">stressplot</span>(o.imds,mde)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Das Ergebnis (hier mit dem Algorithmus isoMDS) sieht man links. Wie gut die NMDS die originale Struktur wiedergibt, zeigt sich rechts (erzeugt mit stressplot):</p>
<p><img src="./myMediaFolder/media/image103.png" class="img-fluid"><img src="./myMediaFolder/media/image104.png" class="img-fluid"></p>
<p>Zwei wichtige Aspekte sollte man hier noch erwähnen: Da NMDS mit einem interativen Algorithmus arbeitet, der eine Zufallskomponente enthält, kommen bei jedem Durchlauf geringfügig andere Ergebnisse heraus. Wenn man das verhindern will, kann man mit set.seed arbeiten, was erzwingt, dass die gleiche „Zufallswahl” auch bei neuerlichen Durchläufen des R-Scriptes getroffen wird. Das Mass für die Güte einer NMDS ist der sogenanante Stress:</p>
<blockquote class="blockquote">
<p><strong>Stress = 1 – <em>R</em>²</strong></p>
</blockquote>
<p>In unserem Fall wäre der Stress also 1 – 0.977, also 2.3%, mithin sehr niedrig. Nur in 2.3% der Fälle würde die Lage im zweidimensionalen NMDS-Raum also das Ranking der Distanzen anders als das Ranking der Distanzen im ursprünglichen <em>n</em>-dimensionalen Hyperraum wiedergeben.</p>
</section>
</section>
<section id="zusammenfassung-5" class="level2">
<h2 class="anchored" data-anchor-id="zusammenfassung-5">Zusammenfassung</h2>
<ul>
<li><p><strong>Ordinationen</strong> sind im Kern <strong>deskriptive Verfahren für multivariate</strong> (abhängige) <strong>Variablen</strong> und komplementär zu Cluster-Analysen.</p></li>
<li><p>Ihre Ziele sind <strong>Dimensionsreduktion und Visualisierung</strong>.</p></li>
<li><p>Die basale Form einer Ordination ist die <strong>PCA</strong>. Sie setzt <strong>lineare Beziehungen und wenige Nullwerte</strong> in der Matrix voraus.</p></li>
<li><p>Abgesehen von Visualisierungen kann man PCAs auch zum <strong>Generieren unkorrelierter synthetischer Variablen</strong> für nachfolgende multiple Regressionsanalysen verwenden.</p></li>
<li><p>Auf ökologische Gemeinschafts-Daten angewandt, ergeben PCA und CA normalerweise einen <strong>Hufeisen-Effekt</strong>, wobei standörtlich besonders unähnliche Plots nahe beieinander zu liegen kommen.</p></li>
<li><p><strong>DCA und NMDS</strong> versuchen das zu verhindern, indem sie entweder das Hufeisen «herausrechnen» oder von vornherein nur mit Rängen arbeiten.</p></li>
</ul>
</section>
<section id="weiterführende-literatur-5" class="level2">
<h2 class="anchored" data-anchor-id="weiterführende-literatur-5">Weiterführende Literatur</h2>
<ul>
<li><p><strong>Borcard, D., Gillet, F. &amp; Legendre, P. 2018. <em>Numerical ecology with R</em>. 2nd ed.&nbsp;Springer, Cham: 435 pp.&nbsp;[mit R]</strong></p></li>
<li><p>Crawley, M.J. 2013. <em>The R book</em>. 2nd ed.&nbsp;John Wiley &amp; Sons, Chichester, UK: 1051 pp.&nbsp;[mit R]</p></li>
<li><p>Everitt, B. &amp; Hothorn, T. 2011. <em>An introduction to applied multivariate analysis with R</em>. Springer, New York: 273 pp.&nbsp;[mit R]</p></li>
<li><p>Leyer, I. &amp; Wesche, K. 2007. <em>Multivariate Statistik in der Ökologie</em>. Springer, Berlin: 221 pp.&nbsp;[einfache Erklärung von Ordinationsmethoden, ohne R]</p></li>
<li><p>McCune, B., Grace, J.B. &amp; Urban, D.L. 2002. <em>Analysis of ecological communities</em>. MjM Software Design, Gleneden Beach, Oregon, US: 300 pp.&nbsp;[gut erklärte und detaillierte Einführung in Ordinationen u.a., ohne R]</p></li>
<li><p>Oksanen, L. 2015. <em>Multivariate analysis of ecological communities in R: vegan tutorial</em>. URL: <a href="http://cc.oulu.fi/~jarioksa/opetus/metodi/vegantutor.pdf" class="uri">http://cc.oulu.fi/~jarioksa/opetus/metodi/vegantutor.pdf</a>. [gute Einführung in das R-package <em>vegan</em> mit vielen Ordinationsmethoden]</p></li>
<li><p>Wildi, O. 2013. <em>Data analysis in vegetation ecology</em>. 2nd ed.Wiley-Blackwell, Chichester, UK: 301 pp.&nbsp;[mit R]</p></li>
<li><p>Wildi, O. 2017. <em>Data analysis in vegetation ecology</em>. 3rd ed.&nbsp;CABI, Wallingford, UK: 333 pp.&nbsp;[mit R]</p></li>
</ul>
</section>
<section id="quellen-der-beispiele" class="level2">
<h2 class="anchored" data-anchor-id="quellen-der-beispiele">Quellen der Beispiele</h2>
<p>Bruelheide, H., Dengler, J., Purschke, O., Lenoir, J., Jiménez-Alfaro, B., Hennekens, S.M., Botta-Dukát, Z., Chytrý, M., Field, R., (…) &amp; Jandt, U. 2018. Global trait–environment relationships of plant communities. <em>Nature Ecology and Evolution</em> 2: 1906–1917.</p>
<p>Díaz, S., Kattge, J., Cornelissen, J.H.C., Wright, I.J., Lavorel, S., Dray, S., Reu, B., Kleyer, M., Wirth, C.(…) &amp; Gorné, L.D. 2016. The global spectrum of plant form and function. <em>Nature</em> 529: 167–171.</p>
</section>
</section>
<section id="statistik-7-ordinationen-ii" class="level1">
<h1>Statistik 7: Ordinationen II</h1>
<p><strong>In Statistik 7 beschäftigen wir uns zunächst damit, wie wir Ordinationsdiagramme informativer gestalten können, etwa durch die Beschriftung der Beobachtunge, post-hoc-Projektion der Prädiktorvariablen oder <em>Response surfaces</em>. Während wir bislang mit <em>«unconstrained»</em> Ordinationen gearbeitet haben, welche die Gesamtvariabilität in den Beobachtungen visualisieren, beschränken die jeweiligen <em>«constrained»-</em>Varianten derselben Ordinationsmethoden die Betrachtung auf den Teil der Variabilität, welcher durch eine Linearkombination der berücksichtigen Prädiktoren erklärt werden kann. Wir beschäftigen uns im Detail mit der Redundanz-Analyse (RDA), der <em>«constrained»</em>-Variante der PCA und gehen einen kompletten analytischen Ablauf mit Aufbereitung, Interpretation und Visualisierung der Ergebnisse am Beispiel eines gemeinschaftsökologischen Datensatzes (Fischgesellschaften und Umweltfaktoren im Jura-Fluss Doubs) durch.</strong></p>
<section id="lernziele-6" class="level2">
<h2 class="anchored" data-anchor-id="lernziele-6">Lernziele</h2>
<p><em>Ihr…</em></p>
<ul>
<li><p><em>wisst, wie man durch post-hoc gefittete Umweltvariablen (als Vektoren oder response surfaces) <strong>Ordinationen informativer machen</strong> kann;</em></p></li>
<li><p><em>habt verstanden, was <strong>«constrained» Ordinationen</strong> von <strong>normalen Ordinationen</strong> unterscheidet; und</em></p></li>
<li><p><em>könnt eine <strong>RDA anwenden und ihre Ergebnisse interpretieren</strong>, um einen multivariaten Datensatz effektiv zu analysieren.</em></p></li>
</ul>
</section>
<section id="interpretation-von-ordinationsergebnissen" class="level2">
<h2 class="anchored" data-anchor-id="interpretation-von-ordinationsergebnissen">Interpretation von Ordinationsergebnissen</h2>
<section id="beschriftung-der-variablen" class="level3">
<h3 class="anchored" data-anchor-id="beschriftung-der-variablen">Beschriftung der Variablen</h3>
<p>Die Interpretation eines Ordinationsdiagramms wird durch Beschriftung der Variablen (und ggf. der Beobachtungen) wesentlich unterstützt. Bei der Ordination von gemeinschaftsökologischen Daten stellen allerdings die grosse Zahl der Artnamen und ihre grosse Länge eine Herausforderung dar. Wenn man in unserem Moordatensatz aus der letzten Lektion mit seinen 119 Arten einfach alle ungefiltert und ungekürzt in das Diagramm plotten würde, wären weder die Punkte des Diagramms erkennbar, noch die Namen lesbar. Insofern bietet es sich an, eine Teilmenge besonders aussagekräftiger Arten (d.&nbsp;h. Variablen) auszuwählen. Mit dem in vegan implementierten Befehl make.cepnames werden diese auf 8 Buchstaben gekürzt (4 vom Gattungsnamen und 4 vom Artepithet), was in fast allen Fällen eindeutig ist. Zudem kann man die relative Position der Beschriftung zum jeweiligen Punkt durch den Parameter pos steuern (oben, unten, rechts, links)).</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="co">#4+4-Abkürzung der Namen</span></span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>snames <span class="ot">&lt;-</span> <span class="fu">make.cepnames</span>(snames)</span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-4"><a href="#cb141-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Individuelle Position der Namen</span></span>
<span id="cb141-5"><a href="#cb141-5" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(sx,sy,snames,<span class="at">pos=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">1</span>),<span class="at">cex=</span><span class="fl">0.8</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image105.png" class="img-fluid"></p>
</section>
<section id="post-hoc-korrelation-von-umweltvariablen" class="level3">
<h3 class="anchored" data-anchor-id="post-hoc-korrelation-von-umweltvariablen">Post hoc-Korrelation von Umweltvariablen</h3>
<p>In gemeinschaftsökologischen Datensätzen ist ja eine wichtige Frage meist, welche Umweltvariablen für die Verteilung der Arten in den Gemeinschaften/Vegetationsaufnahmen verantwortlich sind. Zur Rekapitulation: unsere bisherigen Ordinationsmethoden haben einzig die Artenvorkommen als Informationen (Variablen) genutzt. Eine Interpretationen der dahinterliegenden Umweltgradienten geschah bislang nur auf Basis unseres ökologischen Wissens über die Arten (sofern vorhanden). Sofern es jedoch auch erhobene Umweltdaten zu jeder Beobachtung gibt, können wir diese nachträglich (<em>post hoc</em>) zur Interpretation heranziehen. Wichtig ist dabei, dass diese zusätzlichen Umweltvariablen hier nicht die eigentliche Ordination beeinflusst haben, sondern nur zur <strong>nachträglichen Interpretation</strong> herangezogen werden (daher <em>post hoc</em>). Für unseren Moordatensatz gibt es tatsächich auch einen zusätzlichen Datensatz mit Umweltvariablen, die in jeder Vegetationsaufnahme erhoben wurden (enthalten im data frame ssit). Wir wählen davon fünf aus, um das Prinzip <em>post hoc</em>-gefitteter Umweltvariablen im Fall einer CA vorzustellen:</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>sel.sites <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"pH.peat"</span>, <span class="st">"Acidity.peat"</span>, <span class="st">"CEC.peat"</span>, <span class="st">"P.peat"</span>, <span class="st">"Waterlev.max"</span>)</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>ev <span class="ot">&lt;-</span> <span class="fu">envfit</span>(ca, ssit[,sel.sites])</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ca, <span class="at">display =</span> <span class="st">"sites"</span>, <span class="at">type =</span> <span class="st">"point"</span>)</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ev, <span class="at">add=</span>T, <span class="at">cex=</span><span class="fl">0.8</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image106.png" class="img-fluid"></p>
</section>
<section id="response-surfaces" class="level3">
<h3 class="anchored" data-anchor-id="response-surfaces">Response surfaces</h3>
<p>Die nachträglich gefitteten Vektoren der Umweltvariablen suggerieren allerdings eine Linearität im Ordinationsraum, die oftmals nicht gegeben ist. Daher ist es oft angemessener stattdessen <em>Response surfaces</em> zu visualisieren, was mit dem Befehl ordisurf in vegan geht. Diese werden vom Programm mit GAMs gefittet. Allerdings kann man so kaum mehr als zwei Variablen auf einmal darsellen, weswegen die Variante mit den Vektorpfeilen oben weiterhin ihre Berechtigung hat:</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ca, <span class="at">display =</span> <span class="st">"sites"</span>, <span class="at">type =</span> <span class="st">"point"</span>)<span class="fu">ordisurf</span>(ca, ssit<span class="sc">$</span>pH.peat, <span class="at">add=</span>T)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image107.png" class="img-fluid"></p>
</section>
<section id="zeitliche-entwicklung" class="level3">
<h3 class="anchored" data-anchor-id="zeitliche-entwicklung">Zeitliche Entwicklung</h3>
<p>Besonders aufschlussreich können Ordinationen von gemeinschaftsökologischen Daten sein, wenn zeitliche Entwicklungen analysiert, d.&nbsp;h. die gleiche Gemeinschaft mehrfach im Abstand von Jahren oder Jahrzehnten erhebt. Dies zeigt die Abbildung aus einer unserer Publikationen, wo 16 Vegetationsaufnahmen aus vier verschiedenen Vegetationstypen im Abstand von zwanzig Jahren wieder aufgenommen wurden. Die Vegetationstypen sind farbig codiert, die alten Aufnahmen gestrichelt, die neuen gefüllt und die Richtung der Veränderung wurde für jeden Vegetationstyp als Vektor zwischen dem alten und neuen Zentroid des Vegetationstyps dargestellt. Der zugehörige R-Code ist allerdings etwas komplexer, so dass wir ihn hier nicht besprechen:</p>
<p><img src="./myMediaFolder/media/image108.png" class="img-fluid"><br>
(aus Hüllbusch et al.&nbsp;2016)</p>
</section>
</section>
<section id="einführung-constrained-ordinations" class="level2">
<h2 class="anchored" data-anchor-id="einführung-constrained-ordinations">Einführung Constrained Ordinations</h2>
<p>Bislang haben wir mit normalen (unconstrained) Ordinationen gearbeitet, was das gängige Verfahren für Datensätze aus allen Disziplinen ist. Hier wurde die Transformation des ursprünglichen <em>n</em>-dimensionalen Hyperraumes auf eine oder wenige Ordinationsebenen allein basierend auf den Informationen in unseren Variablen vorgenommen.</p>
<p>Im Fall von gemeinschaftsökologischen Daten sind unsere Variablen die einzelnen Arten (bzw. deren Häufigkeit in den einzelnen Gemeinschaften/Vegetationsaufnahmen). In diesem Fall interessiert uns aber oft primär, welche Umweltvariablen für das sich ergebende Ordinationsmuster hauptsächlich verantwortlich sind. Dafür können wir zwei Wege wählen:</p>
<ol type="1">
<li><p>Wir können <strong><em>post hoc</em></strong> die Umweltvariablen als Vektoren oder Response surfaces in das Ordinationsdiagramm plotten, das ohne sie gerechnet wurde (siehe voriges Kapitel).</p></li>
<li><p>Wir können die Umweltvariablen schon <strong>direkt bei der Berechnung</strong> der Ordination einbeziehen. Dann spricht man von einer <strong>„constrained” = „canonical” Ordination</strong>. Diese betrachtet nur den Anteil der Artverteilungsmuster, der durch die erhobenen Umweltvariablen erklärt werden kann.</p></li>
</ol>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Frage
</div>
</div>
<div class="callout-body-container callout-body">
<p>Kennt ihr eine Situation in anderen Disziplinen ausser der Community Ecology, wo „constrained“ Ordinationen zum Einsatz kommen (könnten)?</p>
<p>(Dafür brauchen wir einen multivariaten Satz abhängiger und einen multivariaten Satz unabhängiger Variablen)</p>
</div>
</div>
<p>Für die beiden wesentlichen besprochenen Ordinationsverfahren PCA (für lineare Beziehungen) und CA (für unimodale Beziehungen) gibt es jeweils eine <em>unconstrained-</em> und eine <em>constrained-</em>Variante:</p>
<p><img src="./myMediaFolder/media/image109.png" class="img-fluid"></p>
<p>Das Prinzip und der konzeptionelle Ablauf einer „constrained” Ordination sei am Beispiel eines gemeinschaftsökologischen Datensatzes kurz skizziert:</p>
<ul>
<li><p>Man hat für jede Vegetationsaufnahme (o.&nbsp;ä.) zusätzlich zu den Artdaten (abhängige Variablen) ein Set von dort erhobenen Umweltvariablen (unabhängige Variablen).</p></li>
<li><p>Zunächst werden die Artmächtigkeiten der einzelnen Arten zu den betrachteten Umweltvariablen jeweils mit einer <strong>multiplen linearen Regression</strong> in Beziehung gesetzt.</p></li>
<li><p>Für die Ordination (PCA bzw. CA) werden dann statt der tatsächlichen Artmächtigkeiten die von der multiplen Regression <strong>vorhergesagten Artmächtigkeiten</strong> genommen</p></li>
<li><p>Man kann anschliessend ermitteln, wie viel der Gesamtvarianz durch die verwendeten Umweltvariablen erklärt wird</p></li>
</ul>
<p>In R passiert all das automatisch, wenn wir in vegan z.&nbsp;B. den Befehl cca für Canonical Correspondence Analysis wählen:</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>s5 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"pH.peat"</span>,<span class="st">"P.peat"</span>,<span class="st">"Waterlev.av"</span>,<span class="st">"CEC.peat"</span>,<span class="st">"Acidity.peat"</span>)</span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>ssit5 <span class="ot">&lt;-</span> ssit[s5]</span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a>o.cca <span class="ot">&lt;-</span> <span class="fu">cca</span>(sveg<span class="sc">~</span>. ,<span class="at">data=</span>ssit5)</span>
<span id="cb144-4"><a href="#cb144-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(o.cca)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image110.png" class="img-fluid"></p>
</section>
<section id="redundancy-analysis-rda-im-detail" class="level2">
<h2 class="anchored" data-anchor-id="redundancy-analysis-rda-im-detail">Redundancy Analysis (RDA) im Detail</h2>
<section id="die-idee-3" class="level3">
<h3 class="anchored" data-anchor-id="die-idee-3">Die Idee</h3>
<p>Wir schauen uns nun die Redundanzanalyse (RDA) im Detail an, welche die „constrained”-Variante der Hauptkomponentenanalyse (PCA) ist (deswegen werden in vegan beide mit dem gleichen Befehl rda gerechnet, vgl. Statistik 6).</p>
<p>Eine RDA wird für Datensätze angewandt, in denen man <strong>zahlreiche Objekte</strong> (<em>observations</em>) mit jeweils <strong>vielen abhängigen und vielen unabhängigen Variablen</strong> hat und erklären will, welche von den unabhängigen Variablen für die <strong>multivariate Antwort</strong> verantwortlich sind.</p>
<p>Zwei typische Beispie sollen das Prinzip verdeutlichen, das natürlich auch in anderen Disziplinen auftreten kann (Die Tilde ~ wird hier in typischer R-Schreibweise genutzt, um die abhängigen Variablen links von den unabhängigen rechts zu trennen):</p>
<ul>
<li><p>Zusammensetzung von Pflanzengesellschaften (Anteile von Arten in Probeflächen) ~ Umweltparameter in diesen Probeflächen</p></li>
<li><p>Politische Einstellungen von Menschen (z.&nbsp;B. als Beantwortung diverser Fragen auf einer Skala) ~ sozioökonomische Eigenschaften dieser Personen (z.&nbsp;B. Geschlecht, Alter, Bildung, Einkommen, Wohnort,…)</p></li>
</ul>
</section>
<section id="notwendige-datentransformation-für-gemeinschaftsökologische-daten" class="level3">
<h3 class="anchored" data-anchor-id="notwendige-datentransformation-für-gemeinschaftsökologische-daten">Notwendige Datentransformation für gemeinschaftsökologische Daten</h3>
<p>Wir erinnern uns, dass in Statistik 5, von der Verwendung der PCA im Fall von gemeinschaftsökologischen Daten generell abgeraten wurde. Eine Hauptursache für die schlechte Eignung in diesen Fällen, ist dass die PCA (und damit auch die RDA) standardmässig mit der euklidischen Distanz zwischen zwei Objekten arbeitet, also der Länge der Gerade zwischen den beiden Objekten im multivariaten Raum (im zweidimensionalen Fall wäre das die Hypothenuse des rechtwinkligen Dreiecks, das durch die <em>x</em>/<em>y</em>-Koordinaten der beiden Beobachtungen gebildet wird; die Entfernung (= euklidische Distanz) berechnet sich dann einfach mit dem Satz des Pythagoras, analog auch für alle höheren Dimensionen). Für Daten von Artengemeinschaften (mit typischerweie vielen Nullwerten und unimodalen Verteilungen) ist die euklidische Distanz aber ungeeignet, da sie unerwünschte Artefakte (wie den diskutierten Hufeiseneffekt) erzeugt.</p>
<p>Dies haben Legendre &amp; Gallagher (2001) schön mit einer Simulation gezeigt. Zugleich konnten sie zeigen, dass ein anderes Distanzmass, die Hellinger-Distanz diese Probleme in viel geringerem Umfang hat. Hier zunächst noch einmal die Definition der beiden Distanzmasse, mit <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>: Standort, <em>j</em> = 1… <em>p</em>: Arten, <em>y<sub>i,j</sub></em>: Artmächtigkeit Art <em>j</em> an Standort <em>i</em>:</p>
<p>Euklidische Distanz:</p>
<blockquote class="blockquote">
<p><img src="./myMediaFolder/media/image111.emf.png" class="img-fluid"></p>
</blockquote>
<p>Hellinger-Distanz:</p>
<blockquote class="blockquote">
<p><img src="./myMediaFolder/media/image112.emf.png" class="img-fluid"></p>
</blockquote>
<p>Um das „Verhalten” dieser beiden Distanzmasse wurde ein Datensatz mit einem geografischen bzw. Umweltgradienten simuliert, entlang dem insgesamt neun Arten mit unimodalen Verteilungen (ungefähr Gauss’schen <em>response curves</em>) auftreten. Nach unserer Notation von Statistik 6 würden diese 19 Beobachtungspunkte (sites) zusammen einen Diversitätsgradienten von mehr als 8 SD-Einheiten repräsentieren (d.h. zwei vollständige Artenturnovers, vgl. die Kurven für Species 2 and Species 4). Wie man sieht, ist die Rangkorrelation zwischen Distanzmass und tatsächlicher geographischer Distand nach erfolgter Hellinger-Transformation viel besser (95 %), allerdings findet auch hier bei einer geografischen Distanz &gt; 8 keine weitere Differenzierung statt, da die Artengemeinschaften dann keine gemeinsame Art mehr haben.</p>
<p><img src="./myMediaFolder/media/image113.emf.png" class="img-fluid"><br>
<img src="./myMediaFolder/media/image114.emf.png" class="img-fluid"><img src="./myMediaFolder/media/image115.emf.png" class="img-fluid"><br>
(aus Legendre &amp; Gallagher 2001)</p>
<p>Die Schlussfolgerung ist, dass man mit der Hellinger-Distanz auch für gemeinschaftsökologische Daten RDAs (und PCAs) andwenden kann.</p>
</section>
<section id="ein-beispiel-2" class="level3">
<h3 class="anchored" data-anchor-id="ein-beispiel-2">Ein Beispiel</h3>
<p>Unser Beispiel stammt aus dem sehr empfehlenswerten Buch von Borcard et al.&nbsp;(2018), das insbesondere deskriptiv-multivariate Verfahren im Bereich der Ökologie umfangreich erklärt und dazu die R-Codes liefert:</p>
<p>Einer der Datensätze aus dem Buch beschreibt die Fischgemeinschaften an 30 Probestellen (sites) des Flusses Doubs im schweizerisch-französischen Grenzgebiet. An allen Probestellen wurden relative Abundanzen von 27 Fischarten (jeweils 0–5; dependent variables) und 11 Umweltvariablen (independent variables) erhoben. Die folgende Abbildung zeigt für vier häufige Arten die Vereilungsmuster in simplen R-genierten Kärtchen:</p>
<p><img src="./myMediaFolder/media/image116.emf.png" class="img-fluid"></p>
</section>
<section id="generelles-zum-rda-befehl" class="level3">
<h3 class="anchored" data-anchor-id="generelles-zum-rda-befehl">Generelles zum rda-Befehl</h3>
<p>Hier seien kurz drei Syntax-Varianten des rda-Befehls im Package vegan vorgestellt:</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>simpleRDA <span class="ot">&lt;-</span> <span class="fu">rda</span> (Y, X, W)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p><strong>Y</strong> = Antwort-Matrix<strong><br>
X</strong> = Matrix der erklärenden Variablen (nur numerisch)<strong><br>
W</strong> = Matrix der Co-Variablen (optional, für partielle RDAs)</p>
</blockquote>
<p><strong>formulaRDA &lt;- rda (Y ~ var1 + factorA + var2*var3 + Condition(var4),<br>
data = Xwdata)</strong></p>
<blockquote class="blockquote">
<p><strong>Hier auch möglich<br>
</strong>- Faktoren (d.&nbsp;h. kategoriale Variable)<br>
- Interaktionen</p>
</blockquote>
<div class="sourceCode" id="cb146"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>spe.rda <span class="ot">&lt;-</span> <span class="fu">rda</span> (spe.hel <span class="sc">~</span> ., env3)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p><strong>Kurzschreibweise<br>
</strong>&gt; bedeutet: alle Variablen aus dataframe env3</p>
</blockquote>
</section>
<section id="interpretation-der-ergebnisse" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-der-ergebnisse">Interpretation der Ergebnisse</h3>
<p>Wir schauen uns nun die Ergebnisse an, wenn wir die RDA mit Hellingertransformierten Arthäufigkeiten und allen 10 Umweltvariablen rechnen:</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rda</span>(<span class="at">formula =</span> spe.hel <span class="sc">~</span> ele <span class="sc">+</span> slo <span class="sc">+</span> dis <span class="sc">+</span> pH <span class="sc">+</span> har <span class="sc">+</span> pho <span class="sc">+</span> nit <span class="sc">+</span>      amm <span class="sc">+</span> oxy <span class="sc">+</span> bod, <span class="at">data =</span> env3) </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb148"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>Partitioning of variance:</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>              Inertia Proportion</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>Total          0.5025     1.0000</span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>Constrained    0.3654     0.7271</span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>Unconstrained  0.1371     0.2729</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wie wir sehen, enthält der erste Teil des Ergebnis-Outputs eine Varianzpartitionierung. Die <strong>Gesamtvarianz wird aufgeteilt</strong> in jenen Anteil der <strong>durch die Umweltvariablen erklärt</strong> wird (<em>constrained</em>) und die <strong>unerklärte Restvarianz</strong> (<em>unconstrained</em>). Der Wert entspricht <em>R</em>² in linearen Modellen, hat aber einen <em>bias</em> (s. u.).</p>
<p>Der Output geht wie folgt weiter:</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>Importance of components:</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>                        RDA1   RDA2    RDA3    RDA4     RDA5     RDA6</span>
<span id="cb149-3"><a href="#cb149-3" aria-hidden="true" tabindex="-1"></a>Eigenvalue            0.2281 0.0537 0.03212 0.02321 0.008699 0.007218</span>
<span id="cb149-4"><a href="#cb149-4" aria-hidden="true" tabindex="-1"></a>Proportion Explained  0.4539 0.1069 0.06392 0.04618 0.017311 0.014363</span>
<span id="cb149-5"><a href="#cb149-5" aria-hidden="true" tabindex="-1"></a>Cumulative Proportion 0.4539 0.5607 0.62466 0.67084 0.688155 0.702518</span>
<span id="cb149-6"><a href="#cb149-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb149-7"><a href="#cb149-7" aria-hidden="true" tabindex="-1"></a>[…]</span>
<span id="cb149-8"><a href="#cb149-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb149-9"><a href="#cb149-9" aria-hidden="true" tabindex="-1"></a>                          RDA12     PC1     PC2     PC3     PC4</span>
<span id="cb149-10"><a href="#cb149-10" aria-hidden="true" tabindex="-1"></a>Eigenvalue            0.0003405 0.04581 0.02814 0.01528 0.01399</span>
<span id="cb149-11"><a href="#cb149-11" aria-hidden="true" tabindex="-1"></a>Proportion Explained  0.0006776 0.09116 0.05601 0.03042 0.02784</span>
<span id="cb149-12"><a href="#cb149-12" aria-hidden="true" tabindex="-1"></a>Cumulative Proportion 0.7270922 0.81825 0.87425 0.90467 0.93251</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wir sehen 12 RDA-Achsen (12 statt 10, da eine der Variablen ein Faktor war, der in drei dummy-Variablen zerlegt wurde). Die restliche Varianz findet sich dann auf den „unconstrained”-Achsen, die mit PC1, PC2 usw. benannt sind. Die Varianz auf diesen Achsen steht für nicht gemessene Variablen (oder auch Interkationen und unimodale Beziehungen dergemessenen Variablen).</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>Accumulated constrained eigenvalues</span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>Importance of components:</span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>                        RDA1   RDA2    RDA3    RDA4     RDA5     RDA6</span>
<span id="cb150-4"><a href="#cb150-4" aria-hidden="true" tabindex="-1"></a>Eigenvalue            0.2281 0.0537 0.03212 0.02321 0.008699 0.007218</span>
<span id="cb150-5"><a href="#cb150-5" aria-hidden="true" tabindex="-1"></a>Proportion Explained  0.6243 0.1470 0.08791 0.06351 0.023808 0.019755</span>
<span id="cb150-6"><a href="#cb150-6" aria-hidden="true" tabindex="-1"></a>Cumulative Proportion 0.6243 0.7712 0.85913 0.92264 0.946448 0.966202</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In diesem Fall erklärt die erste RDA-Achse schon ungewöhnlich hohe 62% der Gesamtvarianz, mit der zweiten Achse zusammen gar 77%. Der Output geht aber noch weiter…</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>Scaling 2 for species and site scores</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>* Species are scaled proportional to eigenvalues</span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a>* Sites are unscaled: weighted dispersion equal on all dimensions</span>
<span id="cb151-4"><a href="#cb151-4" aria-hidden="true" tabindex="-1"></a>* General scaling constant of scores:  1.93676 </span>
<span id="cb151-5"><a href="#cb151-5" aria-hidden="true" tabindex="-1"></a>Species scores</span>
<span id="cb151-6"><a href="#cb151-6" aria-hidden="true" tabindex="-1"></a>         RDA1     RDA2      RDA3      RDA4      RDA5      RDA6</span>
<span id="cb151-7"><a href="#cb151-7" aria-hidden="true" tabindex="-1"></a>Cogo  0.13386  0.11619 -0.238205  0.018531  0.043161 -0.029728</span>
<span id="cb151-8"><a href="#cb151-8" aria-hidden="true" tabindex="-1"></a>Satr  0.64240  0.06654  0.123649  0.181606 -0.009584  0.029785</span>
<span id="cb151-9"><a href="#cb151-9" aria-hidden="true" tabindex="-1"></a>Phph  0.47477  0.07009 -0.010153 -0.115349 -0.045312 -0.030034</span>
<span id="cb151-10"><a href="#cb151-10" aria-hidden="true" tabindex="-1"></a>Babl  0.36260  0.06966  0.041311 -0.190563 -0.046944  0.006446</span>
<span id="cb151-11"><a href="#cb151-11" aria-hidden="true" tabindex="-1"></a>Thth  0.13081  0.10707 -0.239273  0.043512  0.065818  0.003468</span>
<span id="cb151-12"><a href="#cb151-12" aria-hidden="true" tabindex="-1"></a>[…]</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><em>Species scores</em>sind die Koordinaten der Spitzen von Artvektoren in Bi- und Triplots. Es gibt zwei <em>Scaling</em>-Optionen, wobei Scaling 2 der <em>default</em> ist. Und es geht noch weiter:</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>Site scores (weighted sums of species scores)</span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a>       RDA1      RDA2     RDA3      RDA4      RDA5      RDA6</span>
<span id="cb152-4"><a href="#cb152-4" aria-hidden="true" tabindex="-1"></a>1   0.40149 -0.154133  0.55506  1.601005  0.193044  0.916850</span>
<span id="cb152-5"><a href="#cb152-5" aria-hidden="true" tabindex="-1"></a>2   0.53522 -0.025131  0.43393  0.294832 -0.518997  0.458849</span>
<span id="cb152-6"><a href="#cb152-6" aria-hidden="true" tabindex="-1"></a>3   0.49429 -0.014617  0.49415  0.169258 -0.246061  0.163409</span>
<span id="cb152-7"><a href="#cb152-7" aria-hidden="true" tabindex="-1"></a>4   0.33451  0.001188  0.51644 -0.320793  0.089569 -0.219820</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><em>Site scores</em> sind die Koordinaten der Untersuchungsflächen im Raum der abhängigen Variablen <strong>Y</strong> (hier also der Arten).</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>Site constraints (linear combinations of constraining variables)</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>       RDA1      RDA2     RDA3      RDA4      RDA5     RDA6</span>
<span id="cb153-3"><a href="#cb153-3" aria-hidden="true" tabindex="-1"></a>1   0.55130  0.002681  0.47744  0.626961 -0.210684  0.31503</span>
<span id="cb153-4"><a href="#cb153-4" aria-hidden="true" tabindex="-1"></a>2   0.29736  0.105880  0.64854  0.261364 -0.057127  0.09312</span>
<span id="cb153-5"><a href="#cb153-5" aria-hidden="true" tabindex="-1"></a>3   0.36843 -0.185333  0.59805  0.324556 -0.001611  0.31093</span>
<span id="cb153-6"><a href="#cb153-6" aria-hidden="true" tabindex="-1"></a>4   0.44346 -0.066361  0.33293 -0.344230 -0.279546 -0.37077</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><em>Site constraints</em> sind die Koordinaten der Untersuchungsflächen im Raum der Prädiktorvariablen <strong>X</strong> (hier also der Umweltvariablen).</p>
<p>Während dieser primäre Output schon sehr aufschlussreich war, gibt es noch weitere Dinge, die uns interessieren (sollten):</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(spe.rda)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb155"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>                        RDA1          RDA2          RDA3</span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>ele             0.0004483347  7.795777e-05  0.0005188756</span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>slo.moderate   -0.0123140760 -1.655649e-02  0.0160736225</span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a>slo.steep       0.0480170930  4.905556e-02  0.1023432587</span>
<span id="cb155-5"><a href="#cb155-5" aria-hidden="true" tabindex="-1"></a>slo.very_steep  0.0181630025 -5.708251e-02  0.2326204779</span>
<span id="cb155-6"><a href="#cb155-6" aria-hidden="true" tabindex="-1"></a>dis            -0.0014041126  4.456720e-03  0.0089169975</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><code>coef (spe.rda)</code> sind die Regressionskoeffizienten der Variablen zu den Achsen.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>\<span class="co"># Unadjusted R\^2 und Adjusted R\^2</span></span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>(R2 <span class="ot">&lt;-</span> <span class="fu">RsquareAdj</span>(spe.rda))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb157"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>$r.squared</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>[1] 0.7270922</span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>$adj.r.squared</span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>[1] 0.5224114</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Der originale (<em>unadjusted</em>) <em>R</em>² ist derselbe, den wir oben im Haupt-Output bekommen haben. <strong><em>R</em><sup>2</sup>-adjusted</strong> dagegen misst die <strong>erklärte Varianz ohne <em>bias</em></strong> (<em>bias</em> resultiert daraus, dass bei vielen Variablen zwischen diesen auch rein zufällig Korrelationen auftreten).</p>
</section>
<section id="visualisierung-der-ergebnisse" class="level3">
<h3 class="anchored" data-anchor-id="visualisierung-der-ergebnisse">Visualisierung der Ergebnisse</h3>
<p>Da eine RDA ein statistisch komplexes Verfahren ist, gibt es auch nicht nur eine Art und Weise, die Ergebnisse zu visualisieren, sondern zwei, Scaling 1 und Scaling 2. Diese sind im Folgenden gezeigt und ihre Unterschiede stichpunktartig erklärt. Scaling 1 eignet sich meist besser für die Visualisierung von Objekten (<em>sites</em>) und Scaling 2 meist bessser für die Visualisierung von Antwortvariablen (<em>species</em>).</p>
<p>Distanz-Triplot (<em>Scaling</em> 1):</p>
<p><img src="./myMediaFolder/media/image117.emf.png" class="img-fluid"></p>
<ol type="1">
<li><p><strong>Winkel zwischen Antwort- und erklärenden Variablen</strong> entsprechen &gt; deren Korrelationen (aber nicht jene zwischen Antwortvariablen)</p></li>
<li><p>Die Beziehung von <strong>Zentroiden qualitativer Variablen (Faktoren) und &gt; Antwortvariablen</strong> ergibt sich aus der Projektion der Zentroide im &gt; rechten Winkel auf die Anwortvariable.</p></li>
<li><p><strong>Distanzen zwischen Zentroiden und zwischen individuellen &gt; Objekten</strong> (<em>sites</em>) entsprechen ungefähr deren Distanzen im &gt; multivariaten Raum.</p></li>
</ol>
<p>Korrelations-Triplot (<em>Scaling</em> 2):</p>
<p><img src="./myMediaFolder/media/image118.emf.png" class="img-fluid"></p>
<ol type="1">
<li><p><strong>Die Projektion eines</strong> Objektes im rechten Winkel auf eine &gt; Antwort- oder eine numerische Prädiktorvariable entspricht dessen &gt; Wert entlang dieser Achse.</p></li>
<li><p><strong>Winkel zwischen Antwort- und erklärenden Variablen wie auch &gt; innerhalb beider Gruppen entsprechen deren Korrelationen</strong></p></li>
<li><p>Die Beziehung eines <strong>Zentroids</strong> einer qualitativen Variablen und &gt; der Antwortvariablen, ergibt sich aus seiner rechtwinkligen &gt; Projektion auf letztere.</p></li>
<li><p><strong>Distanzen zwischen Zentroiden und zwischen individuellen &gt; Objekten</strong> (<em>sites</em>) entsprechen <strong>nicht</strong> deren Distanzen im &gt; multivariaten Raum.</p></li>
</ol>
</section>
<section id="signifikanz-der-achsen" class="level3">
<h3 class="anchored" data-anchor-id="signifikanz-der-achsen">Signifikanz der Achsen</h3>
<p>Eine RDA produziert immer viele Achsen, aber die entscheidende Frage ist, <strong>welche davon signifikant sind</strong> (eine Frage, die wir nur im Falle von <em>constrained</em>-Ordinationen stellen können, da diese im Gegensatz zu den rein deskriptiven <em>unconstrained</em>-Ordinationen eine inferenzstatistische Komponente haben). Da die Voraussetzungen parametrischer Tests in der Regel massiv verletzt sind, kann die Signifikanz nur mit Permutationen gestestet werden:</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Global test of the RDA result</span></span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(spe.rda, <span class="at">permutations =</span> <span class="fu">how</span>(<span class="at">nperm =</span> <span class="dv">999</span>))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb159"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>Permutation test for rda under reduced model</span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>Permutation: free</span>
<span id="cb159-3"><a href="#cb159-3" aria-hidden="true" tabindex="-1"></a>Number of permutations: 999</span>
<span id="cb159-4"><a href="#cb159-4" aria-hidden="true" tabindex="-1"></a>Model: rda(formula = spe.hel ~ ele + slo + dis + pH + har + pho + nit + amm + oxy + bod, data = env3)</span>
<span id="cb159-5"><a href="#cb159-5" aria-hidden="true" tabindex="-1"></a>         Df Variance      F Pr(&gt;F)    </span>
<span id="cb159-6"><a href="#cb159-6" aria-hidden="true" tabindex="-1"></a>Model    12  0.36537 3.5523  0.001 ***</span>
<span id="cb159-7"><a href="#cb159-7" aria-hidden="true" tabindex="-1"></a>Residual 16  0.13714</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb160"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tests of all canonical axes</span></span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(spe.rda, <span class="at">by =</span> <span class="st">"axis"</span>, <span class="at">permutations =</span> <span class="fu">how</span>(<span class="at">nperm =</span> <span class="dv">999</span>))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb161"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>Permutation test for rda under reduced model</span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>Forward tests for axes</span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a>Permutation: free</span>
<span id="cb161-4"><a href="#cb161-4" aria-hidden="true" tabindex="-1"></a>Number of permutations: 999</span>
<span id="cb161-5"><a href="#cb161-5" aria-hidden="true" tabindex="-1"></a>Model: rda(formula = spe.hel ~ ele + slo + dis + pH + har + pho + nit + amm + oxy + bod, data = env3)</span>
<span id="cb161-6"><a href="#cb161-6" aria-hidden="true" tabindex="-1"></a>         Df Variance       F Pr(&gt;F)    </span>
<span id="cb161-7"><a href="#cb161-7" aria-hidden="true" tabindex="-1"></a>RDA1      1 0.228083 26.6105  0.001 ***</span>
<span id="cb161-8"><a href="#cb161-8" aria-hidden="true" tabindex="-1"></a>RDA2      1 0.053698  6.2649  0.004 ** </span>
<span id="cb161-9"><a href="#cb161-9" aria-hidden="true" tabindex="-1"></a>RDA3      1 0.032119  3.7473  0.333    </span>
<span id="cb161-10"><a href="#cb161-10" aria-hidden="true" tabindex="-1"></a>RDA4      1 0.023206  2.7074  0.775    </span>
<span id="cb161-11"><a href="#cb161-11" aria-hidden="true" tabindex="-1"></a>RDA5      1 0.008699  1.0149  1.000 </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wir sehen, dass in diesem Fall die ersten beiden Achsen (RDA1, RDA2) signifikant sind. Nur diese sollten abgebildet werden!</p>
</section>
<section id="partielle-rda-und-varianzpartitionierung" class="level3">
<h3 class="anchored" data-anchor-id="partielle-rda-und-varianzpartitionierung">Partielle RDA und Varianzpartitionierung</h3>
<p>Bei vielen Umweltvariablen können ggf. partielle RDAs aufschlussreich sein, die im Prinzip analog zu partiellen Regressionsplots (vgl. Statistik 3) funktionieren. Man kann dies für einzelne Variablen oder für Gruppen von Variablen machen. Zum Beispiel könnten wir fragen: Wie viel von der Zusammensetzung der Firschgemeinschaften erklärt die Wasserchemie, wenn man die topografischen Variablen konstant hält? Mit vegan geht das folgendermassen, einschliesslich Visualisierung in einem sogenannten Venn-Diagramm:</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Formula interface; X and W variables must be in the same </span></span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a><span class="co"># data frame</span></span>
<span id="cb162-3"><a href="#cb162-3" aria-hidden="true" tabindex="-1"></a>(spechem.physio2 <span class="ot">&lt;-</span> </span>
<span id="cb162-4"><a href="#cb162-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rda</span>(spe.hel <span class="sc">~</span> pH <span class="sc">+</span> har <span class="sc">+</span> pho <span class="sc">+</span> nit <span class="sc">+</span> amm <span class="sc">+</span> oxy <span class="sc">+</span> bod </span>
<span id="cb162-5"><a href="#cb162-5" aria-hidden="true" tabindex="-1"></a>        <span class="sc">+</span> <span class="fu">Condition</span>(ele <span class="sc">+</span> slo <span class="sc">+</span> dis), <span class="at">data =</span> env2))</span>
<span id="cb162-6"><a href="#cb162-6" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(spechem.physio2, <span class="at">permutations =</span> <span class="fu">how</span>(<span class="at">nperm =</span> <span class="dv">999</span>))</span>
<span id="cb162-7"><a href="#cb162-7" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(spechem.physio2, <span class="at">permutations =</span> <span class="fu">how</span>(<span class="at">nperm =</span> <span class="dv">999</span>), <span class="at">by =</span> <span class="st">"axis"</span>)</span>
<span id="cb162-8"><a href="#cb162-8" aria-hidden="true" tabindex="-1"></a>(spe.part.all <span class="ot">&lt;-</span> <span class="fu">varpart</span>(spe.hel, envchem, envtopo))</span>
<span id="cb162-9"><a href="#cb162-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-10"><a href="#cb162-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot of the partitioning results</span></span>
<span id="cb162-11"><a href="#cb162-11" aria-hidden="true" tabindex="-1"></a><span class="fu">dev.new</span>(<span class="at">title =</span> <span class="st">"Variation partitioning - all variables"</span>, </span>
<span id="cb162-12"><a href="#cb162-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">noRStudioGD =</span> <span class="cn">TRUE</span>)</span>
<span id="cb162-13"><a href="#cb162-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(spe.part.all, <span class="at">digits =</span> <span class="dv">2</span>, <span class="at">bg =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"blue"</span>),</span>
<span id="cb162-14"><a href="#cb162-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">Xnames =</span> <span class="fu">c</span>(<span class="st">"Chemistry"</span>, <span class="st">"Physiography"</span>), </span>
<span id="cb162-15"><a href="#cb162-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">id.size =</span> <span class="fl">0.7</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image119.png" class="img-fluid"></p>
<p>Das <strong>Venn-Diagramm visualisiert die Varianzaufteilung</strong> zwischen zwei (oder mehr Variablen oder Gruppen von Variablen). Hier erkären die chemischen Variablen 24 %, die pysiographischen (topographischen) 11 % jeweils unabhängig voneinander, wohingegen ein grosser Teil der Varianz (23 %) von beiden Variablengruppen gemeinsam erklärt wird (weil sie nicht völlig unkorreliert sind).</p>
</section>
</section>
<section id="zusammenfassung-6" class="level2">
<h2 class="anchored" data-anchor-id="zusammenfassung-6">Zusammenfassung</h2>
<ul>
<li><p><strong>Post-hoc gefittete Umweltvariablen</strong> dienen der nachträglichen Beschreibung der allein aufgrund der Artdaten gefundenen Ähnlichkeitsmuster.</p></li>
<li><p><strong>«Constrained» Ordinationen (RDA, CCA)</strong> betrachten dagegen von vornherein nur den Anteil der Ähnlichkeitsmuster in der Artenmatrix, der sich (in linearen Modellen) durch die gemessenen Umweltvariablen erklären lässt.</p></li>
<li><p>Eine RDA kann nicht nur deskriptiv gebraucht werden, sondern man kann auch die Signifikanz von Achsen analysieren oder Varianz partitionieren.</p></li>
</ul>
</section>
<section id="weiterführende-literatur-6" class="level2">
<h2 class="anchored" data-anchor-id="weiterführende-literatur-6">Weiterführende Literatur</h2>
<ul>
<li><p><strong>Borcard, D., Gillet, F. &amp; Legendre, P. 2018. <em>Numerical ecology with R</em>. 2nd ed.&nbsp;Springer, Cham: 435 pp.&nbsp;[mit R]</strong></p></li>
<li><p>Everitt, B. &amp; Hothorn, T. 2011. <em>An introduction to applied multivariate analysis with R</em>. Springer, New York: 273 pp.&nbsp;[mit R]</p></li>
<li><p>Legendre, P. &amp; Gallagher, E.D. 2001. Ecologically meaningful transformation for ordination of species data. <em>Oecologia</em> 129: 271–280.</p></li>
<li><p>Leyer, I. &amp; Wesche, K. 2007. <em>Multivariate Statistik in der Ökologie</em>. Springer, Berlin: 221 pp.&nbsp;[einfache Erklärung von Ordinationsmethoden, ohne R]</p></li>
<li><p>McCune, B., Grace, J.B. &amp; Urban, D.L. 2002. <em>Analysis of ecological communities</em>. MjM Software Design, Gleneden Beach, Oregon, US: 300 pp.&nbsp;[gut erklärte und detaillierte Einführung in Ordinationen u.a., ohne R]</p></li>
<li><p>Oksanen, L. 2015. <em>Multivariate analysis of ecological communities in R: vegan tutorial</em>. URL: <a href="http://cc.oulu.fi/~jarioksa/opetus/metodi/vegantutor.pdf" class="uri">http://cc.oulu.fi/~jarioksa/opetus/metodi/vegantutor.pdf</a>. [gute Einführung in das R-package <em>vegan</em> mit vielen Ordinationsmethoden]</p></li>
<li><p>Wildi, O. 2017. <em>Data analysis in vegetation ecology</em>. 3rd ed.&nbsp;CABI, Wallingford, UK: 333 pp.&nbsp;[mit R]</p></li>
</ul>
</section>
<section id="quellen-des-beispiels" class="level2">
<h2 class="anchored" data-anchor-id="quellen-des-beispiels">Quellen des Beispiels</h2>
<p>Hüllbusch, E., Brandt, L.M., Ende, P. &amp; Dengler, J. 2016. Little vegetation change during two decades in a dry grassland complex in the Biosphere Reserve Schorfheide-Chorin (NE Germany). <em>Tuexenia</em> 36: 395−412.</p>
</section>
</section>
<section id="statistik-8-clusteranalysen-und-rückblick" class="level1">
<h1>Statistik 8: Clusteranalysen und Rückblick</h1>
<p><strong>In Statistik 8 lernen die Studierenden Clusteranalysen/Klassifikationen als eine den Ordinationen komplementäre Technik der deskriptiven Statistik multivariater Datensätze kennen. Es gibt Partitionierungen (ohne Hierarchie), divisive und agglomerative Clusteranalysen (die jeweils eine Hierarchie produzieren). Etwas genauer gehen wir auf die <em>k</em>-means Clusteranalyse (eine Partitionierung) und eine Reihe von agglomerativen Clusterverfahren ein. Hierbei hat das gewählte Distanzmass und der Modus für die sukzessive Fusion von Clustern einen grossen Einfluss auf das Endergebnis. Wir besprechen ferner, wie man die Ergebnisse von Clusteranalysen adäquat visualisieren und mit anderen statistischen Prozeduren kombinieren kann.</strong></p>
<p><strong>Im Abschluss von Statistik 8 werden wir dann die an den acht Statistiktagen behandelten Verfahren noch einmal rückblickend betrachten und thematisieren, welches Verfahren wann gewählt werden sollte. Ebenfalls ist Platz, um den adäquaten Ablauf statistischer Analysen vom Einlesen der Daten bis zur Verschriftlichung der Ergebnisse, einschliesslich der verschiedenen zu treffenden Entscheidungen, zu thematisieren.</strong></p>
<section id="lernziele-7" class="level2">
<h2 class="anchored" data-anchor-id="lernziele-7">Lernziele</h2>
<p><em>Ihr…</em></p>
<ul>
<li><p><em>habt eine prinzipielle Idee, wie <strong>Cluster-Analysen</strong> funktionieren;</em></p></li>
<li><p><em>könnt <strong>k-means clustering</strong> auf Datensätze anwenden; und</em></p></li>
<li><p><em>kennt <strong>unterschiedliche Methoden der agglomerativen Clusteranalyse</strong> sowie der Bewertung von ihren Ergebnissen und könnt ihre jeweilige Eignung grob einschätzen.</em></p></li>
</ul>
</section>
<section id="clusteranalysen-allgemein" class="level2">
<h2 class="anchored" data-anchor-id="clusteranalysen-allgemein">Clusteranalysen allgemein</h2>
<p>Wie Ordinationen (Statistik 6 und 7) gehören Clusteranalysen zu den multivariat-deskriptiven Methoden. Wozu macht man dann Clusteranalysen?</p>
<ul>
<li><p>Clusteranalysen sind <strong>komplementär zu Ordinationen</strong>: Bei Clusteranalysen liegt der Fokus auf den Unterschieden, während bei der Ordination der Fokus auf dem allmählichen Wandel entlang von Gradienten liegt. Insofern sind Ordinationen und Clusteranalysen Methoden, die für die gleichen Datensätze und z.&nbsp;T. ähnliche Fragestellungen angewendet werden können, aber mit Betonung unterschiedlicher Aspekte. Oftmals werden in einer Studie sogar beide Verfahren angewandt.</p></li>
<li><p>Prinzipiell geht es bei Clusteranalysen um das Herausarbeiten von Gruppen von Objekten mit ähnlichen Eigenschaften, z. B.:</p>
<ul>
<li><p>um diese zu beschreiben,</p></li>
<li><p>um diese auf Unterschiede zu testen oder</p></li>
<li><p>um deren Verbreitung in Karten darstellen zu können.</p></li>
</ul></li>
</ul>
<p>Es gibt drei grundlegende Typen von Clusteranalysen, jeweils mit mehreren Methoden:</p>
<ul>
<li><p><strong>Partitionierung</strong> (ohne Hierarchie)</p></li>
<li><p><strong>Hierarchische Clusteranalyse</strong></p>
<ul>
<li><p><strong>divisiv</strong> (der Gesamtdatensatz wird sukzessive in immer feinere Gruppen aufgeteilt)</p></li>
<li><p><strong>agglomerativ</strong> (beginnend mit den Einzelbeobachtungen werden diese immer weiter zu Gruppen zusammengefasst)</p></li>
</ul></li>
</ul>
<p>Im Kurs behandeln wir nur die Partitionierung und verschiedene agglomerative Clusterferfahren. Ein divisives Clusterverfahren wäre z. B. TWINSPAN (Hill 1979; Roleček et al.&nbsp;2009), welches in der Vegetationsökologie viel verwendet wird, m. W. nicht in R implementiert ist, dafür unter anderem im Freeware-Programm JUICE (Tichý 2002).</p>
</section>
<section id="k-means-clustering" class="level2">
<h2 class="anchored" data-anchor-id="k-means-clustering">k-means clustering</h2>
<p>Das <em>k-means clustering</em> ist die einfachste Clustermethode überhaupt. Ihre Kernaspekte lassen sich wie folgt beschreiben:</p>
<ul>
<li><p>Partitionierung (ohne Hierarchie) in vom Benutzer vorgegebene <em>k</em> Cluster.</p></li>
<li><p>Verfahren versucht die Summe der quadratische Abweichungen vom den Clusterzentren (Zentroide) zu minimieren.</p></li>
<li><p>In der Tendenz entstehen ± sphärische Cluster ähnlicher Grösse (sphärisch meint kugelförmig/isodiametrisch, aber eben nicht im dreidimensionalen, sondern im vieldimensionalen Variablenraum).</p></li>
<li><p>Da das Ganze mit einem iterativen Optimierungsalgorithmus passiert, der mit zufällig gewählten Startpunkten beginnt, unterscheiden sich unterschiedliche Durchläufe im Ergebnis.</p></li>
</ul>
<p>Die Durchführung des <em>k-means clustering</em> eines multivariaten Datensatzes geschieht mit dem Befehl kmeans aus Base R, hier angewandt auf unseren Moordatensatz, den wir schon von den Ordinationen kennen:</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>kmeans<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(sveg, <span class="dv">3</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wie sehen unsere drei Cluster nun aus? Am besten plotten wir sie in das Ordinationsdiagramm, indem wir die Beobachtungen je nach Clusterzugehörigkeit einfärben:</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pca, <span class="at">type =</span> <span class="st">"n"</span>)</span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(pca, <span class="at">display =</span> <span class="st">"sites"</span>, <span class="at">pch=</span><span class="dv">19</span>, <span class="at">col=</span>kmeans<span class="fl">.2</span>[[<span class="dv">1</span>]])</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="./myMediaFolder/media/image120.png" class="img-fluid"></p>
<p>Wie viele Cluster sollte man nun unterscheiden? Oftmals ergibt sich die Zahl (oder zumindest eine Grössenordnung) aus dem Zweck, für den man die Clusteranalyse macht. Es gibt auch unterschiedliche numerische Kriterien, um die „beste” Partitionierung zu finden (allerdings liefern verschieden Gütemasse unterschiedliche Ergebnisse).</p>
<p>Ein Gütemass ist <strong>SSI = <em>Simple Structure Index</em></strong>. Der SSI kombiniert drei Aspekte von Cluster-Güte: (a) maximale Differenz aller Variablen zwischen den Clustern, (b) Grössen der einzelnen Clustern und (c) Abweichung der Variablenwerte in den Clusterzentren vom Gesamtmittel. Der SSI reicht von 0 bis 1 und eine Partitionierung ist umso besser, je höher der Wert ist.</p>
<p>Wenn wir mit einem kurzen R-Code (wird in der Demo gezeigt) für unseren Moordatensatz die Partitionen von <em>k</em> = 2 bis 10 ausrechnen und jeweils den SSI berechnen, ergibt sich das folgende Bild:</p>
<p><img src="./myMediaFolder/media/image121.emf.png" class="img-fluid"></p>
<p>Die farbige Visualisierung links zeigt, dass es eben keine hierarchische Clusteranalyse ist. Bei <em>k</em> &gt; 2 bleibt die ursprüngliche Abgrenzung der zwei Hauptcluster nicht erhalten. Gemäss SSI wäre in diesem Fall die 10-Cluster-Lösung die beste (es sei aber empfohlen, solchen numerischen „Empfehlungen” nicht blindlings zu glauben).</p>
</section>
<section id="agglomerative-clusterverfahren" class="level2">
<h2 class="anchored" data-anchor-id="agglomerative-clusterverfahren">Agglomerative Clusterverfahren</h2>
<section id="einführung" class="level3">
<h3 class="anchored" data-anchor-id="einführung">Einführung</h3>
<p>Bei agglomerativen Clusterverfahren folgt der Algorithmus immer dem folgenden Ablauf:</p>
<ul>
<li><p>Sie fassen die <strong>beiden ähnlichsten Beobachtungen als initiales Cluster</strong> zusammen.</p></li>
<li><p>Danach geht es mit dem <strong>Zusammenfassen des nächstähnlichen Paares</strong> von Einzelbeobachtungen bzw. Clustern so lange weiter, bis alle Cluster zu einem einzigen zusammengefasst sind.</p></li>
</ul>
<p>Es gibt deswegen so viele verschiedene agglomerative Clusterverfahren, da man zwei wesentliche Parameter im Prinzip frei kombinieren kann, das verwendete Distanzmass und den Modus für das Zusammenfügen von Clustern:</p>
<p>An <strong>Distanzmassen</strong> sind die folgenden beiden die gängigsten:</p>
<ul>
<li><p><strong>Euklidische (pythagoreische) Distanz</strong>: Länge der Gerade, die die beiden Punkte im multidimensionalen Hyperraum miteinander verbindet.</p></li>
<li><p><strong>Chord-Distanz</strong>: euklidische Distanz, nachdem alle Variablen auf Länge 1 standardisiert wurden.</p></li>
</ul>
<p>Die vier gängigsten <strong>Modi für das Zusammenfassen von Clustern</strong> sind:</p>
<ul>
<li><p><strong><em>Single linkage</em></strong> (<em>nearest neighbour</em>): Distanz zum nächsten Element eines Clusters wird genommen.</p></li>
<li><p><strong><em>Complete linkage</em></strong> (<em>furthest neighbour</em>): Distanz zum am weitesten entfernten Element eines Clusters wird genommen.</p></li>
<li><p><strong><em>Average linkage</em></strong> (4 verschiedene Methoden, darunter besonders gängig <strong>UPGMA = <em>unweighted pair-group method using arithmetic averages</em></strong>): Distanz zum Cluster”zentrum” wird genommen.</p></li>
<li><p><strong><em>Ward’s mimimum variance clustering</em></strong>: Statt Distanzen zwischen Clustermitgliedern zu minimieren, wird hier die Clustervariabilität minimiert.</p></li>
</ul>
<p>Schauen wir uns an, welchen Effekt die vier Verfahren kombiniert mit der Chord-Distanz auf die Fischgemeinschaftsdaten des Doubs-Datensatzes haben:</p>
<p><img src="./myMediaFolder/media/image122.emf.png" class="img-fluid"><img src="./myMediaFolder/media/image123.emf.png" class="img-fluid"><img src="./myMediaFolder/media/image124.emf.png" class="img-fluid"><img src="./myMediaFolder/media/image125.emf.png" class="img-fluid"></p>
<p>Es zeigt sich, dass die Cluster doch sehr unterschiedlich aussehen können. Die terminalen Cluster sind oft identisch (ein Cluster aus den Probestellen 17 und 18 gibt es etwas bei allen vier Methoden), doch auf höherer Ebene gibt es gravierende Unterschiede. Diese äussern sich insbesondere in der Anfälligkeit gegenüber <strong>Kettenbildung (<em>Chaining</em>)</strong>, was meint, dass eine Aufnahme allen anderen gegenübergesellt wird und in diesem grossen Cluster im nächsten Schritt wieder eine einzige einzige Aufnahme dem Rest herausgegriffen usw. <em>Single linkage</em> ist methodenbedingt besonders anfällig für <em>Chaining</em> (siehe links oben). Da für die meisten Anwendungen solche Ein- Aufnahmen-Cluster unpraktisch sind, wird <em>single linkage</em> kaum noch verwendet. <em>Complete linkage</em> und UPGMA neigen weniger zu Chaining und die Ward-Methode am wenigsten.</p>
</section>
<section id="güte-von-clusterungen" class="level3">
<h3 class="anchored" data-anchor-id="güte-von-clusterungen">Güte von Clusterungen</h3>
<p>Nun ist zwar Chaining unpraktisch, aber was, wenn es doch die realen Ähnlichkeitsbeziehungen am besten wiedergeben würde? Ein gutes Mass für die Güte eines Clusterergebnisses ist die <strong>Cophenetische Korrelation</strong>. Hier werden die Clusterpositionen in paarweise Distanzen zwischen Beobachtungen übersetzt und mit den ursprünglichen Distanzen verglichen (vergleichbar dem Stressplot im Falle einer NMDS-Ordination, vgl. Statistik 6). Schauen wir uns das Ergebnis für die vier Beispiele von oben an:</p>
<p><img src="./myMediaFolder/media/image126.jpeg" class="img-fluid"></p>
<p>Auch hier schneidet <em>single linkage</em> am schlechtesten ab. Wie meist, sind UPGMA und Ward am besten, wobei hier UPGMA sogar besser als Ward abschneidet.</p>
</section>
<section id="wie-viele-cluster-sollte-man-unterscheiden" class="level3">
<h3 class="anchored" data-anchor-id="wie-viele-cluster-sollte-man-unterscheiden">Wie viele Cluster sollte man unterscheiden?</h3>
<p>Wie schon bei der <em>k</em>-means-Partitionierung stellt sich auch beim hierarchischen Clustering die Frage nach der optimalen Zahl von unterschiedenen Clustern. Vielfach ergibt sich die Antwort darauf zumindest grössenordnungsmässig aus der geplanten Verwendung der Cluster. Es gibt auch verschiedene mathematische Gütemasse, u.&nbsp;a. Silhouette, Matrix-Korrelation und Indikatorarten:</p>
<p>Sihouette: mittlere Distanz eines Objektes zu allen Objekten eines Clusters zur mittleren Distanz zu allen Objekten des nächstähnlichen Clusters. Die Werte reichen von –1 bis +1.</p>
<p><img src="./myMediaFolder/media/image127.emf.png" class="img-fluid"></p>
<p>Matrix-Korrelation: Vergleich der originalen Unähnlichkeitsmatrix mit der binären Matrix basierend auf der Gruppenzusammengehörigkeit im Dendrogramm.</p>
<p><img src="./myMediaFolder/media/image128.emf.png" class="img-fluid"></p>
<p>Indikatorarten: Anzahl von Indikatorarten (links) bzw. Anteil von Clustern mit signifikanten Indikatorarten (rechts) (hier basierend auf dem IndVal-Konzept; siehe Borcard et al.&nbsp;2018). Dieser Ansatz funktioniert natürlich nur, wenn es sich um Daten von Artengemeinschaften handelt.</p>
<p><img src="./myMediaFolder/media/image129.emf.png" class="img-fluid"></p>
</section>
<section id="charakterisierung-von-clustern" class="level3">
<h3 class="anchored" data-anchor-id="charakterisierung-von-clustern">Charakterisierung von Clustern</h3>
<p>Wie schon bei <em>k</em>-means können wir die Cluster dadurch charakterisieren, dass wir die Clusterzugehörigkeit in ein einfaches oder Biplot-Ordinationsdiagramm plotten. Weitere Möglichkeiten der Beschreibung/Charakterisierung von Clustern sind u.&nbsp;a. (jeweils visualisiert für die 4-Cluster-Lösung des Doubs-Datensatzes):</p>
<ol type="1">
<li>Einfärbung im Dendrogramm (den R-Code dazu gibt es im Demoskript):</li>
</ol>
<p><img src="./myMediaFolder/media/image130.emf.png" class="img-fluid"></p>
<ol start="2" type="1">
<li>Geordnete Community-Tabelle (im Fall von von gemeinschaftsökologischen Daten), ggf. mit Hervorhebung der signifikant konzentrierten Arten:</li>
</ol>
<div class="sourceCode" id="cb165"><pre class="sourceCode default code-with-copy"><code class="sourceCode default"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>      32222222222  111111     1111 </span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>      09876210543959876506473221341</span>
<span id="cb165-3"><a href="#cb165-3" aria-hidden="true" tabindex="-1"></a> Icme 5432121......................</span>
<span id="cb165-4"><a href="#cb165-4" aria-hidden="true" tabindex="-1"></a> Abbr 54332431.....1...............</span>
<span id="cb165-5"><a href="#cb165-5" aria-hidden="true" tabindex="-1"></a> Blbj 54542432.1...1...............</span>
<span id="cb165-6"><a href="#cb165-6" aria-hidden="true" tabindex="-1"></a> Anan 54432222.....111.............</span>
<span id="cb165-7"><a href="#cb165-7" aria-hidden="true" tabindex="-1"></a> Gyce 5555443212...11..............</span>
<span id="cb165-8"><a href="#cb165-8" aria-hidden="true" tabindex="-1"></a> Scer 522112221...21...............</span>
<span id="cb165-9"><a href="#cb165-9" aria-hidden="true" tabindex="-1"></a> Cyca 53421321.....1111............</span>
<span id="cb165-10"><a href="#cb165-10" aria-hidden="true" tabindex="-1"></a> Rham 55432333.....221.............</span>
<span id="cb165-11"><a href="#cb165-11" aria-hidden="true" tabindex="-1"></a> Legi 35432322.1...1111............</span>
<span id="cb165-12"><a href="#cb165-12" aria-hidden="true" tabindex="-1"></a> Alal 55555555352..322.............</span>
<span id="cb165-13"><a href="#cb165-13" aria-hidden="true" tabindex="-1"></a> Chna 12111322.1...211.............</span>
<span id="cb165-14"><a href="#cb165-14" aria-hidden="true" tabindex="-1"></a> Titi 53453444...1321111.21........</span>
<span id="cb165-15"><a href="#cb165-15" aria-hidden="true" tabindex="-1"></a> Ruru 55554555121455221..1.........</span>
<span id="cb165-16"><a href="#cb165-16" aria-hidden="true" tabindex="-1"></a> Albi 53111123.....2341............</span>
<span id="cb165-17"><a href="#cb165-17" aria-hidden="true" tabindex="-1"></a> Baba 35342544.....23322.........1.</span>
<span id="cb165-18"><a href="#cb165-18" aria-hidden="true" tabindex="-1"></a> Eslu 453423321...41111..12.1....1.</span>
<span id="cb165-19"><a href="#cb165-19" aria-hidden="true" tabindex="-1"></a> Gogo 5544355421..242122111......1.</span>
<span id="cb165-20"><a href="#cb165-20" aria-hidden="true" tabindex="-1"></a> Pefl 54211432....41321..12........</span>
<span id="cb165-21"><a href="#cb165-21" aria-hidden="true" tabindex="-1"></a> Pato 2211.222.....3344............</span>
<span id="cb165-22"><a href="#cb165-22" aria-hidden="true" tabindex="-1"></a> Sqce 3443242312152132232211..11.1.</span>
<span id="cb165-23"><a href="#cb165-23" aria-hidden="true" tabindex="-1"></a> Lele 332213221...52235321.1.......</span>
<span id="cb165-24"><a href="#cb165-24" aria-hidden="true" tabindex="-1"></a> Babl .1111112...32534554555534124.</span>
<span id="cb165-25"><a href="#cb165-25" aria-hidden="true" tabindex="-1"></a> Teso .1...........11254........23.</span>
<span id="cb165-26"><a href="#cb165-26" aria-hidden="true" tabindex="-1"></a> Phph .1....11...13334344454544455.</span>
<span id="cb165-27"><a href="#cb165-27" aria-hidden="true" tabindex="-1"></a> Cogo ..............1123......2123.</span>
<span id="cb165-28"><a href="#cb165-28" aria-hidden="true" tabindex="-1"></a> Satr .1..........2.123413455553553</span>
<span id="cb165-29"><a href="#cb165-29" aria-hidden="true" tabindex="-1"></a> Thth .1............11.2......2134.</span>
<span id="cb165-30"><a href="#cb165-30" aria-hidden="true" tabindex="-1"></a>  sites species </span>
<span id="cb165-31"><a href="#cb165-31" aria-hidden="true" tabindex="-1"></a>     29      27 </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="3" type="1">
<li>Vergleich der (Umwelt-)Variablen zwischen den Clustern mittels <strong>ANOVA</strong>.</li>
</ol>
</section>
</section>
<section id="zusammenfassung-7" class="level2">
<h2 class="anchored" data-anchor-id="zusammenfassung-7">Zusammenfassung</h2>
<ul>
<li><p><strong><em>k-means clustering</em></strong> ist eine einfache nicht-hierarchische Clustermethode, bei der der Benutzer vorgibt, wie viele Einheiten er haben möchte.</p></li>
<li><p><strong>Agglomerative Clusterverfahren</strong> fassen Einheiten sukzessive über ihre Ähnlichkeitsbeziehungen zusammen. Am Ende kann man dann subjektiv oder nach unterschiedlichen numerischen Kriterien entscheiden, welche Clusterauflösung dem Bedarf am besten entspricht.</p></li>
</ul>
</section>
<section id="weiterführende-literatur-7" class="level2">
<h2 class="anchored" data-anchor-id="weiterführende-literatur-7">Weiterführende Literatur</h2>
<p><strong>Borcard, D., Gillet, F. &amp; Legendre, P. 2018. <em>Numerical ecology with R</em>. 2nd ed.&nbsp;Springer, Cham: 435 pp.&nbsp;[mit R]</strong></p>
<p>Crawley, M.J. 2013. <em>The R book</em>. 2nd ed.&nbsp;John Wiley &amp; Sons, Chichester, UK: 1051 pp.&nbsp;[mit R]</p>
<p>Everitt, B. &amp; Hothorn, T. 2011. <em>An introduction to applied multivariate analysis with R</em>. Springer, New York: 273 pp.&nbsp;[mit R]</p>
<p>Hill, M.O. 1979. <em>TWINSPAN – A FORTRAN program for arranging multivariate data in an ordered two-way table by classification of the individuals and attributes</em>. Cornell University, Ithaca, NY: 90 pp.</p>
<p>Roleček, J., Tichý, L., Zelený, D. &amp; Chytrý, M. 2009. Modified TWINSPAN classification in which the hierarchy represents cluster heterogeneity. <em>Journal of Vegetation Science</em> 20: 596–602.</p>
<p>Tichý, L. 2002. JUICE, software for vegetation classification. <em>Journal of Vegetation Science</em> 13: 451–453.</p>
<p>Wildi, O. 2017. <em>Data analysis in vegetation ecology</em>. 3rd ed.&nbsp;CABI, Wallingford, UK: 333 pp.&nbsp;[mit R]</p>
</section>
</section>
<section id="anhang-übersicht-über-statistische-verfahren" class="level1">
<h1>Anhang: Übersicht über statistische Verfahren</h1>
<p><img src="./myMediaFolder/media/image131.emf.png" class="img-fluid"></p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Kopiert");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Kopiert");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>